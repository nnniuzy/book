
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>超分辨率代码数据集合集 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="baseline.html" />
    
    
    <link rel="prev" href="SR.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../introduction/0.html">
            
                <a href="../introduction/0.html">
            
                    
                    送给研一入学的你们—炼丹师入门手册
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../introduction/AI_system.html">
            
                <a href="../introduction/AI_system.html">
            
                    
                    为什么要使得AI System具备可解释性呢？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../code_technique/">
            
                <a href="../code_technique/">
            
                    
                    编程技巧
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../code_technique/python/python_technique.html">
            
                <a href="../code_technique/python/python_technique.html">
            
                    
                    python编程技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../code_technique/python/sort.html">
            
                <a href="../code_technique/python/sort.html">
            
                    
                    python常见排序
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../code_technique/python/opencv.html">
            
                <a href="../code_technique/python/opencv.html">
            
                    
                    opencv-python极速入门
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../code_technique/pytorch/pytorch1.html">
            
                <a href="../code_technique/pytorch/pytorch1.html">
            
                    
                    pytorch常用代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../code_technique/pytorch/pytorch2.html">
            
                <a href="../code_technique/pytorch/pytorch2.html">
            
                    
                    pytorch常用代码段合集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../code_technique/pytorch/pytorch_train.html">
            
                <a href="../code_technique/pytorch/pytorch_train.html">
            
                    
                    pytorch训练技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="../code_technique/pytorch/pytorch_.html">
            
                <a href="../code_technique/pytorch/pytorch_.html">
            
                    
                    pytorch解冻
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="../code_technique/pytorch/pytorch_vision.html">
            
                <a href="../code_technique/pytorch/pytorch_vision.html">
            
                    
                    pytorch网络可视化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.9" data-path="../code_technique/pytorch/PSNR_SSIM.html">
            
                <a href="../code_technique/pytorch/PSNR_SSIM.html">
            
                    
                    PSNR&&SSIM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.10" data-path="../code_technique/pytorch/SPP.html">
            
                <a href="../code_technique/pytorch/SPP.html">
            
                    
                    SPP
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.11" data-path="../code_technique/pytorch/Tensor_to_img_imge_to_tensor.html">
            
                <a href="../code_technique/pytorch/Tensor_to_img_imge_to_tensor.html">
            
                    
                    Tensor to img && imge to tensor
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../linux/">
            
                <a href="../linux/">
            
                    
                    Linux
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../linux/linux_technique.html">
            
                <a href="../linux/linux_technique.html">
            
                    
                    Linux技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../linux/linux_GPU.html">
            
                <a href="../linux/linux_GPU.html">
            
                    
                    Linux显卡驱动修复
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../paper/">
            
                <a href="../paper/">
            
                    
                    论文
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../paper/paper_write.html">
            
                <a href="../paper/paper_write.html">
            
                    
                    论文写作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../paper/Image_to_Image.html">
            
                <a href="../paper/Image_to_Image.html">
            
                    
                    Image-to-Image 的论文汇总（含 GitHub 代码）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../paper/GNN.html">
            
                <a href="../paper/GNN.html">
            
                    
                    GNN综述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../paper/Perceptual_GAN_for_Small_Object_Detection.html">
            
                <a href="../paper/Perceptual_GAN_for_Small_Object_Detection.html">
            
                    
                    Perceptual GAN for Small Object Detection阅读笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.5" data-path="../paper/GMMN.html">
            
                <a href="../paper/GMMN.html">
            
                    
                    GAN变体-GMMN 网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6" data-path="../paper/Deformable_Kernels.html">
            
                <a href="../paper/Deformable_Kernels.html">
            
                    
                    图像视频去噪中的Deformable Kernels
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.7" data-path="../paper/Isolating_Sources_of_Disentanglement_in_VAEs.html">
            
                <a href="../paper/Isolating_Sources_of_Disentanglement_in_VAEs.html">
            
                    
                    Isolating Sources of Disentanglement in VAEs
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.8" data-path="../paper/Spectral_Normalization.html">
            
                <a href="../paper/Spectral_Normalization.html">
            
                    
                    Spectral Normalization 谱归一化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9" data-path="../paper/Unbalanced_sample_loss.html">
            
                <a href="../paper/Unbalanced_sample_loss.html">
            
                    
                    不均衡样本loss
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10" data-path="../paper/NN.html">
            
                <a href="../paper/NN.html">
            
                    
                    论文神经网络示意图
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="./">
            
                <a href="./">
            
                    
                    超分辨率
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="SR_summarize.html">
            
                <a href="SR_summarize.html">
            
                    
                    超分辨率方向综述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="SR.html">
            
                <a href="SR.html">
            
                    
                    超分辨率技术
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.7.3" data-path="code_dataset.html">
            
                <a href="code_dataset.html">
            
                    
                    超分辨率代码数据集合集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="baseline.html">
            
                <a href="baseline.html">
            
                    
                    超分辨率baseline
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="loss.html">
            
                <a href="loss.html">
            
                    
                    超分辨率的损失函数总结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../data/">
            
                <a href="../data/">
            
                    
                    图片和数据处理
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="../data/picture.html">
            
                <a href="../data/picture.html">
            
                    
                    图片处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="../data/picture_enhance.html">
            
                <a href="../data/picture_enhance.html">
            
                    
                    图像数据增强
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="../data/data.html">
            
                <a href="../data/data.html">
            
                    
                    数据增强
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.4" data-path="../data/imaaug.html">
            
                <a href="../data/imaaug.html">
            
                    
                    imaaug 数据增强大杀器
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../math/">
            
                <a href="../math/">
            
                    
                    数学
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="../math/matrix.html">
            
                <a href="../math/matrix.html">
            
                    
                    矩阵总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="../math/distribution_show.html">
            
                <a href="../math/distribution_show.html">
            
                    
                    分布
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.3" data-path="../math/affine_transformation.html">
            
                <a href="../math/affine_transformation.html">
            
                    
                    仿射变换
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.4" data-path="../math/graph.html">
            
                <a href="../math/graph.html">
            
                    
                    图的基本概念
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../other/">
            
                <a href="../other/">
            
                    
                    其他
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="../other/discriminator_train.html">
            
                <a href="../other/discriminator_train.html">
            
                    
                    判别器训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="../other/FLOPS.html">
            
                <a href="../other/FLOPS.html">
            
                    
                    网络FLOPS计算
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >超分辨率代码数据集合集</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="awesome-super-resolution&#xFF08;in-progress&#xFF09;">Awesome-Super-Resolution&#xFF08;in progress&#xFF09;</h1>
<h2 id="repositories">repositories</h2>
<h1 id="repositories">repositories</h1>
<h4 id="awesome-paper-list"><strong>Awesome paper list:</strong></h4>
<p><strong>&#x56FE;&#x50CF;&#x8D85;&#x5206;&#x8FA8;&#xFF1A;</strong></p>
<p><a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank">https://github.com/YapengTian/Single-Image-Super-Resolution</a></p>
<p><strong>&#x8D85;&#x5206;&#x8FA8;Benckmark&#xFF1A;</strong></p>
<p><a href="https://github.com/huangzehao/Super-Resolution.Benckmark" target="_blank">https://github.com/huangzehao/Super-Resolution.Benckmark</a></p>
<p><strong>&#x89C6;&#x9891;&#x8D85;&#x5206;&#x8FA8;&#xFF1A;</strong></p>
<p><a href="https://github.com/flyywh/Video-Super-Resolution" target="_blank">https://github.com/flyywh/Video-Super-Resolution</a></p>
<p><a href="https://github.com/LoSealL/VideoSuperResolution" target="_blank">https://github.com/LoSealL/VideoSuperResolution</a></p>
<h4 id="awesome-paper-list">Awesome paper list:</h4>
<p><a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank">Single-Image-Super-Resolution</a></p>
<p><a href="https://github.com/huangzehao/Super-Resolution.Benckmark" target="_blank">Super-Resolution.Benckmark</a></p>
<p><a href="https://github.com/flyywh/Video-Super-Resolution" target="_blank">Video-Super-Resolution</a></p>
<p><a href="https://github.com/LoSealL/VideoSuperResolution" target="_blank">VideoSuperResolution</a></p>
<h4 id="awesome-repos">Awesome repos:</h4>
<table>
<thead>
<tr>
<th style="text-align:center">repo</th>
<th style="text-align:center">Framework</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://github.com/thstkdgus35/EDSR-PyTorch" target="_blank">EDSR-PyTorch</a></td>
<td style="text-align:center">PyTorch</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/titu1994/Image-Super-Resolution" target="_blank">Image-Super-Resolution</a></td>
<td style="text-align:center">Keras</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/idealo/image-super-resolution" target="_blank">image-super-resolution</a></td>
<td style="text-align:center">Keras</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/WolframRhodium/Super-Resolution-Zoo" target="_blank">Super-Resolution-Zoo</a></td>
<td style="text-align:center">MxNet</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/krasserm/super-resolution" target="_blank">super-resolution</a></td>
<td style="text-align:center">Keras</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/alexjc/neural-enhance" target="_blank">neural-enhance</a></td>
<td style="text-align:center">Theano</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/david-gpu/srez" target="_blank">srez</a></td>
<td style="text-align:center">Tensorflow</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/nagadomi/waifu2x" target="_blank">waifu2x</a></td>
<td style="text-align:center">Torch</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/xinntao/BasicSR" target="_blank">BasicSR</a></td>
<td style="text-align:center">PyTorch</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/icpm/super-resolution" target="_blank">super-resolution</a></td>
<td style="text-align:center">PyTorch</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/LoSealL/VideoSuperResolution" target="_blank">VideoSuperResolution</a></td>
<td style="text-align:center">Tensorflow</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://github.com/thangvubk/video-super-resolution" target="_blank">video-super-resolution</a></td>
<td style="text-align:center">Pytorch</td>
</tr>
</tbody>
</table>
<h2 id="datasets">Datasets</h2>
<p>Note this table is referenced from <a href="https://github.com/LoSealL/VideoSuperResolution#link-of-datasets" target="_blank">here</a>.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Name</th>
<th style="text-align:center">Usage</th>
<th style="text-align:center">Link</th>
<th style="text-align:center">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Set5</td>
<td style="text-align:center">Test</td>
<td style="text-align:center"><a href="https://uofi.box.com/shared/static/kfahv87nfe8ax910l85dksyl2q212voc.zip" target="_blank">download</a></td>
<td style="text-align:center"><a href="https://github.com/jbhuang0604/SelfExSR" target="_blank">jbhuang0604</a></td>
</tr>
<tr>
<td style="text-align:center">SET14</td>
<td style="text-align:center">Test</td>
<td style="text-align:center"><a href="https://uofi.box.com/shared/static/igsnfieh4lz68l926l8xbklwsnnk8we9.zip" target="_blank">download</a></td>
<td style="text-align:center"><a href="https://github.com/jbhuang0604/SelfExSR" target="_blank">jbhuang0604</a></td>
</tr>
<tr>
<td style="text-align:center">BSD100</td>
<td style="text-align:center">Test</td>
<td style="text-align:center"><a href="https://uofi.box.com/shared/static/qgctsplb8txrksm9to9x01zfa4m61ngq.zip" target="_blank">download</a></td>
<td style="text-align:center"><a href="https://github.com/jbhuang0604/SelfExSR" target="_blank">jbhuang0604</a></td>
</tr>
<tr>
<td style="text-align:center">Urban100</td>
<td style="text-align:center">Test</td>
<td style="text-align:center"><a href="https://uofi.box.com/shared/static/65upg43jjd0a4cwsiqgl6o6ixube6klm.zip" target="_blank">download</a></td>
<td style="text-align:center"><a href="https://github.com/jbhuang0604/SelfExSR" target="_blank">jbhuang0604</a></td>
</tr>
<tr>
<td style="text-align:center">Manga109</td>
<td style="text-align:center">Test</td>
<td style="text-align:center"><a href="http://www.manga109.org/ja/index.html" target="_blank">website</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">SunHay80</td>
<td style="text-align:center">Test</td>
<td style="text-align:center"><a href="https://uofi.box.com/shared/static/rirohj4773jl7ef752r330rtqw23djt8.zip" target="_blank">download</a></td>
<td style="text-align:center"><a href="https://github.com/jbhuang0604/SelfExSR" target="_blank">jbhuang0604</a></td>
</tr>
<tr>
<td style="text-align:center">BSD300</td>
<td style="text-align:center">Train/Val</td>
<td style="text-align:center"><a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300-images.tgz" target="_blank">download</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">BSD500</td>
<td style="text-align:center">Train/Val</td>
<td style="text-align:center"><a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz" target="_blank">download</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">91-Image</td>
<td style="text-align:center">Train</td>
<td style="text-align:center"><a href="http://www.ifp.illinois.edu/~jyang29/codes/ScSR.rar" target="_blank">download</a></td>
<td style="text-align:center">Yang</td>
</tr>
<tr>
<td style="text-align:center">DIV2K2017</td>
<td style="text-align:center">Train/Val</td>
<td style="text-align:center"><a href="https://data.vision.ee.ethz.ch/cvl/DIV2K/" target="_blank">website</a></td>
<td style="text-align:center">NTIRE2017</td>
</tr>
<tr>
<td style="text-align:center">Real SR</td>
<td style="text-align:center">Train/Val</td>
<td style="text-align:center"><a href="https://competitions.codalab.org/competitions/21439#participate" target="_blank">website</a></td>
<td style="text-align:center">NTIRE2019</td>
</tr>
<tr>
<td style="text-align:center">Waterloo</td>
<td style="text-align:center">Train</td>
<td style="text-align:center"><a href="https://ece.uwaterloo.ca/~k29ma/exploration/" target="_blank">website</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">VID4</td>
<td style="text-align:center">Test</td>
<td style="text-align:center"><a href="https://people.csail.mit.edu/celiu/CVPR2011/videoSR.zip" target="_blank">download</a></td>
<td style="text-align:center">4 videos</td>
</tr>
<tr>
<td style="text-align:center">MCL-V</td>
<td style="text-align:center">Train</td>
<td style="text-align:center"><a href="http://mcl.usc.edu/mcl-v-database/" target="_blank">website</a></td>
<td style="text-align:center">12 videos</td>
</tr>
<tr>
<td style="text-align:center">GOPRO</td>
<td style="text-align:center">Train/Val</td>
<td style="text-align:center"><a href="https://github.com/SeungjunNah/DeepDeblur_release" target="_blank">website</a></td>
<td style="text-align:center">33 videos, deblur</td>
</tr>
<tr>
<td style="text-align:center">CelebA</td>
<td style="text-align:center">Train</td>
<td style="text-align:center"><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank">website</a></td>
<td style="text-align:center">Human faces</td>
</tr>
<tr>
<td style="text-align:center">Sintel</td>
<td style="text-align:center">Train/Val</td>
<td style="text-align:center"><a href="http://sintel.is.tue.mpg.de/downloads" target="_blank">website</a></td>
<td style="text-align:center">Optical flow</td>
</tr>
<tr>
<td style="text-align:center">FlyingChairs</td>
<td style="text-align:center">Train</td>
<td style="text-align:center"><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html#flyingchairs" target="_blank">website</a></td>
<td style="text-align:center">Optical flow</td>
</tr>
<tr>
<td style="text-align:center">Vimeo-90k</td>
<td style="text-align:center">Train/Test</td>
<td style="text-align:center"><a href="http://toflow.csail.mit.edu/" target="_blank">website</a></td>
<td style="text-align:center">90k HQ videos</td>
</tr>
</tbody>
</table>
<h4 id="dataset-collections">Dataset collections</h4>
<p><a href="https://drive.google.com/drive/folders/1-99XFJs_fvQ2wFdxXrnJFcRRyPJYKN0K" target="_blank">Benckmark and DIV2K</a>: Set5, Set14, B100, Urban100, Manga109, DIV2K2017 include bicubic downsamples with x2,3,4,8</p>
<p><a href="https://www.kaggle.com/msahebi/super-resolution#SR_testing_datasets.zip" target="_blank">SR_testing_datasets</a>: Test: Set5, Set14, B100, Urban100, Manga109, Historical; Train: T91,General100, BSDS200</p>
<h2 id="paper">paper</h2>
<h3 id="non-dl-based-approach">Non-DL based approach</h3>
<p>SCSR: TIP2010, Jianchao Yang et al.<a href="https://ieeexplore.ieee.org/document/5466111/?arnumber=5466111" target="_blank">paper</a>, <a href="http://www.ifp.illinois.edu/~jyang29/" target="_blank">code</a></p>
<p>ANR: ICCV2013, Radu Timofte et al. <a href="http://www.vision.ee.ethz.ch/~timofter/publications/Timofte-ICCV-2013.pdf" target="_blank">paper</a>, <a href="http://www.vision.ee.ethz.ch/~timofter/ICCV2013_ID1774_SUPPLEMENTARY/index.html" target="_blank">code</a></p>
<p>A+: ACCV 2014, Radu Timofte et al. <a href="http://www.vision.ee.ethz.ch/~timofter/publications/Timofte-ACCV-2014.pdf" target="_blank">paper</a>, <a href="http://www.vision.ee.ethz.ch/~timofter/ACCV2014_ID820_SUPPLEMENTARY/" target="_blank">code</a></p>
<p>IA: CVPR2016, Radu Timofte et al. <a href="http://www.vision.ee.ethz.ch/~timofter/publications/Timofte-CVPR-2016.pdf" target="_blank">paper</a></p>
<p>SelfExSR: CVPR2015, Jia-Bin Huang et al. <a href="https://uofi.box.com/shared/static/8llt4ijgc39n3t7ftllx7fpaaqi3yau0.pdf" target="_blank">paper</a>, <a href="https://github.com/jbhuang0604/SelfExSR" target="_blank">code</a></p>
<p>NBSRF: ICCV2015, Jordi Salvador et al. <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Salvador_Naive_Bayes_Super-Resolution_ICCV_2015_paper.pdf" target="_blank">paper</a></p>
<p>RFL: ICCV2015, Samuel Schulter et al <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schulter_Fast_and_Accurate_2015_CVPR_paper.pdf" target="_blank">paper</a>, <a href="http://bbs.cvmart.net/articles/396" target="_blank">code</a></p>
<h3 id="dl-based-approach">DL based approach</h3>
<p>Note this table is referenced from <a href="https://github.com/LoSealL/VideoSuperResolution/blob/master/README.md#network-list-and-reference-updating" target="_blank">here</a></p>
<table>
<thead>
<tr>
<th style="text-align:left">Model</th>
<th style="text-align:left">Published</th>
<th style="text-align:left">Code</th>
<th style="text-align:left">Keywords</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">SRCNN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1501.00092" target="_blank">ECCV14</a></td>
<td style="text-align:left"><a href="https://github.com/qobilidop/srcnn" target="_blank">Keras</a></td>
<td style="text-align:left">Kaiming</td>
</tr>
<tr>
<td style="text-align:left">RAISR</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1606.01299" target="_blank">arXiv</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left">Google, Pixel 3</td>
</tr>
<tr>
<td style="text-align:left">ESPCN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1609.05158" target="_blank">CVPR16</a></td>
<td style="text-align:left"><a href="https://github.com/qobilidop/srcnn" target="_blank">Keras</a></td>
<td style="text-align:left">Real time/SISR/<strong>VideoSR</strong></td>
</tr>
<tr>
<td style="text-align:left">VDSR</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1511.04587" target="_blank">CVPR16</a></td>
<td style="text-align:left"><a href="http://cv.snu.ac.kr/research/VDSR/" target="_blank">Matlab</a></td>
<td style="text-align:left">Deep, Residual</td>
</tr>
<tr>
<td style="text-align:left">DRCN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1511.04491" target="_blank">CVPR16</a></td>
<td style="text-align:left"><a href="http://cv.snu.ac.kr/research/DRCN/" target="_blank">Matlab</a></td>
<td style="text-align:left">Recurrent</td>
</tr>
<tr>
<td style="text-align:left">DRRN</td>
<td style="text-align:left"><a href="http://cvlab.cse.msu.edu/pdfs/Tai_Yang_Liu_CVPR2017.pdf" target="_blank">CVPR17</a></td>
<td style="text-align:left"><a href="https://github.com/tyshiwo/DRRN_CVPR17" target="_blank">Caffe</a>, <a href="https://github.com/jt827859032/DRRN-pytorch" target="_blank">PyTorch</a></td>
<td style="text-align:left">Recurrent</td>
</tr>
<tr>
<td style="text-align:left">LapSRN</td>
<td style="text-align:left"><a href="http://vllab.ucmerced.edu/wlai24/LapSRN/" target="_blank">CVPR17</a></td>
<td style="text-align:left"><a href="https://github.com/phoenix104104/LapSRN" target="_blank">Matlab</a></td>
<td style="text-align:left">Huber loss</td>
</tr>
<tr>
<td style="text-align:left">IRCNN</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Learning_Deep_CNN_CVPR_2017_paper.pdf" target="_blank">CVPR17</a></td>
<td style="text-align:left"><a href="https://github.com/cszn/IRCNN" target="_blank">Matlab</a></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">EDSR</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1707.02921" target="_blank">CVPR17</a></td>
<td style="text-align:left"><a href="https://github.com/thstkdgus35/EDSR-PyTorch" target="_blank">PyTorch</a></td>
<td style="text-align:left">NTIRE17 Champion</td>
</tr>
<tr>
<td style="text-align:left">BTSRN</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Fan_Balanced_Two-Stage_Residual_CVPR_2017_paper.pdf" target="_blank">CVPR17</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left">NTIRE17</td>
</tr>
<tr>
<td style="text-align:left">SelNet</td>
<td style="text-align:left"><a href="https://ieeexplore.ieee.org/document/8014887" target="_blank">CVPR17</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left">NTIRE17</td>
</tr>
<tr>
<td style="text-align:left">TLSR</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Xu_Fast_and_Accurate_CVPR_2017_paper.pdf" target="_blank">CVPR17</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left">NTIRE17</td>
</tr>
<tr>
<td style="text-align:left">SRGAN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1609.04802" target="_blank">CVPR17</a></td>
<td style="text-align:left"><a href="https://github.com/tensorlayer/srgan" target="_blank">Tensorflow</a></td>
<td style="text-align:left">1st proposed GAN</td>
</tr>
<tr>
<td style="text-align:left">VESPCN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1611.05250" target="_blank">CVPR17</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left"><strong>VideoSR</strong></td>
</tr>
<tr>
<td style="text-align:left">MemNet</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1708.02209" target="_blank">ICCV17</a></td>
<td style="text-align:left"><a href="https://github.com/tyshiwo/MemNet" target="_blank">Caffe</a></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">SRDenseNet</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Tong_Image_Super-Resolution_Using_ICCV_2017_paper.pdf" target="_blank">ICCV17</a></td>
<td style="text-align:left">-, <a href="https://github.com/wxywhu/SRDenseNet-pytorch" target="_blank">PyTorch</a></td>
<td style="text-align:left">Dense</td>
</tr>
<tr>
<td style="text-align:left">SPMC</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1704.02738" target="_blank">ICCV17</a></td>
<td style="text-align:left"><a href="https://github.com/jiangsutx/SPMC_VideoSR" target="_blank">Tensorflow</a></td>
<td style="text-align:left"><strong>VideoSR</strong></td>
</tr>
<tr>
<td style="text-align:left">EnhanceNet</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1612.07919" target="_blank">ICCV17</a></td>
<td style="text-align:left"><a href="https://github.com/msmsajjadi/EnhanceNet-Code" target="_blank">TensorFlow</a></td>
<td style="text-align:left">Perceptual Loss</td>
</tr>
<tr>
<td style="text-align:left">PRSR</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Dahl_Pixel_Recursive_Super_ICCV_2017_paper.pdf" target="_blank">ICCV17</a></td>
<td style="text-align:left"><a href="https://github.com/nilboy/pixel-recursive-super-resolution" target="_blank">TensorFlow</a></td>
<td style="text-align:left">an extension of PixelCNN</td>
</tr>
<tr>
<td style="text-align:left">AffGAN</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1610.04490.pdf" target="_blank">ICLR17</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">MS-LapSRN</td>
<td style="text-align:left"><a href="https://ieeexplore.ieee.org/document/8434354" target="_blank">TPAMI18</a></td>
<td style="text-align:left"><a href="https://github.com/phoenix104104/LapSRN" target="_blank">Matlab</a></td>
<td style="text-align:left">Fast LapSRN</td>
</tr>
<tr>
<td style="text-align:left">DCSCN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1707.05425" target="_blank">arXiv</a></td>
<td style="text-align:left"><a href="https://github.com/jiny2001/dcscn-super-resolution" target="_blank">Tensorflow</a></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">IDN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1803.09454" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/Zheng222/IDN-Caffe" target="_blank">Caffe</a></td>
<td style="text-align:left">Fast</td>
</tr>
<tr>
<td style="text-align:left">DSRN</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Han_Image_Super-Resolution_via_CVPR_2018_paper.pdf" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/WeiHan3/dsrn/tree/db21d57dfab57de3608f0372e749c6488b6b305d" target="_blank">TensorFlow</a></td>
<td style="text-align:left">Dual state&#xFF0C;Recurrent</td>
</tr>
<tr>
<td style="text-align:left">RDN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1802.08797" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/yulunzhang/RDN" target="_blank">Torch</a></td>
<td style="text-align:left">Deep, BI-BD-DN</td>
</tr>
<tr>
<td style="text-align:left">SRMD</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1712.06116" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/cszn/SRMD" target="_blank">Matlab</a></td>
<td style="text-align:left">Denoise/Deblur/SR</td>
</tr>
<tr>
<td style="text-align:left">DBPN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1803.02735" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/alterzero/DBPN-Pytorch" target="_blank">PyTorch</a></td>
<td style="text-align:left">NTIRE18 Champion</td>
</tr>
<tr>
<td style="text-align:left">WDSR</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1808.08718" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/JiahuiYu/wdsr_ntire2018" target="_blank">PyTorch</a>&#xFF0C;<a href="https://github.com/ychfan/tf_estimator_barebone/blob/master/docs/super_resolution.md" target="_blank">TensorFlow</a></td>
<td style="text-align:left">NTIRE18 Champion</td>
</tr>
<tr>
<td style="text-align:left">ProSRN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1804.02900" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/fperazzi/proSR" target="_blank">PyTorch</a></td>
<td style="text-align:left">NTIRE18</td>
</tr>
<tr>
<td style="text-align:left">ZSSR</td>
<td style="text-align:left"><a href="http://www.wisdom.weizmann.ac.il/~vision/zssr/" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/assafshocher/ZSSR" target="_blank">Tensorflow</a></td>
<td style="text-align:left">Zero-shot</td>
</tr>
<tr>
<td style="text-align:left">FRVSR</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1801.04590" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/msmsajjadi/FRVSR" target="_blank">PDF</a></td>
<td style="text-align:left"><strong>VideoSR</strong></td>
</tr>
<tr>
<td style="text-align:left">DUF</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.pdf" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/yhjo09/VSR-DUF" target="_blank">Tensorflow</a></td>
<td style="text-align:left"><strong>VideoSR</strong></td>
</tr>
<tr>
<td style="text-align:left">TDAN</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1812.02898.pdf" target="_blank">arXiv</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left"><strong>VideoSR</strong>&#xFF0C;Deformable Align</td>
</tr>
<tr>
<td style="text-align:left">SFTGAN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1804.02815" target="_blank">CVPR18</a></td>
<td style="text-align:left"><a href="https://github.com/xinntao/SFTGAN" target="_blank">PyTorch</a></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">CARN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1803.08664" target="_blank">ECCV18</a></td>
<td style="text-align:left"><a href="https://github.com/nmhkahn/CARN-pytorch" target="_blank">PyTorch</a></td>
<td style="text-align:left">Lightweight</td>
</tr>
<tr>
<td style="text-align:left">RCAN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1807.02758" target="_blank">ECCV18</a></td>
<td style="text-align:left"><a href="https://github.com/yulunzhang/RCAN" target="_blank">PyTorch</a></td>
<td style="text-align:left">Deep, BI-BD-DN</td>
</tr>
<tr>
<td style="text-align:left">MSRN</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Juncheng_Li_Multi-scale_Residual_Network_ECCV_2018_paper.pdf" target="_blank">ECCV18</a></td>
<td style="text-align:left"><a href="https://github.com/MIVRC/MSRN-PyTorch" target="_blank">PyTorch</a></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">SRFeat</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Seong-Jin_Park_SRFeat_Single_Image_ECCV_2018_paper.pdf" target="_blank">ECCV18</a></td>
<td style="text-align:left"><a href="https://github.com/HyeongseokSon1/SRFeat" target="_blank">Tensorflow</a></td>
<td style="text-align:left">GAN</td>
</tr>
<tr>
<td style="text-align:left">ESRGAN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1809.00219" target="_blank">ECCV18</a></td>
<td style="text-align:left"><a href="https://github.com/xinntao/ESRGAN" target="_blank">PyTorch</a></td>
<td style="text-align:left">PRIM18 region 3 Champion</td>
</tr>
<tr>
<td style="text-align:left">FEQE</td>
<td style="text-align:left"><a href="http://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Vu_Fast_and_Efficient_Image_Quality_Enhancement_via_Desubpixel_Convolutional_Neural_ECCVW_2018_paper.pdf" target="_blank">ECCV18</a></td>
<td style="text-align:left"><a href="https://github.com/thangvubk/FEQE" target="_blank">Tensorflow</a></td>
<td style="text-align:left">Fast</td>
</tr>
<tr>
<td style="text-align:left">NLRN</td>
<td style="text-align:left"><a href="https://papers.nips.cc/paper/7439-non-local-recurrent-network-for-image-restoration.pdf" target="_blank">NIPS18</a></td>
<td style="text-align:left"><a href="https://github.com/Ding-Liu/NLRN" target="_blank">Tensorflow</a></td>
<td style="text-align:left">Non-local, Recurrent</td>
</tr>
<tr>
<td style="text-align:left">SRCliqueNet</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1809.04508" target="_blank">NIPS18</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left">Wavelet</td>
</tr>
<tr>
<td style="text-align:left">CBDNet</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1807.04686" target="_blank">arXiv</a></td>
<td style="text-align:left"><a href="https://github.com/GuoShi28/CBDNet" target="_blank">Matlab</a></td>
<td style="text-align:left">Blind-denoise</td>
</tr>
<tr>
<td style="text-align:left">TecoGAN</td>
<td style="text-align:left"><a href="http://arxiv.org/abs/1811.09393" target="_blank">arXiv</a></td>
<td style="text-align:left"><a href="https://github.com/thunil/TecoGAN" target="_blank">Tensorflow</a></td>
<td style="text-align:left"><strong>VideoSR</strong> GAN</td>
</tr>
<tr>
<td style="text-align:left">RBPN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1903.10128" target="_blank">CVPR19</a></td>
<td style="text-align:left"><a href="https://github.com/alterzero/RBPN-PyTorch" target="_blank">PyTorch</a></td>
<td style="text-align:left"><strong>VideoSR</strong></td>
</tr>
<tr>
<td style="text-align:left">SRFBN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1903.09814" target="_blank">CVPR19</a></td>
<td style="text-align:left"><a href="https://github.com/Paper99/SRFBN_CVPR19" target="_blank">PyTorch</a></td>
<td style="text-align:left">Feedback</td>
</tr>
<tr>
<td style="text-align:left">MoreMNAS</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1901.01074.pdf" target="_blank">arXiv</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left">Lightweight&#xFF0C;NAS</td>
</tr>
<tr>
<td style="text-align:left">FALSR</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1901.07261.pdf" target="_blank">arXiv</a></td>
<td style="text-align:left"><a href="https://ieeexplore.ieee.org/document/8434354" target="_blank">TensorFlow</a></td>
<td style="text-align:left">Lightweight&#xFF0C;NAS</td>
</tr>
<tr>
<td style="text-align:left">Meta-SR</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1903.00875.pdf" target="_blank">arXiv</a></td>
<td style="text-align:left"></td>
<td style="text-align:left">Arbitrary Magnification</td>
</tr>
<tr>
<td style="text-align:left">AWSRN</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1904.02358" target="_blank">arXiv</a></td>
<td style="text-align:left"><a href="https://github.com/ChaofWang/AWSRN" target="_blank">PyTorch</a></td>
<td style="text-align:left">Lightweight</td>
</tr>
<tr>
<td style="text-align:left">OISR</td>
<td style="text-align:left">CVPR19</td>
<td style="text-align:left"><a href="https://github.com/HolmesShuan/OISR-PyTorch" target="_blank">PyTorch</a></td>
<td style="text-align:left">ODE-inspired Network</td>
</tr>
<tr>
<td style="text-align:left">DPSR</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1903.12529.pdf" target="_blank">CVPR19</a></td>
<td style="text-align:left"><a href="https://github.com/cszn/DPSR" target="_blank">PyTorch</a></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">DNI</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1811.10515.pdf" target="_blank">CVPR19</a></td>
<td style="text-align:left"><a href="https://github.com/xinntao/DNI" target="_blank">PyTorch</a></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">MAANet</td>
<td style="text-align:left"><a href="https://arxiv.org/abs/1904.06252" target="_blank">arXiv</a></td>
<td style="text-align:left"></td>
<td style="text-align:left">Multi-view Aware Attention</td>
</tr>
<tr>
<td style="text-align:left">RNAN</td>
<td style="text-align:left"><a href="https://openreview.net/pdf?id=HkeGhoA5FX" target="_blank">ICLR19</a></td>
<td style="text-align:left"><a href="https://github.com/yulunzhang/RNAN" target="_blank">PyTorch</a></td>
<td style="text-align:left">Residual Non-local Attention</td>
</tr>
<tr>
<td style="text-align:left">FSTRN</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1904.02870.pdf" target="_blank">CVPR19</a></td>
<td style="text-align:left">-</td>
<td style="text-align:left"><strong>VideoSR</strong>, fast spatio-temporal residual block</td>
</tr>
<tr>
<td style="text-align:left">MsDNN</td>
<td style="text-align:left"><a href="https://arxiv.org/pdf/1904.10698.pdf" target="_blank">arXiv</a></td>
<td style="text-align:left"><a href="https://github.com/shangqigao/gsq-image-SR" target="_blank">TensorFlow</a></td>
<td style="text-align:left">NTIRE19 real SR 21th place</td>
</tr>
</tbody>
</table>
<h4 id="super-resolution-survey&#xFF1A;">Super Resolution survey&#xFF1A;</h4>
<p>[1] Wenming Yang, Xuechen Zhang, Yapeng Tian, Wei Wang, Jing-Hao Xue. Deep Learning for Single Image Super-Resolution: A Brief Review. arxiv, 2018. <a href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">paper</a></p>
<p>[2]Saeed Anwar, Salman Khan, Nick Barnes. A Deep Journey into Super-resolution: A survey. arxiv, 2019.<a href="https://arxiv.org/pdf/1904.07523.pdf" target="_blank">paper</a></p>
<hr>
<h1 id="super-resolutionbenckmark">Super-Resolution.Benckmark</h1>
<p>A curated list of super-resolution resources and a benchmark for single image super-resolution algorithms.</p>
<p>See my implementated super-resolution algorithms:</p>
<ul>
<li><a href="https://github.com/huangzehao/torch-srgan" target="_blank">SRGAN</a></li>
<li><a href="https://github.com/huangzehao/caffe-vdsr" target="_blank">VDSR</a></li>
<li><a href="https://github.com/huangzehao/SCN_Matlab" target="_blank">CSCN</a></li>
</ul>
<h2 id="todo">TODO</h2>
<p>Build a benckmark like <a href="https://sites.google.com/site/jbhuang0604/publications/struct_sr" target="_blank">SelfExSR_Code</a></p>
<h2 id="state-of-the-art-algorithms">State-of-the-art algorithms</h2>
<h4 id="classical-sparse-coding-method">Classical Sparse Coding Method</h4>
<ul>
<li>ScSR <a href="http://www.ifp.illinois.edu/~jyang29/ScSR.htm" target="_blank">[Web]</a></li>
<li>Image super-resolution as sparse representation of raw image patches (CVPR2008), Jianchao Yang et al.</li>
<li>Image super-resolution via sparse representation (TIP2010), Jianchao Yang et al.</li>
<li>Coupled dictionary training for image super-resolution (TIP2011), Jianchao Yang et al.</li>
</ul>
<h4 id="anchored-neighborhood-regression-method">Anchored Neighborhood Regression Method</h4>
<ul>
<li>ANR <a href="http://www.vision.ee.ethz.ch/~timofter/ICCV2013_ID1774_SUPPLEMENTARY/index.html" target="_blank">[Web]</a></li>
<li>Anchored Neighborhood Regression for Fast Example-Based Super-Resolution (ICCV2013), Radu Timofte et al.</li>
<li>A+ <a href="http://www.vision.ee.ethz.ch/~timofter/ACCV2014_ID820_SUPPLEMENTARY/" target="_blank">[Web]</a></li>
<li>A+: Adjusted Anchored Neighborhood Regression for Fast Super-Resolution (ACCV2014), Radu Timofte et al.</li>
<li>IA <a href="http://www.vision.ee.ethz.ch/~timofter/CVPR2016_ID769_SUPPLEMENTARY/index.html" target="_blank">[Web]</a></li>
<li>Seven ways to improve example-based single image super resolution (CVPR2016), Radu Timofte et al.</li>
</ul>
<h4 id="self-exemplars">Self-Exemplars</h4>
<ul>
<li>SelfExSR <a href="https://sites.google.com/site/jbhuang0604/publications/struct_sr" target="_blank">[Web]</a></li>
<li>Single Image Super-Resolution from Transformed Self-Exemplars (CVPR2015), Jia-Bin Huang et al.</li>
</ul>
<h4 id="bayes">Bayes</h4>
<ul>
<li>NBSRF <a href="http://jordisalvador-image.blogspot.com/2015/08/iccv-2015.html" target="_blank">[Web]</a></li>
<li>Naive Bayes Super-Resolution Forest (ICCV2015), Jordi Salvador et al.</li>
</ul>
<h4 id="deep-learning-method">Deep Learning Method</h4>
<ul>
<li>SRCNN <a href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html" target="_blank">[Web]</a> <a href="https://github.com/nagadomi/waifu2x" target="_blank">[waifu2x by nagadomi]</a></li>
<li>Image Super-Resolution Using Deep Convolutional Networks (ECCV2014), Chao Dong et al.</li>
<li>Image Super-Resolution Using Deep Convolutional Networks (TPAMI2015), Chao Dong et al.</li>
<li>CSCN <a href="http://www.ifp.illinois.edu/~dingliu2/iccv15/" target="_blank">[Web]</a></li>
<li>Deep Networks for Image Super-Resolution with Sparse Prior (ICCV2015), Zhaowen Wang et al.</li>
<li>Robust Single Image Super-Resolution via Deep Networks with Sparse Prior (TIP2016), Ding Liu et al.</li>
<li>VDSR <a href="http://cv.snu.ac.kr/research/VDSR/" target="_blank">[Web]</a> <a href="https://github.com/huangzehao/caffe-vdsr" target="_blank">[Unofficial Implementation in Caffe]</a></li>
<li>Accurate Image Super-Resolution Using Very Deep Convolutional Networks (CVPR2016), Jiwon Kim et al.</li>
<li>DRCN <a href="http://cv.snu.ac.kr/research/DRCN/" target="_blank">[Web]</a></li>
<li>Deeply-Recursive Convolutional Network for Image Super-Resolution (CVPR2016), Jiwon Kim et al.</li>
<li>ESPCN <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shi_Real-Time_Single_Image_CVPR_2016_paper.pdf" target="_blank">[PDF]</a></li>
<li>Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network (CVPR2016), Wenzhe Shi et al.</li>
<li>Is the deconvolution layer the same as a convolutional layer? <a href="https://arxiv.org/ftp/arxiv/papers/1609/1609.07009.pdf" target="_blank">[PDF]</a></li>
<li>Checkerboard artifact free sub-pixel convolution <a href="https://arxiv.org/pdf/1707.02937.pdf" target="_blank">[PDF]</a></li>
<li>FSRCNN <a href="http://mmlab.ie.cuhk.edu.hk/projects/FSRCNN.html" target="_blank">[Web]</a></li>
<li>Acclerating the Super-Resolution Convolutional Neural Network (ECCV2016), Dong Chao et al.</li>
<li>LapSRN <a href="http://vllab1.ucmerced.edu/~wlai24/LapSRN/" target="_blank">[Web]</a></li>
<li>Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution (CVPR 2017), Wei-Sheng Lai et al.</li>
<li>EDSR <a href="https://arxiv.org/pdf/1707.02921.pdf" target="_blank">[PDF]</a></li>
<li>Enhanced Deep Residual Networks for Single Image Super-Resolution (Winner of NTIRE2017 Super-Resolution Challenge), Bee Lim et al.</li>
</ul>
<h4 id="perceptual-loss-and-gan">Perceptual Loss and GAN</h4>
<ul>
<li>Perceptual Loss <a href="http://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16.pdf" target="_blank">[PDF]</a></li>
<li>Perceptual Losses for Real-Time Style Transfer and Super-Resolution (ECCV2016), Justin Johnson et al.</li>
<li>SRGAN <a href="https://arxiv.org/abs/1609.04802" target="_blank">[PDF]</a></li>
<li>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (CVPR2017), Christian Ledig et al.</li>
<li>AffGAN <a href="https://arxiv.org/pdf/1610.04490.pdf" target="_blank">[PDF]</a></li>
<li>AMORTISED MAP INFERENCE FOR IMAGE SUPER-RESOLUTION (ICLR2017), Casper Kaae S&#xF8;nderby et al.</li>
<li>EnhanceNet <a href="https://arxiv.org/abs/1612.07919" target="_blank">[PDF]</a></li>
<li>EnhanceNet: Single Image Super-Resolution through Automated Texture Synthesis, Mehdi S. M. Sajjadi et al.</li>
<li>neural-enchance <a href="https://github.com/alexjc/neural-enhance" target="_blank">[Github]</a></li>
</ul>
<h4 id="video-sr">Video SR</h4>
<ul>
<li>VESPCN <a href="https://arxiv.org/pdf/1611.05250.pdf" target="_blank">[PDF]</a></li>
<li>Real-Time Video Super-Resolution with Spatio-Temporal Networks and Motion Compensation (CVPR2017), Jose Caballero et al.</li>
</ul>
<h2 id="dicussion">Dicussion</h2>
<h4 id="deconvolution-and-sub-pixel-convolution">Deconvolution and Sub-Pixel Convolution</h4>
<ul>
<li><a href="http://distill.pub/2016/deconv-checkerboard/" target="_blank">Deconvolution and Checkerboard Artifacts</a></li>
<li><a href="https://github.com/Tetrachrome/subpixel" target="_blank">SubPixel</a></li>
</ul>
<h2 id="datasets">Datasets</h2>
<table>
<thead>
<tr>
<th>Test Dataset</th>
<th>Image source</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Set 5</strong></td>
<td><a href="http://people.rennes.inria.fr/Aline.Roumy/results/SR_BMVC12.html" target="_blank">Bevilacqua et al. BMVC 2012</a></td>
</tr>
<tr>
<td><strong>Set 14</strong></td>
<td><a href="https://sites.google.com/site/romanzeyde/research-interests" target="_blank">Zeyde et al. LNCS 2010</a></td>
</tr>
<tr>
<td><strong>BSD 100</strong></td>
<td><a href="https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/" target="_blank">Martin et al. ICCV 2001</a></td>
</tr>
<tr>
<td><strong>Urban 100</strong></td>
<td><a href="https://sites.google.com/site/jbhuang0604/publications/struct_sr" target="_blank">Huang et al. CVPR 2015</a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Train Dataset</th>
<th>Image source</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Yang 91</strong></td>
<td><a href="http://www.ifp.illinois.edu/~jyang29/ScSR.htm" target="_blank">Yang et al. CVPR 2008</a></td>
</tr>
<tr>
<td><strong>BSD 200</strong></td>
<td><a href="https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/" target="_blank">Martin et al. ICCV 2001</a></td>
</tr>
<tr>
<td><strong>General 100</strong></td>
<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/FSRCNN.html" target="_blank">Dong et al. ECCV 2016</a></td>
</tr>
<tr>
<td><strong>ImageNet</strong></td>
<td><a href="http://www.image-net.org/" target="_blank">Olga Russakovsky et al. IJCV 2015</a></td>
</tr>
<tr>
<td><strong>COCO</strong></td>
<td><a href="http://mscoco.org/" target="_blank">Tsung-Yi Lin et al. ECCV 2014</a></td>
</tr>
</tbody>
</table>
<h2 id="quantitative-comparisons">Quantitative comparisons</h2>
<p>Results from papers of VDSR, DRCN, CSCN and IA.</p>
<p><strong>Note:</strong> IA use enchanced prediction trick to improve result.</p>
<h5 id="results-on-set-5">Results on Set 5</h5>
<table>
<thead>
<tr>
<th>Scale</th>
<th>Bicubic</th>
<th>A+</th>
<th>SRCNN</th>
<th>SelfExSR</th>
<th>CSCN</th>
<th>VDSR</th>
<th>DRCN</th>
<th>IA</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>2x</strong> - PSNR/SSIM</td>
<td>33.66/0.9929</td>
<td>36.54/0.9544</td>
<td>36.66/0.9542</td>
<td>36.49/0.9537</td>
<td>36.93/0.9552</td>
<td>37.53/0.9587</td>
<td>37.63/0.9588</td>
<td>37.39/</td>
</tr>
<tr>
<td><strong>3x</strong> - PSNR/SSIM</td>
<td>30.39/0.8682</td>
<td>32.59/0.9088</td>
<td>32.75/0.9090</td>
<td>32.58/0.9093</td>
<td>33.10/0.9144</td>
<td>33.66/0.9213</td>
<td>33.82/0.9226</td>
<td>33.46/</td>
</tr>
<tr>
<td><strong>4x</strong> - PSNR/SSIM</td>
<td>28.42/0.8104</td>
<td>30.28/0.8603</td>
<td>30.48/0.8628</td>
<td>30.31/0.8619</td>
<td>30.86/0.8732</td>
<td>31.35/0.8838</td>
<td>31.53/0.8854</td>
<td>31.10/</td>
</tr>
</tbody>
</table>
<h5 id="results-on-set-14">Results on Set 14</h5>
<table>
<thead>
<tr>
<th>Scale</th>
<th>Bicubic</th>
<th>A+</th>
<th>SRCNN</th>
<th>SelfExSR</th>
<th>CSCN</th>
<th>VDSR</th>
<th>DRCN</th>
<th>IA</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>2x</strong> - PSNR/SSIM</td>
<td>30.24/0.8688</td>
<td>32.28/0.9056</td>
<td>32.42/0.9063</td>
<td>32.22/0.9034</td>
<td>32.56/0.9074</td>
<td>33.03/0.9124</td>
<td>33.04/0.9118</td>
<td>32.87/</td>
</tr>
<tr>
<td><strong>3x</strong> - PSNR/SSIM</td>
<td>27.55/0.7742</td>
<td>29.13/0.8188</td>
<td>29.28/0.8209</td>
<td>29.16/0.8196</td>
<td>29.41/0.8238</td>
<td>29.77/0.8314</td>
<td>29.76/0.8311</td>
<td>29.69/</td>
</tr>
<tr>
<td><strong>4x</strong> - PSNR/SSIM</td>
<td>26.00/0.7027</td>
<td>27.32/0.7491</td>
<td>27.49/0.7503</td>
<td>27.40/0.7518</td>
<td>27.64/0.7587</td>
<td>28.01/0.7674</td>
<td>28.02/0.7670</td>
<td>27.88/</td>
</tr>
</tbody>
</table>
<h5 id="results-on-bsd-100">Results on BSD 100</h5>
<table>
<thead>
<tr>
<th>Scale</th>
<th>Bicubic</th>
<th>A+</th>
<th>SRCNN</th>
<th>SelfExSR</th>
<th>CSCN</th>
<th>VDSR</th>
<th>DRCN</th>
<th>IA</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>2x</strong> - PSNR/SSIM</td>
<td>29.56/0.8431</td>
<td>31.21/0.8863</td>
<td>31.36/0.8879</td>
<td>31.18/0.8855</td>
<td>31.40/0.8884</td>
<td>31.90/0.8960</td>
<td>31.85/0.8942</td>
<td>31.79/</td>
</tr>
<tr>
<td><strong>3x</strong> - PSNR/SSIM</td>
<td>27.21/0.7385</td>
<td>28.29/0.7835</td>
<td>28.41/0.7863</td>
<td>28.29/0.7840</td>
<td>28.50/0.7885</td>
<td>28.82/0.7976</td>
<td>28.80/0.7963</td>
<td>28.76/</td>
</tr>
<tr>
<td><strong>4x</strong> - PSNR/SSIM</td>
<td>25.96/0.6675</td>
<td>26.82/0.7087</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="SR.html" class="navigation navigation-prev " aria-label="Previous page: 超分辨率技术">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="baseline.html" class="navigation navigation-next " aria-label="Next page: 超分辨率baseline">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"超分辨率代码数据集合集","level":"1.7.3","depth":2,"next":{"title":"超分辨率baseline","level":"1.7.4","depth":2,"path":"super_resolution/baseline.md","ref":"super_resolution/baseline.md","articles":[]},"previous":{"title":"超分辨率技术","level":"1.7.2","depth":2,"path":"super_resolution/SR.md","ref":"super_resolution/SR.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-search","search-pro","back-to-top-button","expandable-chapters-small","back-to-top-button","chapter-fold","expandable-chapters-small","github","katex","include-codeblock","livereload"],"root":"./content","styles":{"website":"assets/styles/website.less","ebook":"assets/styles/ebook.less","pdf":"assets/styles/pdf.less","mobi":"assets/styles/mobi.less","epub":"assets/styles/epub.less"},"pluginsConfig":{"chapter-fold":{},"prism":{"css":["prismjs/themes/prism-solarizedlight.css"],"lang":{"flow":"typescript"}},"github":{"url":"https://github.com/OUCMachineLearning/OUCML"},"livereload":{},"search-pro":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"katex":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"expandable-chapters-small":{},"include-codeblock":{"check":false,"edit":false,"fixlang":false,"lang":"","template":"default","theme":"chrome","unindent":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"language":"zh-hans","gitbook":"*"},"file":{"path":"super_resolution/code_dataset.md","mtime":"2019-10-24T04:35:18.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-10-25T10:54:29.358Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

