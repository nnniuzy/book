## 基于深度学习的超分辨率图像技术一览

> 近年来，使用深度学习技术的图像超分辨率（SR）取得了显着进步。一般可以将现有的SR技术研究大致分为三大类：监督SR，无监督SR和特定领域SR（人脸）。

# 先说监督SR



如今已经有各种深度学习的超分辨率模型。这些模型依赖于有监督的超分辨率，即用LR图像和相应的基础事实（GT）HR图像训练。虽然这些模型之间的差异非常大，但它们本质上是一组组件的组合，例如模型框架，上采样方法，网络设计和学习策略等。从这个角度来看，研究人员将这些组件组合起来构建一个用于拟合特定任务的集成SR模型。



由于图像超分辨率是一个病态问题，如何进行上采样（即从低分辨率产生高分辨率）是关键问题。基于采用的上采样操作及其在模型中的位置，SR模型可归因于四种模型框架：预先采样SR，后上采样SR，渐进上采样SR和迭代上下采样SR，如图所示。

![img](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-10-02-111013.jpg)

![img](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-10-02-111012.jpg)

除了在模型中的位置之外，上采样操作如何实现它们也非常重要。为了克服插值法的缺点，并以端到端的方式学习上采样操作，转置卷积层（Transposed Convolution Layer）和亚像素层（Sub-pixel Layer）可以引入到超分辨率中。



转置卷积层，即反卷积层，基于尺寸类似于卷积层输出的特征图来预测可能的输入。具体地说，它通过插入零值并执行卷积来扩展图像，从而提高了图像分辨率。为了简洁起见，以3×3内核执行2次上采样为例，如图所示。首先，输入扩展到原始大小的两倍，其中新添加的像素值被设置为0（b）。然后应用大小为3×3、步长1和填充1的内核卷积（c）。这样输入特征图实现因子为2的上采样，而感受野最多为2×2。



![img](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-10-02-111020.jpg)

由于转置卷积层可以以端到端的方式放大图像大小，同时保持与vanilla卷积兼容的连接模式，因此它被广泛用作SR模型的上采样层。然而，它很容易在每个轴上产生“不均匀重叠（uneven overlapping）”，并且在两个轴的乘法进一步产生了特有的不同幅度棋盘状图案，从而损害了SR性能。



亚像素层也是端到端学习的上采样层，通过卷积生成多个通道然后重新整形，如图所示。首先卷积产生具有s2倍通道的输出，其中s是上采样因子（b）。假设输入大小为h×w×c，则输出大小为h×w×s2c。之后，执行整形（shuffle）操作产生大小为sh×sw×c的输出（c）。感受野大小可以达到3×3。

![img](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-10-02-111021.jpg)

由于端到端的上采样方式，亚像素层也被SR模型广泛使用。与转置卷积层相比，亚像素层的最大优势是具有较大的感知场，提供更多的上下文信息，能帮助生成更准确的细节。然而，亚像素层的感受野的分布是不均匀的，块状区域实际上共享相同的感受野，这可能导致在块边界附近的一些畸变。



各种深度学习的模型已经被用于SR，如图所示。

![img](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-10-02-111015.jpg)

ResNet学习残差而不是彻底的映射，已被SR模型广泛采用，如上图（a）所示。其中，残差学习策略可以大致分为两种类型，即全局和局部残差学习。



由于超分辨率是图像到图像的转换任务，其中输入图像与目标图像高度相关，全局残差学习仅学习两个图像之间的残差。在这种情况下，它避免学习从完整图像到另一个图像的复杂转换，而只需要学习残差图来恢复丢失的高频细节。由于大多数区域残差接近于零，模型的复杂性和学习难度都大大降低。这种方法在预上采样的SR框架普遍采用。



**局部残差学习**类似于ResNet的残差学习，用于缓解不断增加的网络深度引起的退化问题并提高学习能力。



实践中，上述方法都是通过快捷连接（通常有小常数因子的缩放）和逐元素加法操作实现的。区别在于，前者直接连接输入图像和输出图像，而后者通常在不同深度的网络中层之间添加多个快捷方式。



**• 递归学习**



递归学习（以递归方式多次应用相同模块）也被超分辨率采用，如上图 （b）所示。在实践中，递归学习固有地带来了消失（vanishing）或爆涨（exploding）梯度问题，因此残差学习和多信号监督等一些技术通常与递归学习相结合，以减轻这些问题。



**• 通道关注**



考虑到不同通道之间特征表征的相互依赖和作用，一种“挤压-激发（SAE，squeeze-and-excitation）”模块明确对通道相互依赖性建模，来提高表示能力，如上图（c）所示。其中用全局平均池化将每个输入通道压缩到通道描述子（即一个常数）中，然后将这些描述子馈送到两个全连接层产生通道尺度因子。基于通道乘法，用尺度因子重新缩放输入通道得到最终输出。



**• 致密连接**



致密连接在视觉任务中变得越来越流行。在致密块的每个层，所有前层的特征图用作输入，并且其自身特征图用作所有后续层的输入，在一个有l层致密块中带来l·（l - 1）/ 2个连接。致密连接，不仅有助于缓解梯度消失问题、增强信号的传播并促进特征重用，而且在连接之后采用小增长率（即致密块的通道数）和通道缩减来大大减少参数量。





为了融合低级和高级特征以提供更丰富的信息来重建高质量的细节，致密连接被引入SR领域，如上图（d）所示。



**• 多路径学习**



多路径学习指模型存在多个路径传递特征，这些路径执行不同的操作以提供更好的建模功能。具体而言，它可以分为三种类型：全局法、局部法和特定尺度法。



全局多路径学习是指用多个路径提取图像不同方面的特征。这些路径可以在传播中相互交叉，从而大大增强了特征提取的能力。



**本地多路径学习**用新块进行多尺度特征提取，如上图（e）所示。该块采用不同内核大小的卷积同时提取特征，然后将输出连接起来并再次进行相同的操作。快捷方式通过逐元素添加来连接该块的输出和输入。通过这种局部多路径学习，SR模型可以更好地从多个尺度提取图像特征，进一步提高性能。



**特定尺度多路径学习**共享模型的主要部分（即特征提取的中间部分），并分别在网络的开头和结尾附加特定尺度的预处理路径和上采样路径，如上图（f）所示。在训练期间，仅启用和更新与所选尺度对应的路径。这样大多数参数在不同尺度上共享。



**• 高级卷积**



卷积运算是深度神经网络的基础，改进卷积运算可获得更好的性能或更快的速度。这里给出两个方法：扩张卷积（Dilated Convolution）和群卷积（Group Convolution）。众所周知，上下文信息有助于在图像超分辨率生成逼真的细节。扩张卷积能将感受野增加两倍，最终实现更好的性能。群卷积以很少的性能损失可减少大量的参数和操作，如上图（g）所示。



**• 像素递归学习**



大多数SR模型认为这是一个与像素无关的任务，因此无法正确地确定生成像素之间的相互依赖性。在人注意力转移机制推动下，一种递推网络可依次发现参与的补丁并进行局部增强。以这种方式，模型能够根据每个图像自身特性自适应地个性化最佳搜索路径，从而充分利用图像全局的内依赖性（intra-dependence）。不过，需要长传播路径的递归过程，特别对超分辨率的HR图像，大大增加了计算成本和训练难度。



• **金字塔池化**



金字塔池化模块更好地利用全局和局部的上下文信息，如上图（h）所示。具体地，对于尺寸为h×w×c的特征图，每个特征图被划分为M×M个区间，并经历全局平均池化产生M×M×c个输出。然后，执行1×1卷积输出压缩到一个单信道。之后，通过双线性插值将低维特征图上采样到与原始特征图相同的大小。使用不同的M，该模块可以有效地整合全局和局部的上下文信息。



**• 小波变换**



众所周知，小波变换（WT）是一种高效的图像表示，将图像信号分解为表示纹理细节的高频小波和包含全局拓扑信息的低频小波。将WT与基于深度学习的SR模型相结合，这样插值LR小波的子带作为输入，并预测相应HR子带的残差。WT和逆WT分别用于分解LR输入和重建HR输出。



另外学习策略问题，涉及损失函数的设计（包括像素损失，内容损失，纹理损失，对抗损失和周期连续损失）、批处理归一化（BN）、课程学习（Curriculum Learning）和多信号监督（Multi-supervision）等等。



# 再说无监督SR



现有的超分辨率工作主要集中在监督学习上，然而难以收集不同分辨率的相同场景的图像，因此通常通过对HR图像预定义退化来获得SR数据集中的LR图像。为了防止预定义退化带来的不利影响，无监督的超分辨率成为选择。在这种情况下，只提供非配对图像（HR或LR）用于训练，实际上得到的模型更可能应对实际场景中的SR问题。



**• 零击（zero shot）超分辨率**



单个图像内部的统计数据足以提供超分辨率所需的信息，所以零击超分辨率（ZSSR）在测试时训练小图像特定的SR网络进行无监督SR，而不是在大数据集上训练通用模型。具体来说，核估计方法直接从单个测试图像估计退化内核，并在测试图像上执行不同尺度因子的退化来构建小数据集。然后在该数据集上训练超分辨率的小CNN模型用于最终预测。



ZSSR利用图像内部特定信息的跨尺度复现这一特点，对非理想条件下（非bi-cubic退化核获得的图像，受模糊、噪声和压缩畸变等影响）更接近现实世界场景的图像，比以前的方法性能提高一大截，同时在理想条件下（bi-cubic插值构建的图像），和以前方法结果差不多。尽管这样，由于需要在测试期间为每个图像训练单个网络，使得其测试时间远比其他SR模型长。



**• 弱监督SR**



为了在超分辨率中不引入预退化，弱监督学习的SR模型，即使用不成对的LR-HR图像，是一种方案。一些方法学习HR-LR退化模型并用于构建训练SR模型的数据集，而另外一些方法设计周期循环（cycle-in-cycle）网络同时学习LR-HR和HR-LR映射。



由于预退化是次优的，从未配对的LR-HR数据集中学习退化是可行的。一种方法称为“两步法”：



- 1）训练HR-LR 的GAN模型，用不成对的LR-HR图像学习退化；
- 2）基于第一个GAN模型，使用成对的LR-HR图像训练LR- HR 的GAN模型执行SR。



对于HR到LR 的GAN模型，HR图像被馈送到生成器产生LR输出，不仅需要匹配HR图像缩小（平均池化）获得的LR图像，而且还要匹配真实LR图像的分布。训练之后，生成器作为退化模型生成LR-HR图像对。



对于LR到HR 的GAN模型，生成器（即SR模型）将生成的LR图像作为输入并预测HR输出，不仅需要匹配相应的HR图像而且还匹配HR图像的分布 。



在“两步法”中，无监督模型有效地提高了超分辨率真实世界LR图像的质量，比以前方法性能获得了很大改进。



无监督SR的另一种方法是将LR空间和HR空间视为两个域，并使用周期循环结构学习彼此之间的映射。这种情况下，训练目的包括推送映射结果去匹配目标的域分布，并通过来回（round trip）映射使图像恢复。



**• 深度图像先验知识**



CNN结构在逆问题之前捕获大量的低级图像统计量，所以在执行SR之前可使用随机初始化的CNN作为手工先验知识。具体地讲，定义生成器网络，将随机向量z作为输入并尝试生成目标HR图像I。训练目标是网络找到一个Iˆ y，其下采样Iˆy与LR图像Ix相同。



因为网络随机初始化，从未在数据集上进行过训练，所以唯一的先验知识是CNN结构本身。虽然这种方法的性能仍然比监督方法差很多，但远远超过传统的bicubic上采样。此外，表现出的CNN架构本身合理性，促使将深度学习方法与CNN结构或自相似性等先验知识相结合来提高超分辨率。



# 特定SR



特定SR领域主要包括深度图、人脸图像、高光谱图像和视频等内容的SR应用。



**面部图像超分辨率**，即面部幻觉（FH， face hallucination），通常可以帮助其他与面部相关的任务。与通用图像相比，面部图像具有更多与面部相关的结构化信息，因此将面部先验知识（例如，关键点，结构解析图和身份）结合到FH中是非常流行且有希望的方法。利用面部先验知识的最直接的方式是约束所生成的HR图像具有与基础事实（GT）的HR图像相同的面部相关信息。



与**全色图像**（PAN，panchromatic images），即具有3个波段的RGB图像相比，有数百个波段的**高光谱图像**（HSI，hyperspectral images）提供了丰富的光谱特征并有助于各种视觉任务。然而，由于硬件限制，收集高质量的HSI比收集PAN更困难，收集的HSI分辨率要低得多。因此，超分辨率被引入该领域，研究人员倾向于将HR PAN和LR HSI结合起来预测HR HSI。



就**视频超分辨率**而言，多个帧提供更多的场景信息，不仅有帧内空间依赖性而且有帧间时间依赖性（例如，运动、亮度和颜色变化）。大多数方法主要集中在更好地利用时空依赖性，包括显式运动补偿（例如，光流算法、基于学习的方法）和递归方法等。



# 参考文献



1. Z Wang, J Chen, S Hoi,“Deep Learning for Image Super-resolution: A Survey”, Arxiv 1902.06068,2019
2. W Yang et al.,“Deep Learning for Single Image Super-Resolution: A Brief Review”, Archiv 1808.03344, 2018
3. Z Li et al.,“Feedback Network for Image Super-Resolution”, CVPR 2019
4. C Chen et al.,“Camera Lens Super-Resolution”, CVPR 2019
5. K Zhang et al.,“Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels”, CVPR 2019



-完-