
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>imaaug 数据增强大杀器 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../math/" />
    
    
    <link rel="prev" href="data.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../introduction/0.html">
            
                <a href="../introduction/0.html">
            
                    
                    送给研一入学的你们—炼丹师入门手册
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../introduction/AI_system.html">
            
                <a href="../introduction/AI_system.html">
            
                    
                    为什么要使得AI System具备可解释性呢？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../code_technique/">
            
                <a href="../code_technique/">
            
                    
                    编程技巧
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../code_technique/python/python_technique.html">
            
                <a href="../code_technique/python/python_technique.html">
            
                    
                    python编程技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../code_technique/python/sort.html">
            
                <a href="../code_technique/python/sort.html">
            
                    
                    python常见排序
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../code_technique/python/opencv.html">
            
                <a href="../code_technique/python/opencv.html">
            
                    
                    opencv-python极速入门
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../code_technique/pytorch/pytorch1.html">
            
                <a href="../code_technique/pytorch/pytorch1.html">
            
                    
                    pytorch常用代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../code_technique/pytorch/pytorch2.html">
            
                <a href="../code_technique/pytorch/pytorch2.html">
            
                    
                    pytorch常用代码段合集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../code_technique/pytorch/pytorch_train.html">
            
                <a href="../code_technique/pytorch/pytorch_train.html">
            
                    
                    pytorch训练技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="../code_technique/pytorch/pytorch_.html">
            
                <a href="../code_technique/pytorch/pytorch_.html">
            
                    
                    pytorch解冻
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="../code_technique/pytorch/pytorch_vision.html">
            
                <a href="../code_technique/pytorch/pytorch_vision.html">
            
                    
                    pytorch网络可视化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.9" data-path="../code_technique/pytorch/PSNR_SSIM.html">
            
                <a href="../code_technique/pytorch/PSNR_SSIM.html">
            
                    
                    PSNR&&SSIM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.10" data-path="../code_technique/pytorch/SPP.html">
            
                <a href="../code_technique/pytorch/SPP.html">
            
                    
                    SPP
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.11" data-path="../code_technique/pytorch/Tensor_to_img_imge_to_tensor.html">
            
                <a href="../code_technique/pytorch/Tensor_to_img_imge_to_tensor.html">
            
                    
                    Tensor to img && imge to tensor
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../linux/">
            
                <a href="../linux/">
            
                    
                    Linux
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../linux/linux_technique.html">
            
                <a href="../linux/linux_technique.html">
            
                    
                    Linux技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../linux/linux_GPU.html">
            
                <a href="../linux/linux_GPU.html">
            
                    
                    Linux显卡驱动修复
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../paper/">
            
                <a href="../paper/">
            
                    
                    论文
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../paper/paper_write.html">
            
                <a href="../paper/paper_write.html">
            
                    
                    论文写作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../paper/Image_to_Image.html">
            
                <a href="../paper/Image_to_Image.html">
            
                    
                    Image-to-Image 的论文汇总（含 GitHub 代码）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../paper/GNN.html">
            
                <a href="../paper/GNN.html">
            
                    
                    GNN综述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../paper/Perceptual_GAN_for_Small_Object_Detection.html">
            
                <a href="../paper/Perceptual_GAN_for_Small_Object_Detection.html">
            
                    
                    Perceptual GAN for Small Object Detection阅读笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.5" data-path="../paper/GMMN.html">
            
                <a href="../paper/GMMN.html">
            
                    
                    GAN变体-GMMN 网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6" data-path="../paper/Deformable_Kernels.html">
            
                <a href="../paper/Deformable_Kernels.html">
            
                    
                    图像视频去噪中的Deformable Kernels
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.7" data-path="../paper/Isolating_Sources_of_Disentanglement_in_VAEs.html">
            
                <a href="../paper/Isolating_Sources_of_Disentanglement_in_VAEs.html">
            
                    
                    Isolating Sources of Disentanglement in VAEs
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.8" data-path="../paper/Spectral_Normalization.html">
            
                <a href="../paper/Spectral_Normalization.html">
            
                    
                    Spectral Normalization 谱归一化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9" data-path="../paper/Unbalanced_sample_loss.html">
            
                <a href="../paper/Unbalanced_sample_loss.html">
            
                    
                    不均衡样本loss
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10" data-path="../paper/NN.html">
            
                <a href="../paper/NN.html">
            
                    
                    论文神经网络示意图
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../super_resolution/">
            
                <a href="../super_resolution/">
            
                    
                    超分辨率
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../super_resolution/SR_summarize.html">
            
                <a href="../super_resolution/SR_summarize.html">
            
                    
                    超分辨率方向综述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../super_resolution/SR.html">
            
                <a href="../super_resolution/SR.html">
            
                    
                    超分辨率技术
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../super_resolution/code_dataset.html">
            
                <a href="../super_resolution/code_dataset.html">
            
                    
                    超分辨率代码数据集合集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="../super_resolution/baseline.html">
            
                <a href="../super_resolution/baseline.html">
            
                    
                    超分辨率baseline
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="../super_resolution/loss.html">
            
                <a href="../super_resolution/loss.html">
            
                    
                    超分辨率的损失函数总结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="./">
            
                <a href="./">
            
                    
                    图片和数据处理
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="picture.html">
            
                <a href="picture.html">
            
                    
                    图片处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="picture_enhance.html">
            
                <a href="picture_enhance.html">
            
                    
                    图像数据增强
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="data.html">
            
                <a href="data.html">
            
                    
                    数据增强
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="2.1.4" data-path="imaaug.html">
            
                <a href="imaaug.html">
            
                    
                    imaaug 数据增强大杀器
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../math/">
            
                <a href="../math/">
            
                    
                    数学
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="../math/matrix.html">
            
                <a href="../math/matrix.html">
            
                    
                    矩阵总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="../math/distribution_show.html">
            
                <a href="../math/distribution_show.html">
            
                    
                    分布
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.3" data-path="../math/affine_transformation.html">
            
                <a href="../math/affine_transformation.html">
            
                    
                    仿射变换
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.4" data-path="../math/graph.html">
            
                <a href="../math/graph.html">
            
                    
                    图的基本概念
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../other/">
            
                <a href="../other/">
            
                    
                    其他
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="../other/discriminator_train.html">
            
                <a href="../other/discriminator_train.html">
            
                    
                    判别器训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="../other/FLOPS.html">
            
                <a href="../other/FLOPS.html">
            
                    
                    网络FLOPS计算
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >imaaug 数据增强大杀器</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="imgaug">imgaug</h1>
<p>This python library helps you with augmenting images for your machine learning projects.
It converts a set of input images into a new, much larger set of slightly altered images.</p>
<p><a href="https://travis-ci.org/aleju/imgaug" target="_blank"><img src="https://travis-ci.org/aleju/imgaug.svg?branch=master" alt="Build Status"></a>
<a href="https://codecov.io/gh/aleju/imgaug" target="_blank"><img src="https://codecov.io/gh/aleju/imgaug/branch/master/graph/badge.svg" alt="codecov"></a>
<a href="https://www.codacy.com/app/aleju/imgaug?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=aleju/imgaug&amp;utm_campaign=Badge_Grade" target="_blank"><img src="https://api.codacy.com/project/badge/Grade/1370ce38e99e40af842d47a8dd721444" alt="Codacy Badge"></a></p>
<table>

<tr>
<th>&#xA0;</th>
<th>Image</th>
<th>Heatmaps</th>
<th>Seg. Maps</th>
<th>Keypoints</th>
<th>Bounding Boxes,<br>Polygons</th>
</tr>

<!-- Line 1: Original Input -->
<tr>
<td><em>Original Input</em></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_image.jpg?raw=true" height="83" width="124" alt="input images"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_heatmap.jpg?raw=true" height="83" width="124" alt="input heatmaps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_segmap.jpg?raw=true" height="83" width="124" alt="input segmentation maps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_kps.jpg?raw=true" height="83" width="124" alt="input keypoints"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/noop_bbs.jpg?raw=true" height="83" width="124" alt="input bounding boxes"></td>
</tr>

<!-- Line 2: Gauss. Noise + Contrast + Sharpen -->
<tr>
<td>Gauss. Noise<br>+&#xA0;Contrast<br>+&#xA0;Sharpen</td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_image.jpg?raw=true" height="83" width="124" alt="non geometric augmentations, applied to images"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_heatmap.jpg?raw=true" height="83" width="124" alt="non geometric augmentations, applied to heatmaps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_segmap.jpg?raw=true" height="83" width="124" alt="non geometric augmentations, applied to segmentation maps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_kps.jpg?raw=true" height="83" width="124" alt="non geometric augmentations, applied to keypoints"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/non_geometric_bbs.jpg?raw=true" height="83" width="124" alt="non geometric augmentations, applied to bounding boxes"></td>
</tr>

<!-- Line 3: Affine -->
<tr>
<td>Affine</td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_image.jpg?raw=true" height="83" width="124" alt="affine augmentations, applied to images"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_heatmap.jpg?raw=true" height="83" width="124" alt="affine augmentations, applied to heatmaps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_segmap.jpg?raw=true" height="83" width="124" alt="affine augmentations, applied to segmentation maps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_kps.jpg?raw=true" height="83" width="124" alt="affine augmentations, applied to keypoints"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/affine_bbs.jpg?raw=true" height="83" width="124" alt="affine augmentations, applied to bounding boxes"></td>
</tr>

<!-- Line 4: Crop + Pad -->
<tr>
<td>Crop<br>+&#xA0;Pad</td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_image.jpg?raw=true" height="83" width="124" alt="crop and pad augmentations, applied to images"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_heatmap.jpg?raw=true" height="83" width="124" alt="crop and pad augmentations, applied to heatmaps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_segmap.jpg?raw=true" height="83" width="124" alt="crop and pad augmentations, applied to segmentation maps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_kps.jpg?raw=true" height="83" width="124" alt="crop and pad augmentations, applied to keypoints"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/cropandpad_bbs.jpg?raw=true" height="83" width="124" alt="crop and pad augmentations, applied to bounding boxes"></td>
</tr>

<!-- Line 5: Fliplr + Perspective -->
<tr>
<td>Fliplr<br>+&#xA0;Perspective</td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_image.jpg" height="83" width="124" alt="Horizontal flip and perspective transform augmentations, applied to images"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_heatmap.jpg?raw=true" height="83" width="124" alt="Horizontal flip and perspective transform augmentations, applied to heatmaps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_segmap.jpg?raw=true" height="83" width="124" alt="Horizontal flip and perspective transform augmentations, applied to segmentation maps"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_kps.jpg?raw=true" height="83" width="124" alt="Horizontal flip and perspective transform augmentations, applied to keypoints"></td>
<td><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/small_overview/fliplr_perspective_bbs.jpg?raw=true" height="83" width="124" alt="Horizontal flip and perspective transform augmentations, applied to bounding boxes"></td>
</tr>

</table>


<p><strong>More (strong) example augmentations of one input image:</strong></p>
<p><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/examples_grid.jpg?raw=true" alt="64 quokkas" title="64 quokkas"></p>
<h2 id="features-of-the-library">Features of the library</h2>
<ul>
<li>Supports both common and exotic augmentation techniques.<ul>
<li>E.g. affine transformations, perspective transformations, contrast changes, gaussian noise, dropout of regions, hue/saturation changes, cropping/padding, blurring, ...</li>
</ul>
</li>
<li>Supports augmentation of:<ul>
<li>Images (full support for uint8, for other dtypes see <a href="https://imgaug.readthedocs.io/en/latest/source/dtype_support.html" target="_blank">documentation</a>)</li>
<li>Heatmaps (float32)</li>
<li>Segmentation maps (integer-based, bool, float-based)</li>
<li>Keypoints/Landmarks (int or float coordinates)</li>
<li>Bounding Boxes (int or float coordinates)</li>
<li>Polygons (int or float coordinates) (Beta)</li>
<li>LineStrings (int or float coordinates) (Beta)</li>
<li>Can augment all of the above automatically with the same sampled values. E.g. rotate both images and the segmentation maps on them by the same random value sampled from <code>uniform(0&#xB0;, 30&#xB0;)</code>.</li>
<li>Native support for heatmaps and segmentation maps that are smaller than their corresponding images.</li>
</ul>
</li>
<li>Define flexible stochastic ranges for each augmentation parameter.<ul>
<li>E.g. &quot;rotate each image by a value between -45 and 45 degrees&quot;.</li>
<li>E.g. &quot;rotate each image by <code>ABS(N(0, 20.0))*(1+B(1.0, 1.0))</code>&quot;, where <code>ABS(.)</code> is the absolute function, <code>N(.)</code> the gaussian distribution and <code>B(.)</code> the beta distribution.</li>
</ul>
</li>
<li>Offers many helper functions.<ul>
<li>E.g. for drawing heatmaps, segmentation maps, keypoints, bounding boxes and polygons.</li>
<li>E.g. for scaling segmentation maps, average/max pooling of images/maps or for padding images to desired aspect ratios (e.g. to square them).</li>
</ul>
</li>
<li>Define your augmentation sequence once at the start of the experiment, then apply it many times.</li>
<li>Supports augmentation on multiple CPU cores.</li>
</ul>
<h2 id="documentation">Documentation</h2>
<ul>
<li><a href="http://imgaug.readthedocs.io/en/latest/source/examples_basics.html" target="_blank">http://imgaug.readthedocs.io/en/latest/source/examples_basics.html</a> - Quick example code on how to use the library.</li>
<li><a href="http://imgaug.readthedocs.io/en/latest/source/augmenters.html" target="_blank">http://imgaug.readthedocs.io/en/latest/source/augmenters.html</a> - Example code for some augmentation techniques. (See also the API, which usually contains examples for each augmenter.)</li>
<li><a href="http://imgaug.readthedocs.io/en/latest/source/api.html" target="_blank">http://imgaug.readthedocs.io/en/latest/source/api.html</a> - API.</li>
<li>For tutorial jupyter notebooks, see <a href="https://github.com/aleju/imgaug-doc/tree/master/notebooks" target="_blank">imgaug-doc/notebooks</a><ul>
<li>E.g. <a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/A01%20-%20Load%20and%20Augment%20an%20Image.ipynb" target="_blank">Load and Augment an Image</a>,
<a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/A03%20-%20Multicore%20Augmentation.ipynb" target="_blank">Multicore Support</a>,
or working with <a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B01%20-%20Augment%20Keypoints.ipynb" target="_blank">Keypoints/Landmarks</a>,
<a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B02%20-%20Augment%20Bounding%20Boxes.ipynb" target="_blank">Bounding Boxes</a>,
<a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B03%20-%20Augment%20Polygons.ipynb" target="_blank">Polygons</a>,
<a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B06%20-%20Augment%20Line%20Strings.ipynb" target="_blank">Line Strings</a>,
<a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B04%20-%20Augment%20Heatmaps.ipynb" target="_blank">Heatmaps</a>,
<a href="https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B05%20-%20Augment%20Segmentation%20Maps.ipynb" target="_blank">Segmentation Maps</a></li>
</ul>
</li>
</ul>
<h2 id="installation">Installation</h2>
<p>The library supports python 2.7 and 3.4+.</p>
<p>To install the library, first install all requirements:</p>
<pre><code class="lang-bash">pip install six numpy scipy Pillow matplotlib scikit-image opencv-python imageio Shapely
</code></pre>
<p>Then install imgaug either via pypi (can lag behind the github version):</p>
<pre><code class="lang-bash">pip install imgaug
</code></pre>
<p>or install the latest version directly from github:</p>
<pre><code class="lang-bash">pip install git+https://github.com/aleju/imgaug
</code></pre>
<p>Alternatively, you can download the repository via <code>git clone https://github.com/aleju/imgaug</code> and install manually
via <code>cd imgaug &amp;&amp; python setup.py install</code>.</p>
<p>To deinstall the library, just execute <code>pip uninstall imgaug</code>.</p>
<h2 id="recent-changes">Recent Changes</h2>
<ul>
<li><strong>0.2.8</strong>: Improved performance, dtype support and multicore augmentation.</li>
</ul>
<p>See <a href="CHANGELOG.md">changelog</a> for more details.</p>
<h2 id="overview-of-most-augmenters">Overview of most augmenters</h2>
<p>The images below show examples for most augmentation techniques (values written in the form <code>(a, b)</code> mean that a value was randomly picked from the range <code>a &lt;= x &lt;= b</code>):</p>
<table>

<tr><td colspan="5"><strong>meta</strong></td></tr>
<tr>
<td colspan="1"><sub>Noop</sub></td>
<td colspan="1"><sub>ChannelShuffle</sub></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/noop.gif" height="148" width="100" alt="Noop"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/channelshuffle.gif" height="148" width="100" alt="ChannelShuffle"></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>arithmetic</strong></td></tr>
<tr>
<td colspan="1"><sub>Add</sub></td>
<td colspan="1"><sub>Add<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>AdditiveGaussianNoise</sub></td>
<td colspan="1"><sub>AdditiveGaussianNoise<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>AdditiveLaplaceNoise</sub></td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/add.gif" height="148" width="100" alt="Add"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/add_per_channel_true.gif" height="148" width="100" alt="Add per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/additivegaussiannoise.gif" height="148" width="100" alt="AdditiveGaussianNoise"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/additivegaussiannoise_per_channel_true.gif" height="148" width="100" alt="AdditiveGaussianNoise per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/additivelaplacenoise.gif" height="148" width="100" alt="AdditiveLaplaceNoise"></td>
</tr>
<tr>
<td colspan="1"><sub>AdditiveLaplaceNoise<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>AdditivePoissonNoise</sub></td>
<td colspan="1"><sub>AdditivePoissonNoise<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>Multiply</sub></td>
<td colspan="1"><sub>Multiply<br>(per_channel=True)</sub></td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/additivelaplacenoise_per_channel_true.gif" height="148" width="100" alt="AdditiveLaplaceNoise per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/additivepoissonnoise.gif" height="148" width="100" alt="AdditivePoissonNoise"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/additivepoissonnoise_per_channel_true.gif" height="148" width="100" alt="AdditivePoissonNoise per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/multiply.gif" height="148" width="100" alt="Multiply"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/multiply_per_channel_true.gif" height="148" width="100" alt="Multiply per_channel=True"></td>
</tr>
<tr>
<td colspan="1"><sub>Dropout</sub></td>
<td colspan="1"><sub>Dropout<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>CoarseDropout<br>(p=0.2)</sub></td>
<td colspan="1"><sub>CoarseDropout<br>(p=0.2, per_channel=True)</sub></td>
<td colspan="1"><sub>ImpulseNoise</sub></td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/dropout.gif" height="148" width="100" alt="Dropout"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/dropout_per_channel_true.gif" height="148" width="100" alt="Dropout per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/coarsedropout_p_0_2.gif" height="148" width="100" alt="CoarseDropout p=0.2"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/coarsedropout_p_0_2_per_channel_true.gif" height="148" width="100" alt="CoarseDropout p=0.2, per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/impulsenoise.gif" height="148" width="100" alt="ImpulseNoise"></td>
</tr>
<tr>
<td colspan="1"><sub>SaltAndPepper</sub></td>
<td colspan="1"><sub>Salt</sub></td>
<td colspan="1"><sub>Pepper</sub></td>
<td colspan="1"><sub>CoarseSaltAndPepper<br>(p=0.2)</sub></td>
<td colspan="1"><sub>CoarseSalt<br>(p=0.2)</sub></td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/saltandpepper.gif" height="148" width="100" alt="SaltAndPepper"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/salt.gif" height="148" width="100" alt="Salt"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pepper.gif" height="148" width="100" alt="Pepper"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/coarsesaltandpepper_p_0_2.gif" height="148" width="100" alt="CoarseSaltAndPepper p=0.2"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/coarsesalt_p_0_2.gif" height="148" width="100" alt="CoarseSalt p=0.2"></td>
</tr>
<tr>
<td colspan="1"><sub>CoarsePepper<br>(p=0.2)</sub></td>
<td colspan="1"><sub>Invert</sub></td>
<td colspan="1"><sub>Invert<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>JpegCompression</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/coarsepepper_p_0_2.gif" height="148" width="100" alt="CoarsePepper p=0.2"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/invert.gif" height="148" width="100" alt="Invert"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/invert_per_channel_true.gif" height="148" width="100" alt="Invert per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/jpegcompression.gif" height="148" width="100" alt="JpegCompression"></td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>blend</strong></td></tr>
<tr>
<td colspan="1"><sub>Alpha<br>with EdgeDetect(1.0)</sub></td>
<td colspan="1"><sub>Alpha<br>with EdgeDetect(1.0)<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>SimplexNoiseAlpha<br>with EdgeDetect(1.0)</sub></td>
<td colspan="1"><sub>FrequencyNoiseAlpha<br>with EdgeDetect(1.0)</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/alpha_with_edgedetect_1_0.gif" height="148" width="100" alt="Alpha with EdgeDetect1.0"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/alpha_with_edgedetect_1_0_per_channel_true.gif" height="148" width="100" alt="Alpha with EdgeDetect1.0 per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/simplexnoisealpha_with_edgedetect_1_0.gif" height="148" width="100" alt="SimplexNoiseAlpha with EdgeDetect1.0"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/frequencynoisealpha_with_edgedetect_1_0.gif" height="148" width="100" alt="FrequencyNoiseAlpha with EdgeDetect1.0"></td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>blur</strong></td></tr>
<tr>
<td colspan="1"><sub>GaussianBlur</sub></td>
<td colspan="1"><sub>AverageBlur</sub></td>
<td colspan="1"><sub>MedianBlur</sub></td>
<td colspan="1"><sub>BilateralBlur<br>(sigma_color=250,<br>sigma_space=250)</sub></td>
<td colspan="1"><sub>MotionBlur<br>(angle=0)</sub></td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/gaussianblur.gif" height="148" width="100" alt="GaussianBlur"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/averageblur.gif" height="148" width="100" alt="AverageBlur"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/medianblur.gif" height="148" width="100" alt="MedianBlur"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/bilateralblur_sigma_color_250_sigma_space_250.gif" height="148" width="100" alt="BilateralBlur sigma_color=250, sigma_space=250"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/motionblur_angle_0.gif" height="148" width="100" alt="MotionBlur angle=0"></td>
</tr>
<tr>
<td colspan="1"><sub>MotionBlur<br>(k=5)</sub></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/motionblur_k_5.gif" height="148" width="100" alt="MotionBlur k=5"></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>color</strong></td></tr>
<tr>
<td colspan="1"><sub>AddToHueAndSaturation</sub></td>
<td colspan="1"><sub>Grayscale</sub></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/addtohueandsaturation.gif" height="148" width="100" alt="AddToHueAndSaturation"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/grayscale.gif" height="148" width="100" alt="Grayscale"></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>contrast</strong></td></tr>
<tr>
<td colspan="1"><sub>GammaContrast</sub></td>
<td colspan="1"><sub>GammaContrast<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>SigmoidContrast<br>(cutoff=0.5)</sub></td>
<td colspan="1"><sub>SigmoidContrast<br>(gain=10)</sub></td>
<td colspan="1"><sub>SigmoidContrast<br>(per_channel=True)</sub></td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/gammacontrast.gif" height="148" width="100" alt="GammaContrast"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/gammacontrast_per_channel_true.gif" height="148" width="100" alt="GammaContrast per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/sigmoidcontrast_cutoff_0_5.gif" height="148" width="100" alt="SigmoidContrast cutoff=0.5"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/sigmoidcontrast_gain_10.gif" height="148" width="100" alt="SigmoidContrast gain=10"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/sigmoidcontrast_per_channel_true.gif" height="148" width="100" alt="SigmoidContrast per_channel=True"></td>
</tr>
<tr>
<td colspan="1"><sub>LogContrast</sub></td>
<td colspan="1"><sub>LogContrast<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>LinearContrast</sub></td>
<td colspan="1"><sub>LinearContrast<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>AllChannels-<br>HistogramEqualization</sub></td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/logcontrast.gif" height="148" width="100" alt="LogContrast"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/logcontrast_per_channel_true.gif" height="148" width="100" alt="LogContrast per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/linearcontrast.gif" height="148" width="100" alt="LinearContrast"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/linearcontrast_per_channel_true.gif" height="148" width="100" alt="LinearContrast per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/allchannels_histogramequalization.gif" height="148" width="100" alt="AllChannels- HistogramEqualization"></td>
</tr>
<tr>
<td colspan="1"><sub>HistogramEqualization</sub></td>
<td colspan="1"><sub>AllChannelsCLAHE</sub></td>
<td colspan="1"><sub>AllChannelsCLAHE<br>(per_channel=True)</sub></td>
<td colspan="1"><sub>CLAHE</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/histogramequalization.gif" height="148" width="100" alt="HistogramEqualization"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/allchannelsclahe.gif" height="148" width="100" alt="AllChannelsCLAHE"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/allchannelsclahe_per_channel_true.gif" height="148" width="100" alt="AllChannelsCLAHE per_channel=True"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/clahe.gif" height="148" width="100" alt="CLAHE"></td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>convolutional</strong></td></tr>
<tr>
<td colspan="1"><sub>Sharpen<br>(alpha=1)</sub></td>
<td colspan="1"><sub>Emboss<br>(alpha=1)</sub></td>
<td colspan="1"><sub>EdgeDetect</sub></td>
<td colspan="1"><sub>DirectedEdgeDetect<br>(alpha=1)</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/sharpen_alpha_1.gif" height="148" width="100" alt="Sharpen alpha=1"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/emboss_alpha_1.gif" height="148" width="100" alt="Emboss alpha=1"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/edgedetect.gif" height="148" width="100" alt="EdgeDetect"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/directededgedetect_alpha_1.gif" height="148" width="100" alt="DirectedEdgeDetect alpha=1"></td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>flip</strong></td></tr>
<tr>
<td colspan="2"><sub>Fliplr</sub></td>
<td colspan="2"><sub>Flipud</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/fliplr.gif" height="148" width="300" alt="Fliplr"></td>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/flipud.gif" height="148" width="300" alt="Flipud"></td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>geometric</strong></td></tr>
<tr>
<td colspan="2"><sub>Affine</sub></td>
<td colspan="2"><sub>Affine: Modes</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/affine.gif" height="148" width="300" alt="Affine"></td>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/affine_modes.gif" height="148" width="300" alt="Affine: Modes"></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><sub>Affine: cval</sub></td>
<td colspan="2"><sub>PiecewiseAffine</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/affine_cval.gif" height="148" width="300" alt="Affine: cval"></td>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/piecewiseaffine.gif" height="148" width="300" alt="PiecewiseAffine"></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><sub>PerspectiveTransform</sub></td>
<td colspan="2"><sub>ElasticTransformation<br>(sigma=0.2)</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/perspectivetransform.gif" height="148" width="300" alt="PerspectiveTransform"></td>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/elastictransformation_sigma_0_2.gif" height="148" width="300" alt="ElasticTransformation sigma=0.2"></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><sub>ElasticTransformation<br>(sigma=5.0)</sub></td>
<td colspan="2"><sub>Rot90</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/elastictransformation_sigma_5_0.gif" height="148" width="300" alt="ElasticTransformation sigma=5.0"></td>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/rot90.gif" height="148" width="300" alt="Rot90"></td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>segmentation</strong></td></tr>
<tr>
<td colspan="1"><sub>Superpixels<br>(p_replace=1)</sub></td>
<td colspan="1"><sub>Superpixels<br>(n_segments=100)</sub></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/superpixels_p_replace_1.gif" height="148" width="100" alt="Superpixels p_replace=1"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/superpixels_n_segments_100.gif" height="148" width="100" alt="Superpixels n_segments=100"></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>size</strong></td></tr>
<tr>
<td colspan="2"><sub>CropAndPad</sub></td>
<td colspan="2"><sub>Crop</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/cropandpad.gif" height="148" width="300" alt="CropAndPad"></td>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/crop.gif" height="148" width="300" alt="Crop"></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><sub>Pad</sub></td>
<td colspan="2"><sub>PadToFixedSize<br>(height&apos;=height+32,<br>width&apos;=width+32)</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/pad.gif" height="148" width="300" alt="Pad"></td>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/padtofixedsize_height_height_32_width_width_32.gif" height="148" width="300" alt="PadToFixedSize height&apos;=height+32, width&apos;=width+32"></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><sub>CropToFixedSize<br>(height&apos;=height-32,<br>width&apos;=width-32)</sub></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="2"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/croptofixedsize_height_height_32_width_width_32.gif" height="148" width="300" alt="CropToFixedSize height&apos;=height-32, width&apos;=width-32"></td>
<td>&#xA0;</td>
<td>&#xA0;</td>
<td>&#xA0;</td>
</tr>
<tr><td colspan="5"><strong>weather</strong></td></tr>
<tr>
<td colspan="1"><sub>FastSnowyLandscape<br>(lightness_multiplier=2.0)</sub></td>
<td colspan="1"><sub>Clouds</sub></td>
<td colspan="1"><sub>Fog</sub></td>
<td colspan="1"><sub>Snowflakes</sub></td>
<td>&#xA0;</td>
</tr>
<tr>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/fastsnowylandscape_lightness_multiplier_2_0.gif" height="144" width="128" alt="FastSnowyLandscape lightness_multiplier=2.0"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/clouds.gif" height="144" width="128" alt="Clouds"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/fog.gif" height="144" width="128" alt="Fog"></td>
<td colspan="1"><img src="https://raw.githubusercontent.com/aleju/imgaug-doc/master/readme_images/augmenter_videos/snowflakes.gif" height="144" width="128" alt="Snowflakes"></td>
<td>&#xA0;</td>
</tr>

</table>


<h2 id="code-examples">Code Examples</h2>
<p>A standard machine learning situation.
Train on batches of images and augment each batch via crop, horizontal flip (&quot;Fliplr&quot;) and gaussian blur:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa

seq = iaa.Sequential([
    iaa.Crop(px=(<span class="hljs-number">0</span>, <span class="hljs-number">16</span>)), <span class="hljs-comment"># crop images from each side by 0 to 16px (randomly chosen)</span>
    iaa.Fliplr(<span class="hljs-number">0.5</span>), <span class="hljs-comment"># horizontally flip 50% of the images</span>
    iaa.GaussianBlur(sigma=(<span class="hljs-number">0</span>, <span class="hljs-number">3.0</span>)) <span class="hljs-comment"># blur images with a sigma of 0 to 3.0</span>
])

<span class="hljs-keyword">for</span> batch_idx <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):
    <span class="hljs-comment"># &apos;images&apos; should be either a 4D numpy array of shape (N, height, width, channels)</span>
    <span class="hljs-comment"># or a list of 3D numpy arrays, each having shape (height, width, channels).</span>
    <span class="hljs-comment"># Grayscale images must have shape (height, width, 1) each.</span>
    <span class="hljs-comment"># All images must have numpy&apos;s dtype uint8. Values are expected to be in</span>
    <span class="hljs-comment"># range 0-255.</span>
    images = load_batch(batch_idx)  <span class="hljs-comment"># you have to implement this function</span>
    images_aug = seq.augment_images(images)  <span class="hljs-comment"># done by the library</span>
    train_on_images(images_aug)  <span class="hljs-comment"># you have to implement this function</span>
</code></pre>
<p>Apply heavy augmentations to images (used to create the image at the very top of this readme):</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> imgaug <span class="hljs-keyword">as</span> ia
<span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># random example images</span>
images = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, (<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8)

<span class="hljs-comment"># Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,</span>
<span class="hljs-comment"># e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.</span>
sometimes = <span class="hljs-keyword">lambda</span> aug: iaa.Sometimes(<span class="hljs-number">0.5</span>, aug)

<span class="hljs-comment"># Define our sequence of augmentation steps that will be applied to every image</span>
<span class="hljs-comment"># All augmenters with per_channel=0.5 will sample one value _per image_</span>
<span class="hljs-comment"># in 50% of all cases. In all other cases they will sample new values</span>
<span class="hljs-comment"># _per channel_.</span>
seq = iaa.Sequential(
    [
        <span class="hljs-comment"># apply the following augmenters to most images</span>
        iaa.Fliplr(<span class="hljs-number">0.5</span>), <span class="hljs-comment"># horizontally flip 50% of all images</span>
        iaa.Flipud(<span class="hljs-number">0.2</span>), <span class="hljs-comment"># vertically flip 20% of all images</span>
        <span class="hljs-comment"># crop images by -5% to 10% of their height/width</span>
        sometimes(iaa.CropAndPad(
            percent=(<span class="hljs-number">-0.05</span>, <span class="hljs-number">0.1</span>),
            pad_mode=ia.ALL,
            pad_cval=(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>)
        )),
        sometimes(iaa.Affine(
            scale={<span class="hljs-string">&quot;x&quot;</span>: (<span class="hljs-number">0.8</span>, <span class="hljs-number">1.2</span>), <span class="hljs-string">&quot;y&quot;</span>: (<span class="hljs-number">0.8</span>, <span class="hljs-number">1.2</span>)}, <span class="hljs-comment"># scale images to 80-120% of their size, individually per axis</span>
            translate_percent={<span class="hljs-string">&quot;x&quot;</span>: (<span class="hljs-number">-0.2</span>, <span class="hljs-number">0.2</span>), <span class="hljs-string">&quot;y&quot;</span>: (<span class="hljs-number">-0.2</span>, <span class="hljs-number">0.2</span>)}, <span class="hljs-comment"># translate by -20 to +20 percent (per axis)</span>
            rotate=(<span class="hljs-number">-45</span>, <span class="hljs-number">45</span>), <span class="hljs-comment"># rotate by -45 to +45 degrees</span>
            shear=(<span class="hljs-number">-16</span>, <span class="hljs-number">16</span>), <span class="hljs-comment"># shear by -16 to +16 degrees</span>
            order=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-comment"># use nearest neighbour or bilinear interpolation (fast)</span>
            cval=(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-comment"># if mode is constant, use a cval between 0 and 255</span>
            mode=ia.ALL <span class="hljs-comment"># use any of scikit-image&apos;s warping modes (see 2nd image from the top for examples)</span>
        )),
        <span class="hljs-comment"># execute 0 to 5 of the following (less important) augmenters per image</span>
        <span class="hljs-comment"># don&apos;t execute all of them, as that would often be way too strong</span>
        iaa.SomeOf((<span class="hljs-number">0</span>, <span class="hljs-number">5</span>),
            [
                sometimes(iaa.Superpixels(p_replace=(<span class="hljs-number">0</span>, <span class="hljs-number">1.0</span>), n_segments=(<span class="hljs-number">20</span>, <span class="hljs-number">200</span>))), <span class="hljs-comment"># convert images into their superpixel representation</span>
                iaa.OneOf([
                    iaa.GaussianBlur((<span class="hljs-number">0</span>, <span class="hljs-number">3.0</span>)), <span class="hljs-comment"># blur images with a sigma between 0 and 3.0</span>
                    iaa.AverageBlur(k=(<span class="hljs-number">2</span>, <span class="hljs-number">7</span>)), <span class="hljs-comment"># blur image using local means with kernel sizes between 2 and 7</span>
                    iaa.MedianBlur(k=(<span class="hljs-number">3</span>, <span class="hljs-number">11</span>)), <span class="hljs-comment"># blur image using local medians with kernel sizes between 2 and 7</span>
                ]),
                iaa.Sharpen(alpha=(<span class="hljs-number">0</span>, <span class="hljs-number">1.0</span>), lightness=(<span class="hljs-number">0.75</span>, <span class="hljs-number">1.5</span>)), <span class="hljs-comment"># sharpen images</span>
                iaa.Emboss(alpha=(<span class="hljs-number">0</span>, <span class="hljs-number">1.0</span>), strength=(<span class="hljs-number">0</span>, <span class="hljs-number">2.0</span>)), <span class="hljs-comment"># emboss images</span>
                <span class="hljs-comment"># search either for all edges or for directed edges,</span>
                <span class="hljs-comment"># blend the result with the original image using a blobby mask</span>
                iaa.SimplexNoiseAlpha(iaa.OneOf([
                    iaa.EdgeDetect(alpha=(<span class="hljs-number">0.5</span>, <span class="hljs-number">1.0</span>)),
                    iaa.DirectedEdgeDetect(alpha=(<span class="hljs-number">0.5</span>, <span class="hljs-number">1.0</span>), direction=(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)),
                ])),
                iaa.AdditiveGaussianNoise(loc=<span class="hljs-number">0</span>, scale=(<span class="hljs-number">0.0</span>, <span class="hljs-number">0.05</span>*<span class="hljs-number">255</span>), per_channel=<span class="hljs-number">0.5</span>), <span class="hljs-comment"># add gaussian noise to images</span>
                iaa.OneOf([
                    iaa.Dropout((<span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>), per_channel=<span class="hljs-number">0.5</span>), <span class="hljs-comment"># randomly remove up to 10% of the pixels</span>
                    iaa.CoarseDropout((<span class="hljs-number">0.03</span>, <span class="hljs-number">0.15</span>), size_percent=(<span class="hljs-number">0.02</span>, <span class="hljs-number">0.05</span>), per_channel=<span class="hljs-number">0.2</span>),
                ]),
                iaa.Invert(<span class="hljs-number">0.05</span>, per_channel=<span class="hljs-keyword">True</span>), <span class="hljs-comment"># invert color channels</span>
                iaa.Add((<span class="hljs-number">-10</span>, <span class="hljs-number">10</span>), per_channel=<span class="hljs-number">0.5</span>), <span class="hljs-comment"># change brightness of images (by -10 to 10 of original value)</span>
                iaa.AddToHueAndSaturation((<span class="hljs-number">-20</span>, <span class="hljs-number">20</span>)), <span class="hljs-comment"># change hue and saturation</span>
                <span class="hljs-comment"># either change the brightness of the whole image (sometimes</span>
                <span class="hljs-comment"># per channel) or change the brightness of subareas</span>
                iaa.OneOf([
                    iaa.Multiply((<span class="hljs-number">0.5</span>, <span class="hljs-number">1.5</span>), per_channel=<span class="hljs-number">0.5</span>),
                    iaa.FrequencyNoiseAlpha(
                        exponent=(<span class="hljs-number">-4</span>, <span class="hljs-number">0</span>),
                        first=iaa.Multiply((<span class="hljs-number">0.5</span>, <span class="hljs-number">1.5</span>), per_channel=<span class="hljs-keyword">True</span>),
                        second=iaa.ContrastNormalization((<span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span>))
                    )
                ]),
                iaa.ContrastNormalization((<span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span>), per_channel=<span class="hljs-number">0.5</span>), <span class="hljs-comment"># improve or worsen the contrast</span>
                iaa.Grayscale(alpha=(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)),
                sometimes(iaa.ElasticTransformation(alpha=(<span class="hljs-number">0.5</span>, <span class="hljs-number">3.5</span>), sigma=<span class="hljs-number">0.25</span>)), <span class="hljs-comment"># move pixels locally around (with random strengths)</span>
                sometimes(iaa.PiecewiseAffine(scale=(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.05</span>))), <span class="hljs-comment"># sometimes move parts of the image around</span>
                sometimes(iaa.PerspectiveTransform(scale=(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>)))
            ],
            random_order=<span class="hljs-keyword">True</span>
        )
    ],
    random_order=<span class="hljs-keyword">True</span>
)

images_aug = seq.augment_images(images)
</code></pre>
<p>Quickly show example results of your augmentation sequence:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

images = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, (<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8)
seq = iaa.Sequential([iaa.Fliplr(<span class="hljs-number">0.5</span>), iaa.GaussianBlur((<span class="hljs-number">0</span>, <span class="hljs-number">3.0</span>))])

<span class="hljs-comment"># show an image with 8*8 augmented versions of image 0</span>
seq.show_grid(images[<span class="hljs-number">0</span>], cols=<span class="hljs-number">8</span>, rows=<span class="hljs-number">8</span>)

<span class="hljs-comment"># Show an image with 8*8 augmented versions of image 0 and 8*8 augmented</span>
<span class="hljs-comment"># versions of image 1. The identical augmentations will be applied to</span>
<span class="hljs-comment"># image 0 and 1.</span>
seq.show_grid([images[<span class="hljs-number">0</span>], images[<span class="hljs-number">1</span>]], cols=<span class="hljs-number">8</span>, rows=<span class="hljs-number">8</span>)
</code></pre>
<p>Augment two batches of images in <em>exactly the same way</em> (e.g. horizontally flip 1st, 2nd and 5th images in both batches, but do not alter 3rd and 4th images):</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa

<span class="hljs-comment"># Standard scenario: You have N RGB-images and additionally 21 heatmaps per image.</span>
<span class="hljs-comment"># You want to augment each image and its heatmaps identically.</span>
images = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, (<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8)
heatmaps = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, (<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">21</span>), dtype=np.uint8)

seq = iaa.Sequential([iaa.GaussianBlur((<span class="hljs-number">0</span>, <span class="hljs-number">3.0</span>)), iaa.Affine(translate_px={<span class="hljs-string">&quot;x&quot;</span>: (<span class="hljs-number">-40</span>, <span class="hljs-number">40</span>)})])

<span class="hljs-comment"># Convert the stochastic sequence of augmenters to a deterministic one.</span>
<span class="hljs-comment"># The deterministic sequence will always apply the exactly same effects to the images.</span>
seq_det = seq.to_deterministic() <span class="hljs-comment"># call this for each batch again, NOT only once at the start</span>
images_aug = seq_det.augment_images(images)
heatmaps_aug = seq_det.augment_images(heatmaps)
</code></pre>
<p>Augment images <em>and</em> <strong>landmarks/keypoints</strong> on these images:</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> imgaug <span class="hljs-keyword">as</span> ia
<span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
images = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">50</span>, (<span class="hljs-number">4</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8)

<span class="hljs-comment"># Generate random keypoints.</span>
<span class="hljs-comment"># The augmenters expect a list of imgaug.KeypointsOnImage.</span>
keypoints_on_images = []
<span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> images:
    height, width = image.shape[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>]
    keypoints = []
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">4</span>):
        x = random.randint(<span class="hljs-number">0</span>, width<span class="hljs-number">-1</span>)
        y = random.randint(<span class="hljs-number">0</span>, height<span class="hljs-number">-1</span>)
        keypoints.append(ia.Keypoint(x=x, y=y))
    keypoints_on_images.append(ia.KeypointsOnImage(keypoints, shape=image.shape))

seq = iaa.Sequential([iaa.GaussianBlur((<span class="hljs-number">0</span>, <span class="hljs-number">3.0</span>)), iaa.Affine(scale=(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.7</span>))])
seq_det = seq.to_deterministic() <span class="hljs-comment"># call this for each batch again, NOT only once at the start</span>

<span class="hljs-comment"># augment keypoints and images</span>
images_aug = seq_det.augment_images(images)
keypoints_aug = seq_det.augment_keypoints(keypoints_on_images)

<span class="hljs-comment"># Example code to show each image and print the new keypoints coordinates</span>
<span class="hljs-keyword">for</span> img_idx, (image_before, image_after, keypoints_before, keypoints_after) <span class="hljs-keyword">in</span> enumerate(zip(images, images_aug, keypoints_on_images, keypoints_aug)):
    image_before = keypoints_before.draw_on_image(image_before)
    image_after = keypoints_after.draw_on_image(image_after)
    ia.imshow(np.concatenate((image_before, image_after), axis=<span class="hljs-number">1</span>)) <span class="hljs-comment"># before and after</span>
    <span class="hljs-keyword">for</span> kp_idx, keypoint <span class="hljs-keyword">in</span> enumerate(keypoints_after.keypoints):
        keypoint_old = keypoints_on_images[img_idx].keypoints[kp_idx]
        x_old, y_old = keypoint_old.x, keypoint_old.y
        x_new, y_new = keypoint.x, keypoint.y
        print(<span class="hljs-string">&quot;[Keypoints for image #%d] before aug: x=%d y=%d | after aug: x=%d y=%d&quot;</span> % (img_idx, x_old, y_old, x_new, y_new))
</code></pre>
<p>Apply single augmentations to images:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
images = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, (<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8)

flipper = iaa.Fliplr(<span class="hljs-number">1.0</span>) <span class="hljs-comment"># always horizontally flip each input image</span>
images[<span class="hljs-number">0</span>] = flipper.augment_image(images[<span class="hljs-number">0</span>]) <span class="hljs-comment"># horizontally flip image 0</span>

vflipper = iaa.Flipud(<span class="hljs-number">0.9</span>) <span class="hljs-comment"># vertically flip each input image with 90% probability</span>
images[<span class="hljs-number">1</span>] = vflipper.augment_image(images[<span class="hljs-number">1</span>]) <span class="hljs-comment"># probably vertically flip image 1</span>

blurer = iaa.GaussianBlur(<span class="hljs-number">3.0</span>)
images[<span class="hljs-number">2</span>] = blurer.augment_image(images[<span class="hljs-number">2</span>]) <span class="hljs-comment"># blur image 2 by a sigma of 3.0</span>
images[<span class="hljs-number">3</span>] = blurer.augment_image(images[<span class="hljs-number">3</span>]) <span class="hljs-comment"># blur image 3 by a sigma of 3.0 too</span>

translater = iaa.Affine(translate_px={<span class="hljs-string">&quot;x&quot;</span>: <span class="hljs-number">-16</span>}) <span class="hljs-comment"># move each input image by 16px to the left</span>
images[<span class="hljs-number">4</span>] = translater.augment_image(images[<span class="hljs-number">4</span>]) <span class="hljs-comment"># move image 4 to the left</span>

scaler = iaa.Affine(scale={<span class="hljs-string">&quot;y&quot;</span>: (<span class="hljs-number">0.8</span>, <span class="hljs-number">1.2</span>)}) <span class="hljs-comment"># scale each input image to 80-120% on the y axis</span>
images[<span class="hljs-number">5</span>] = scaler.augment_image(images[<span class="hljs-number">5</span>]) <span class="hljs-comment"># scale image 5 by 80-120% on the y axis</span>
</code></pre>
<p>Apply an augmenter to only specific image channels:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># fake RGB images</span>
images = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, (<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8)

<span class="hljs-comment"># add a random value from the range (-30, 30) to the first two channels of</span>
<span class="hljs-comment"># input images (e.g. to the R and G channels)</span>
aug = iaa.WithChannels(
  channels=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],
  children=iaa.Add((<span class="hljs-number">-30</span>, <span class="hljs-number">30</span>))
)

images_aug = aug.augment_images(images)
</code></pre>
<p>You can use more unusual distributions for the stochastic parameters of each augmenter:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> parameters <span class="hljs-keyword">as</span> iap
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
images = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, (<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8)

<span class="hljs-comment"># Blur by a value sigma which is sampled from a uniform distribution</span>
<span class="hljs-comment"># of range 0.1 &lt;= x &lt; 3.0.</span>
<span class="hljs-comment"># The convenience shortcut for this is: iaa.GaussianBlur((0.1, 3.0))</span>
blurer = iaa.GaussianBlur(iap.Uniform(<span class="hljs-number">0.1</span>, <span class="hljs-number">3.0</span>))
images_aug = blurer.augment_images(images)

<span class="hljs-comment"># Blur by a value sigma which is sampled from a normal distribution N(1.0, 0.1),</span>
<span class="hljs-comment"># i.e. sample a value that is usually around 1.0.</span>
<span class="hljs-comment"># Clip the resulting value so that it never gets below 0.1 or above 3.0.</span>
blurer = iaa.GaussianBlur(iap.Clip(iap.Normal(<span class="hljs-number">1.0</span>, <span class="hljs-number">0.1</span>), <span class="hljs-number">0.1</span>, <span class="hljs-number">3.0</span>))
images_aug = blurer.augment_images(images)

<span class="hljs-comment"># Same again, but this time the mean of the normal distribution is not constant,</span>
<span class="hljs-comment"># but comes itself from a uniform distribution between 0.5 and 1.5.</span>
blurer = iaa.GaussianBlur(iap.Clip(iap.Normal(iap.Uniform(<span class="hljs-number">0.5</span>, <span class="hljs-number">1.5</span>), <span class="hljs-number">0.1</span>), <span class="hljs-number">0.1</span>, <span class="hljs-number">3.0</span>))
images_aug = blurer.augment_images(images)

<span class="hljs-comment"># Use for sigma one of exactly three allowed values: 0.5, 1.0 or 1.5.</span>
blurer = iaa.GaussianBlur(iap.Choice([<span class="hljs-number">0.5</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">1.5</span>]))
images_aug = blurer.augment_images(images)

<span class="hljs-comment"># Sample sigma from a discrete uniform distribution of range 1 &lt;= sigma &lt;= 5,</span>
<span class="hljs-comment"># i.e. sigma will have any of the following values: 1, 2, 3, 4, 5.</span>
blurer = iaa.GaussianBlur(iap.DiscreteUniform(<span class="hljs-number">1</span>, <span class="hljs-number">5</span>))
images_aug = blurer.augment_images(images)
</code></pre>
<p>Images can be augmented in <strong>background processes</strong> using the method <code>augment_batches(batches, background=True)</code>,
where <code>batches</code> is expected to be a list of image batches or a list of batches/lists of <code>imgaug.KeypointsOnImage</code> or a list of <code>imgaug.Batch</code>.
The following example augments a list of image batches in the background:</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> imgaug <span class="hljs-keyword">as</span> ia
<span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> data

<span class="hljs-comment"># Number of batches and batch size for this example</span>
nb_batches = <span class="hljs-number">10</span>
batch_size = <span class="hljs-number">32</span>

<span class="hljs-comment"># Example augmentation sequence to run in the background</span>
augseq = iaa.Sequential([
    iaa.Fliplr(<span class="hljs-number">0.5</span>),
    iaa.CoarseDropout(p=<span class="hljs-number">0.1</span>, size_percent=<span class="hljs-number">0.1</span>)
])

<span class="hljs-comment"># For simplicity, we use the same image here many times</span>
astronaut = data.astronaut()
astronaut = ia.imresize_single_image(astronaut, (<span class="hljs-number">64</span>, <span class="hljs-number">64</span>))

<span class="hljs-comment"># Make batches out of the example image (here: 10 batches, each 32 times</span>
<span class="hljs-comment"># the example image)</span>
batches = []
<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(nb_batches):
    batches.append(
        np.array(
            [astronaut <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(batch_size)],
            dtype=np.uint8
        )
    )

<span class="hljs-comment"># Show the augmented images.</span>
<span class="hljs-comment"># Note that augment_batches() returns a generator.</span>
<span class="hljs-keyword">for</span> images_aug <span class="hljs-keyword">in</span> augseq.augment_batches(batches, background=<span class="hljs-keyword">True</span>):
    ia.imshow(ia.draw_grid(images_aug, cols=<span class="hljs-number">8</span>))
</code></pre>
<p>If you need a bit more control over the background augmentation process, you can work with <code>augmenter.pool()</code>,
which allows you to define how many CPU cores to use, how often to restart child workers,
which random number seed to use and how large the chunks of data transferred to each child worker should be.</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> imgaug <span class="hljs-keyword">as</span> ia
<span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa

<span class="hljs-comment"># Basic augmentation sequence. PiecewiseAffine is slow and therefore well suited</span>
<span class="hljs-comment"># for augmentation on multiple CPU cores.</span>
aug = iaa.Sequential([
    iaa.Fliplr(<span class="hljs-number">0.5</span>),
    iaa.PiecewiseAffine((<span class="hljs-number">0.0</span>, <span class="hljs-number">0.1</span>))
])

<span class="hljs-comment"># generator that yields images</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_image_generator</span><span class="hljs-params">(nb_batches, size)</span>:</span>
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(nb_batches):
        <span class="hljs-comment"># Add e.g. keypoints=... or bounding_boxes=... here to also augment</span>
        <span class="hljs-comment"># keypoints / bounding boxes on these images.</span>
        <span class="hljs-keyword">yield</span> ia.Batch(
            images=np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, size=size).astype(np.uint8)
        )

<span class="hljs-comment"># 500 batches of images, each containing 10 images of size 128x128x3</span>
my_generator = create_image_generator(<span class="hljs-number">500</span>, (<span class="hljs-number">10</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>))

<span class="hljs-comment"># Start a pool to augment on multiple CPU cores.</span>
<span class="hljs-comment">#   * processes=-1 means that all CPU cores except one are used for the</span>
<span class="hljs-comment">#     augmentation, so one is kept free to move data to the GPU</span>
<span class="hljs-comment">#   * maxtasksperchild=20 restarts child workers every 20 tasks -- only use this</span>
<span class="hljs-comment">#     if you encounter problems such as memory leaks. Restarting child workers</span>
<span class="hljs-comment">#     decreases performance.</span>
<span class="hljs-comment">#   * seed=123 makes the result of the whole augmentation process deterministic</span>
<span class="hljs-comment">#     between runs of this script, i.e. reproducible results.</span>
<span class="hljs-keyword">with</span> aug.pool(processes=<span class="hljs-number">-1</span>, maxtasksperchild=<span class="hljs-number">20</span>, seed=<span class="hljs-number">123</span>) <span class="hljs-keyword">as</span> pool:
    <span class="hljs-comment"># Augment on multiple CPU cores.</span>
    <span class="hljs-comment">#   * The result of imap_batches() is also a generator.</span>
    <span class="hljs-comment">#   * Use map_batches() if your input is a list.</span>
    <span class="hljs-comment">#   * chunksize=10 controls how much data to send to each child worker per</span>
    <span class="hljs-comment">#     transfer, set it higher for better performance.</span>
    batches_aug_generator = pool.imap_batches(my_generator, chunksize=<span class="hljs-number">10</span>)

    <span class="hljs-keyword">for</span> i, batch_aug <span class="hljs-keyword">in</span> enumerate(batches_aug_generator):
        <span class="hljs-comment"># show first augmented image in first batch</span>
        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:
            ia.imshow(batch_aug.images_aug[<span class="hljs-number">0</span>])
        <span class="hljs-comment"># do something else with the batch here</span>
</code></pre>
<p>You can <strong>dynamically deactivate augmenters</strong> in an already defined sequence:</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> imgaug <span class="hljs-keyword">as</span> ia
<span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># images and heatmaps, just arrays filled with value 30</span>
images = np.ones((<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>), dtype=np.uint8) * <span class="hljs-number">30</span>
heatmaps = np.ones((<span class="hljs-number">16</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">21</span>), dtype=np.uint8) * <span class="hljs-number">30</span>

<span class="hljs-comment"># add vertical lines to see the effect of flip</span>
images[:, <span class="hljs-number">16</span>:<span class="hljs-number">128</span><span class="hljs-number">-16</span>, <span class="hljs-number">120</span>:<span class="hljs-number">124</span>, :] = <span class="hljs-number">120</span>
heatmaps[:, <span class="hljs-number">16</span>:<span class="hljs-number">128</span><span class="hljs-number">-16</span>, <span class="hljs-number">120</span>:<span class="hljs-number">124</span>, :] = <span class="hljs-number">120</span>

seq = iaa.Sequential([
  iaa.Fliplr(<span class="hljs-number">0.5</span>, name=<span class="hljs-string">&quot;Flipper&quot;</span>),
  iaa.GaussianBlur((<span class="hljs-number">0</span>, <span class="hljs-number">3.0</span>), name=<span class="hljs-string">&quot;GaussianBlur&quot;</span>),
  iaa.Dropout(<span class="hljs-number">0.02</span>, name=<span class="hljs-string">&quot;Dropout&quot;</span>),
  iaa.AdditiveGaussianNoise(scale=<span class="hljs-number">0.01</span>*<span class="hljs-number">255</span>, name=<span class="hljs-string">&quot;MyLittleNoise&quot;</span>),
  iaa.AdditiveGaussianNoise(loc=<span class="hljs-number">32</span>, scale=<span class="hljs-number">0.0001</span>*<span class="hljs-number">255</span>, name=<span class="hljs-string">&quot;SomeOtherNoise&quot;</span>),
  iaa.Affine(translate_px={<span class="hljs-string">&quot;x&quot;</span>: (<span class="hljs-number">-40</span>, <span class="hljs-number">40</span>)}, name=<span class="hljs-string">&quot;Affine&quot;</span>)
])

<span class="hljs-comment"># change the activated augmenters for heatmaps,</span>
<span class="hljs-comment"># we only want to execute horizontal flip, affine transformation and one of</span>
<span class="hljs-comment"># the gaussian noises</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">activator_heatmaps</span><span class="hljs-params">(images, augmenter, parents, default)</span>:</span>
    <span class="hljs-keyword">if</span> augmenter.name <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;GaussianBlur&quot;</span>, <span class="hljs-string">&quot;Dropout&quot;</span>, <span class="hljs-string">&quot;MyLittleNoise&quot;</span>]:
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span>
    <span class="hljs-keyword">else</span>:
        <span class="hljs-comment"># default value for all other augmenters</span>
        <span class="hljs-keyword">return</span> default
hooks_heatmaps = ia.HooksImages(activator=activator_heatmaps)

seq_det = seq.to_deterministic() <span class="hljs-comment"># call this for each batch again, NOT only once at the start</span>
images_aug = seq_det.augment_images(images)
heatmaps_aug = seq_det.augment_images(heatmaps, hooks=hooks_heatmaps)
</code></pre>
<h2 id="list-of-augmenters">List of augmenters</h2>
<p>The following is a list of available augmenters.
Note that most of the below mentioned variables can be set to ranges, e.g. <code>A=(0.0, 1.0)</code> to sample a random value between 0 and 1.0 per image,
or <code>A=[0.0, 0.5, 1.0]</code> to sample randomly either <code>0.0</code> or <code>0.5</code> or <code>1.0</code> per image.</p>
<p><strong>arithmetic</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Add(V, PCH)</td>
<td>Adds value <code>V</code> to each image. If <code>PCH</code> is true, then the sampled values may be different per channel.</td>
</tr>
<tr>
<td>AddElementwise(V, PCH)</td>
<td>Adds value <code>V</code> to each pixel. If <code>PCH</code> is true, then the sampled values may be different per channel (and pixel).</td>
</tr>
<tr>
<td>AdditiveGaussianNoise(L, S, PCH)</td>
<td>Adds white/gaussian noise pixelwise to an image. The noise comes from the normal distribution <code>N(L,S)</code>. If <code>PCH</code> is true, then the sampled values may be different per channel (and pixel).</td>
</tr>
<tr>
<td>AdditiveLaplaceNoise(L, S, PCH)</td>
<td>Adds noise sampled from a laplace distribution following <code>Laplace(L, S)</code> to images. If <code>PCH</code> is true, then the sampled values may be different per channel (and pixel).</td>
</tr>
<tr>
<td>AdditivePoissonNoise(L, PCH)</td>
<td>Adds noise sampled from a poisson distribution with <code>L</code> being the <code>lambda</code> exponent. If <code>PCH</code> is true, then the sampled values may be different per channel (and pixel).</td>
</tr>
<tr>
<td>Multiply(V, PCH)</td>
<td>Multiplies each image by value <code>V</code>, leading to darker/brighter images. If <code>PCH</code> is true, then the sampled values may be different per channel.</td>
</tr>
<tr>
<td>MultiplyElementwise(V, PCH)</td>
<td>Multiplies each pixel by value <code>V</code>, leading to darker/brighter pixels. If <code>PCH</code> is true, then the sampled values may be different per channel (and pixel).</td>
</tr>
<tr>
<td>Dropout(P, PCH)</td>
<td>Sets pixels to zero with probability <code>P</code>. If <code>PCH</code> is true, then channels may be treated differently, otherwise whole pixels are set to zero.</td>
</tr>
<tr>
<td>CoarseDropout(P, SPX, SPC, PCH)</td>
<td>Like <code>Dropout</code>, but samples the locations of pixels that are to be set to zero from a coarser/smaller image, which has pixel size <code>SPX</code> or relative size <code>SPC</code>. I.e. if <code>SPC</code> has a small value, the coarse map is small, resulting in large rectangles being dropped.</td>
</tr>
<tr>
<td>ReplaceElementwise(M, R, PCH)</td>
<td>Replaces pixels in an image by replacements <code>R</code>. Replaces the pixels identified by mask <code>M</code>. <code>M</code> can be a probability, e.g. <code>0.05</code> to replace 5% of all pixels. If <code>PCH</code> is true, then the mask will be sampled per image, pixel <em>and additionally channel</em>.</td>
</tr>
<tr>
<td>ImpulseNoise(P)</td>
<td>Replaces <code>P</code> percent of all pixels with impulse noise, i.e. very light/dark RGB colors. This is an alias for <code>SaltAndPepper(P, PCH=True)</code>.</td>
</tr>
<tr>
<td>SaltAndPepper(P, PCH)</td>
<td>Replaces <code>P</code> percent of all pixels with very white or black colors. If <code>PCH</code> is true, then different pixels will be replaced per channel.</td>
</tr>
<tr>
<td>CoarseSaltAndPepper(P, SPX, SPC, PCH)</td>
<td>Similar to <code>CoarseDropout</code>, but instead of setting regions to zero, they are replaced by very white or black colors. If <code>PCH</code> is true, then the coarse replacement masks are sampled once per image and channel.</td>
</tr>
<tr>
<td>Salt(P, PCH)</td>
<td>Similar to <code>SaltAndPepper</code>, but only replaces with very white colors, i.e. no black colors.</td>
</tr>
<tr>
<td>CoarseSalt(P, SPX, SPC, PCH)</td>
<td>Similar to <code>CoarseSaltAndPepper</code>, but only replaces with very white colors, i.e. no black colors.</td>
</tr>
<tr>
<td>Pepper(P, PCH)</td>
<td>Similar to <code>SaltAndPepper</code>, but only replaces with very black colors, i.e. no white colors.</td>
</tr>
<tr>
<td>CoarsePepper(P, SPX, SPC, PCH)</td>
<td>Similar to <code>CoarseSaltAndPepper</code>, but only replaces with very black colors, i.e. no white colors.</td>
</tr>
<tr>
<td>Invert(P, PCH)</td>
<td>Inverts with probability <code>P</code> all pixels in an image, i.e. sets them to (1-pixel_value). If <code>PCH</code> is true, each channel is treated individually (leading to only some channels being inverted).</td>
</tr>
<tr>
<td>ContrastNormalization(S, PCH)</td>
<td>Changes the contrast in images, by moving pixel values away or closer to 128. The direction and strength is defined by <code>S</code>. If <code>PCH</code> is set to true, the process happens channel-wise with possibly different <code>S</code>.</td>
</tr>
<tr>
<td>JpegCompression(C)</td>
<td>Applies JPEG compression of strength <code>C</code> (value range: 0 to 100) to an image. Higher values of <code>C</code> lead to more visual artifacts.</td>
</tr>
</tbody>
</table>
<p><strong>blend</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Alpha(A, FG, BG, PCH)</td>
<td>Augments images using augmenters <code>FG</code> and <code>BG</code> independently, then blends the result using alpha <code>A</code>. Both <code>FG</code> and <code>BG</code> default to doing nothing if not provided. E.g. use <code>Alpha(0.9, FG)</code> to augment images via <code>FG</code>, then blend the result, keeping 10% of the original image (before <code>FG</code>). If <code>PCH</code> is set to true, the process happens channel-wise with possibly different <code>A</code> (<code>FG</code> and <code>BG</code> are computed once per image).</td>
</tr>
<tr>
<td>AlphaElementwise(A, FG, BG, PCH)</td>
<td>Same as <code>Alpha</code>, but performs the blending pixel-wise using a continuous mask (values 0.0 to 1.0) sampled from <code>A</code>. If <code>PCH</code> is set to true, the process happens both pixel- and channel-wise.</td>
</tr>
<tr>
<td>SimplexNoiseAlpha(FG, BG, PCH, SM, UP, I, AGG, SIG, SIGT)</td>
<td>Similar to <code>Alpha</code>, but uses a mask to blend the results from augmenters <code>FG</code> and <code>BG</code>. The mask is sampled from simplex noise, which tends to be blobby. The mask is gathered in <code>I</code> iterations (default: <code>1 to 3</code>), each iteration is combined using aggregation method <code>AGG</code> (default <code>max</code>, i.e. maximum value from all iterations per pixel). Each mask is sampled in low resolution space with max resolution <code>SM</code> (default 2 to 16px) and upscaled to image size using method <code>UP</code> (default: linear or cubic or nearest neighbour upsampling). If <code>SIG</code> is true, a sigmoid is applied to the mask with threshold <code>SIGT</code>, which makes the blobs have values closer to 0.0 or 1.0.</td>
</tr>
<tr>
<td>FrequencyNoiseAlpha(E, FG, BG, PCH, SM, UP, I, AGG, SIG, SIGT)</td>
<td>Similar to <code>SimplexNoiseAlpha</code>, but generates noise masks from the frequency domain. Exponent <code>E</code> is used to increase/decrease frequency components. High values for <code>E</code> pronounce high frequency components. Use values in the range -4 to 4, with -2 roughly generated cloud-like patterns.</td>
</tr>
</tbody>
</table>
<p><strong>blur</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>GaussianBlur(S)</td>
<td>Blurs images using a gaussian kernel with size <code>S</code>.</td>
</tr>
<tr>
<td>AverageBlur(K)</td>
<td>Blurs images using a simple averaging kernel with size <code>K</code>.</td>
</tr>
<tr>
<td>MedianBlur(K)</td>
<td>Blurs images using a median over neihbourhoods of size <code>K</code>.</td>
</tr>
<tr>
<td>BilateralBlur(D, SC, SS)</td>
<td>Blurs images using a bilateral filter with distance <code>D</code> (like kernel size). <code>SC</code> is a sigma for the (influence) distance in color space, <code>SS</code> a sigma for the spatial distance.</td>
</tr>
<tr>
<td>MotionBlur(K, A, D, O)</td>
<td>Blurs an image using a motion blur kernel with size <code>K</code>. <code>A</code> is the angle of the blur in degrees to the y-axis (value range: 0 to 360, clockwise). <code>D</code> is the blur direction (value range: -1.0 to 1.0, 1.0 is forward from the center). <code>O</code> is the interpolation order (<code>O=0</code> is fast, <code>O=1</code> slightly slower but more accurate).</td>
</tr>
</tbody>
</table>
<p><strong>color</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>WithColorspace(T, F, CH)</td>
<td>Converts images from colorspace <code>T</code> to <code>F</code>, applies child augmenters <code>CH</code> and then converts back from <code>F</code> to <code>T</code>.</td>
</tr>
<tr>
<td>AddToHueAndSaturation(V, PCH, F, C)</td>
<td>Adds value <code>V</code> to each pixel in HSV space (i.e. modifying hue and saturation). Converts from colorspace F to HSV (default is F=RGB). Selects channels C before augmenting (default is C=[0,1]). If <code>PCH</code> is true, then the sampled values may be different per channel.</td>
</tr>
<tr>
<td>ChangeColorspace(T, F, A)</td>
<td>Converts images from colorspace <code>F</code> to <code>T</code> and mixes with the original image using alpha <code>A</code>. Grayscale remains at three channels. (Fairly untested augmenter, use at own risk.)</td>
</tr>
<tr>
<td>Grayscale(A, F)</td>
<td>Converts images from colorspace F (default: RGB) to grayscale and mixes with the original image using alpha <code>A</code>.</td>
</tr>
</tbody>
</table>
<p><strong>contrast</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>GammaContrast(G, PCH)</td>
<td>Applies gamma contrast adjustment following <code>I_ij&apos; = I_ij**G&apos;</code>, where <code>G&apos;</code> is a gamma value sampled from <code>G</code> and <code>I_ij</code> a pixel (converted to 0 to 1.0 space). If <code>PCH</code> is true, a different <code>G&apos;</code> is sampled per image and channel.</td>
</tr>
<tr>
<td>SigmoidContrast(G, C, PCH)</td>
<td>Similar to GammaContrast, but applies <code>I_ij&apos; = 1/(1 + exp(G&apos; * (C&apos; - I_ij)))</code>, where <code>G&apos;</code> is a gain value sampled from <code>G</code> and <code>C&apos;</code> is a cutoff value sampled from <code>C</code>.</td>
</tr>
<tr>
<td>LogContrast(G, PCH)</td>
<td>Similar to GammaContrast, but applies <code>I_ij = G&apos; * log(1 + I_ij)</code>, where <code>G&apos;</code> is a gain value sampled from <code>G</code>.</td>
</tr>
<tr>
<td>LinearContrast(S, PCH)</td>
<td>Similar to GammaContrast, but applies <code>I_ij = 128 + S&apos; * (I_ij - 128)</code>, where <code>S&apos;</code> is a strength value sampled from <code>S</code>. This augmenter is identical to ContrastNormalization (which will be deprecated in the future).</td>
</tr>
<tr>
<td>AllChannelsHistogramEqualization()</td>
<td>Applies standard histogram equalization to each channel of each input image.</td>
</tr>
<tr>
<td>HistogramEqualization(F, T)</td>
<td>Similar to <code>AllChannelsHistogramEqualization</code>, but expects images to be in colorspace <code>F</code>, converts to colorspace <code>T</code> and normalizes only an intensity-related channel, e.g. <code>L</code> for <code>T=Lab</code> (default for <code>T</code>) or <code>V</code> for <code>T=HSV</code>.</td>
</tr>
<tr>
<td>AllChannelsCLAHE(CL, K, Kmin, PCH)</td>
<td>Contrast Limited Adaptive Histogram Equalization (histogram equalization in small image patches), applied to each image channel with clipping limit <code>CL</code> and kernel size <code>K</code> (clipped to range <code>[Kmin, inf)</code>). If <code>PCH</code> is true, different values for <code>CL</code> and <code>K</code> are sampled per channel.</td>
</tr>
<tr>
<td>CLAHE(CL, K, Kmin, F, T)</td>
<td>Similar to <code>HistogramEqualization</code>, this applies CLAHE only to intensity-related channels in Lab/HSV/HLS colorspace. (Usually this works significantly better than <code>AllChannelsCLAHE</code>.)</td>
</tr>
</tbody>
</table>
<p><strong>convolutional</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Convolve(M)</td>
<td>Convolves images with matrix <code>M</code>, which can be a lambda function.</td>
</tr>
<tr>
<td>Sharpen(A, L)</td>
<td>Runs a sharpening kernel over each image with lightness <code>L</code> (low values result in dark images). Mixes the result with the original image using alpha <code>A</code>.</td>
</tr>
<tr>
<td>Emboss(A, S)</td>
<td>Runs an emboss kernel over each image with strength <code>S</code>. Mixes the result with the original image using alpha <code>A</code>.</td>
</tr>
<tr>
<td>EdgeDetect(A)</td>
<td>Runs an edge detection kernel over each image. Mixes the result with the original image using alpha <code>A</code>.</td>
</tr>
<tr>
<td>DirectedEdgeDetect(A, D)</td>
<td>Runs a directed edge detection kernel over each image, which detects each from direction <code>D</code> (default: random direction from 0 to 360 degrees, chosen per image). Mixes the result with the original image using alpha <code>A</code>.</td>
</tr>
</tbody>
</table>
<p><strong>flip</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fliplr(P)</td>
<td>Horizontally flips images with probability <code>P</code>.</td>
</tr>
<tr>
<td>Flipud(P)</td>
<td>Vertically flips images with probability <code>P</code>.</td>
</tr>
</tbody>
</table>
<p><strong>geometric</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Affine(S, TPX, TPC, R, SH, O, CVAL, FO, M, B)</td>
<td>Applies affine transformations to images. Scales them by <code>S</code> (&gt;1=zoom in, &lt;1=zoom out), translates them by <code>TPX</code> pixels or <code>TPC</code> percent, rotates them by <code>R</code> degrees and shears them by <code>SH</code> degrees. Interpolation happens with order <code>O</code> (0 or 1 are good and fast). If <code>FO</code> is true, the output image plane size will be fitted to the distorted image size, i.e. images rotated by 45deg will not be partially outside of the image plane. <code>M</code> controls how to handle pixels in the output image plane that have no correspondence in the input image plane. If <code>M=&apos;constant&apos;</code> then <code>CVAL</code> defines a constant value with which to fill these pixels. <code>B</code> allows to set the backend framework (currently <code>cv2</code> or <code>skimage</code>).</td>
</tr>
<tr>
<td>AffineCv2(S, TPX, TPC, R, SH, O, CVAL, M, B)</td>
<td>Same as Affine, but uses only <code>cv2</code> as its backend. Currently does not support <code>FO=true</code>. Might be deprecated in the future.</td>
</tr>
<tr>
<td>PiecewiseAffine(S, R, C, O, M, CVAL)</td>
<td>Places a regular grid of points on the image. The grid has <code>R</code> rows and <code>C</code> columns. Then moves the points (and the image areas around them) by amounts that are samples from normal distribution N(0,<code>S</code>), leading to local distortions of varying strengths. <code>O</code>, <code>M</code> and <code>CVAL</code> are defined as in <code>Affine</code>.</td>
</tr>
<tr>
<td>PerspectiveTransform(S, KS)</td>
<td>Applies a random four-point perspective transform to the image (kinda like an advanced form of cropping). Each point has a random distance from the image corner, derived from a normal distribution with sigma <code>S</code>. If <code>KS</code> is set to True (default), each image will be resized back to its original size.</td>
</tr>
<tr>
<td>ElasticTransformation(S, SM, O, CVAL, M)</td>
<td>Moves each pixel individually around based on distortion fields. <code>SM</code> defines the smoothness of the distortion field and <code>S</code> its strength. <code>O</code> is the interpolation order, <code>CVAL</code> a constant fill value for newly created pixels and <code>M</code> the fill mode (see also augmenter <code>Affine</code>).</td>
</tr>
<tr>
<td>Rot90(K, KS)</td>
<td>Rotate images <code>K</code> times clockwise by 90 degrees. (This is faster than <code>Affine</code>.) If <code>KS</code> is true, the resulting image will be resized to have the same size as the original input image.</td>
</tr>
</tbody>
</table>
<p><strong>meta</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sequential(C, R)</td>
<td>Takes a list of child augmenters <code>C</code> and applies them in that order to images. If <code>R</code> is true (default: false), then the order is random (chosen once per batch).</td>
</tr>
<tr>
<td>SomeOf(N, C, R)</td>
<td>Applies <code>N</code> randomly selected augmenters from a list of augmenters <code>C</code> to each image. The augmenters are chosen per image. <code>R</code> is the same as for <code>Sequential</code>. <code>N</code> can be a range, e.g. <code>(1, 3)</code> in order to pick 1 to 3.</td>
</tr>
<tr>
<td>OneOf(C)</td>
<td>Identical to <code>SomeOf(1, C)</code>.</td>
</tr>
<tr>
<td>Sometimes(P, C, D)</td>
<td>Augments images with probability <code>P</code> by using child augmenters <code>C</code>, otherwise uses <code>D</code>. <code>D</code> can be None, then only <code>P</code> percent of all images are augmented via <code>C</code>.</td>
</tr>
<tr>
<td>WithColorspace(T, F, C)</td>
<td>Transforms images from colorspace <code>F</code> (default: RGB) to colorspace <code>T</code>, applies augmenters <code>C</code> and then converts back to <code>F</code>.</td>
</tr>
<tr>
<td>WithChannels(H, C)</td>
<td>Selects from each image channels <code>H</code> (e.g. <code>[0,1]</code> for red and green in RGB images), applies child augmenters <code>C</code> to these channels and merges the result back into the original images.</td>
</tr>
<tr>
<td>Noop()</td>
<td>Does nothing. (Useful for validation/test.)</td>
</tr>
<tr>
<td>Lambda(I, K)</td>
<td>Applies lambda function <code>I</code> to images and <code>K</code> to keypoints.</td>
</tr>
<tr>
<td>AssertLambda(I, K)</td>
<td>Checks images via lambda function <code>I</code> and keypoints via <code>K</code> and raises an error if false is returned by either of them.</td>
</tr>
<tr>
<td>AssertShape(S)</td>
<td>Raises an error if input images are not of shape <code>S</code>.</td>
</tr>
<tr>
<td>ChannelShuffle(P, C)</td>
<td>Permutes the order of the color channels for <code>P</code> percent of all images. Shuffles by default all channels, but may restrict to a subset using <code>C</code> (list of channel indices).</td>
</tr>
</tbody>
</table>
<p><strong>segmentation</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Superpixels(P, N, M)</td>
<td>Generates N superpixels of the image at (max) resolution M and resizes back to the original size. Then <code>P</code> percent of all superpixel areas in the original image are replaced by the superpixel. (1-P) percent remain unaltered.</td>
</tr>
</tbody>
</table>
<p><strong>size</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Resize(S, I)</td>
<td>Resizes images to size <code>S</code>. Common use case would be to use <code>S={&quot;height&quot;:H, &quot;width&quot;:W}</code> to resize all images to shape <code>HxW</code>. <code>H</code> and <code>W</code> may be floats (e.g. resize to <code>50%</code> of original size). Either <code>H</code> or <code>W</code> may be <code>&quot;keep-aspect-ratio&quot;</code> to define only one side&apos;s new size and resize the other side correspondingly. <code>I</code> is the interpolation to use (default: <code>cubic</code>).</td>
</tr>
<tr>
<td>CropAndPad(PX, PC, PM, PCV, KS)</td>
<td>Crops away or pads <code>PX</code> pixels or <code>PC</code> percent of pixels at top/right/bottom/left of images. Negative values result in cropping, positive in padding. <code>PM</code> defines the pad mode (e.g. use uniform color for all added pixels). <code>PCV</code> controls the color of added pixels if <code>PM=constant</code>. If <code>KS</code> is true (default), the resulting image is resized back to the original size.</td>
</tr>
<tr>
<td>Pad(PX, PC, PM, PCV, KS)</td>
<td>Shortcut for CropAndPad(), which only adds pixels. Only positive values are allowed for <code>PX</code> and <code>PC</code>.</td>
</tr>
<tr>
<td>Crop(PX, PC, KS)</td>
<td>Shortcut for CropAndPad(), which only crops away pixels. Only positive values are allowed for <code>PX</code> and <code>PC</code> (e.g. a value of 5 results in 5 pixels cropped away).</td>
</tr>
<tr>
<td>PadToFixedSize(W, H, PM, PCV, POS)</td>
<td>Pads all images up to height <code>H</code> and width <code>W</code>. <code>PM</code> and <code>PCV</code> are the same as in <code>Pad</code>. <code>POS</code> defines the position around which to pad, e.g. <code>POS=&quot;center&quot;</code> pads equally on all sides, <code>POS=&quot;left-top&quot;</code> pads only the top and left sides.</td>
</tr>
<tr>
<td>CropToFixedSize(W, H, POS)</td>
<td>Similar to <code>PadToFixedSize</code>, but crops down to height <code>H</code> and width <code>W</code> instead of padding.</td>
</tr>
<tr>
<td>KeepSizeByResize(CH, I, IH)</td>
<td>Applies child augmenters <code>CH</code> (e.g. cropping) and afterwards resizes all images back to their original size. <code>I</code> is the interpolation used for images, <code>IH</code> the interpolation used for heatmaps.</td>
</tr>
</tbody>
</table>
<p><strong>weather</strong></p>
<table>
<thead>
<tr>
<th>Augmenter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>FastSnowyLandscape(LT, LM)</td>
<td>Converts landscape images to snowy landscapes by increasing in HLS colorspace the lightness <code>L</code> of all pixels with <code>L&lt;LT</code> by a factor of <code>LM</code>.</td>
</tr>
<tr>
<td>Clouds()</td>
<td>Adds clouds of various shapes and densities to images. Can be senseful to be combined with an <em>overlay</em> augmenter, e.g. <code>SimplexNoiseAlpha</code>.</td>
</tr>
<tr>
<td>Fog()</td>
<td>Adds fog-like cloud structures of various shapes and densities to images. Can be senseful to be combined with an <em>overlay</em> augmenter, e.g. <code>SimplexNoiseAlpha</code>.</td>
</tr>
<tr>
<td>CloudLayer(IM, IFE, ICS, AMIN, AMUL, ASPXM, AFE, S, DMUL)</td>
<td>Adds a single layer of clouds to an image. <code>IM</code> is the mean intensity of the clouds, <code>IFE</code> a frequency noise exponent for the intensities (leading to non-uniform colors), <code>ICS</code> controls the variance of a gaussian for intensity sampling, <code>AM</code> is the minimum opacity of the clouds (values &gt;0 are typical of fog), <code>AMUL</code> a multiplier for opacity values, <code>ASPXM</code> controls the minimum grid size at which to sample opacity values, <code>AFE</code> is a frequency noise exponent for opacity values, <code>S</code> controls the sparsity of clouds and <code>DMUL</code> is a cloud density multiplier. This interface is not final and will likely change in the future.</td>
</tr>
<tr>
<td>Snowflakes(D, DU, FS, FSU, A, S)</td>
<td>Adds snowflakes with density <code>D</code>, density uniformity <code>DU</code>, snowflake size <code>FS</code>, snowflake size uniformity <code>FSU</code>, falling angle <code>A</code> and speed <code>S</code> to an image. One to three layers of snowflakes are added, hence the values should be stochastic.</td>
</tr>
<tr>
<td>SnowflakesLayer(D, DU, FS, FSU, A, S, BSF, BSL)</td>
<td>Adds a single layer of snowflakes to an image. See augmenter <code>Snowflakes</code>. <code>BSF</code> and <code>BSL</code> control a gaussian blur applied to the snowflakes.</td>
</tr>
</tbody>
</table>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="data.html" class="navigation navigation-prev " aria-label="Previous page: 数据增强">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../math/" class="navigation navigation-next " aria-label="Next page: 数学">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"imaaug 数据增强大杀器","level":"2.1.4","depth":2,"next":{"title":"数学","level":"2.2","depth":1,"path":"math/README.md","ref":"math/README.md","articles":[{"title":"矩阵总结","level":"2.2.1","depth":2,"path":"math/matrix.md","ref":"math/matrix.md","articles":[]},{"title":"分布","level":"2.2.2","depth":2,"path":"math/distribution_show.md","ref":"math/distribution_show.md","articles":[]},{"title":"仿射变换","level":"2.2.3","depth":2,"path":"math/affine_transformation.md","ref":"math/affine_transformation.md","articles":[]},{"title":"图的基本概念","level":"2.2.4","depth":2,"path":"math/graph.md","ref":"math/graph.md","articles":[]}]},"previous":{"title":"数据增强","level":"2.1.3","depth":2,"path":"data/data.md","ref":"data/data.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-search","search-pro","back-to-top-button","expandable-chapters-small","back-to-top-button","chapter-fold","expandable-chapters-small","github","katex","include-codeblock","livereload"],"root":"./content","styles":{"website":"assets/styles/website.less","ebook":"assets/styles/ebook.less","pdf":"assets/styles/pdf.less","mobi":"assets/styles/mobi.less","epub":"assets/styles/epub.less"},"pluginsConfig":{"chapter-fold":{},"prism":{"css":["prismjs/themes/prism-solarizedlight.css"],"lang":{"flow":"typescript"}},"github":{"url":"https://github.com/OUCMachineLearning/OUCML"},"livereload":{},"search-pro":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"katex":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"expandable-chapters-small":{},"include-codeblock":{"check":false,"edit":false,"fixlang":false,"lang":"","template":"default","theme":"chrome","unindent":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"language":"zh-hans","gitbook":"*"},"file":{"path":"data/imaaug.md","mtime":"2019-10-24T04:35:18.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-10-25T10:54:29.358Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

