
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Tensor to img && imge to tensor · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../../linux/" />
    
    
    <link rel="prev" href="SPP.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../../introduction/0.html">
            
                <a href="../../introduction/0.html">
            
                    
                    送给研一入学的你们—炼丹师入门手册
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../introduction/AI_system.html">
            
                <a href="../../introduction/AI_system.html">
            
                    
                    为什么要使得AI System具备可解释性呢？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../">
            
                <a href="../">
            
                    
                    编程技巧
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../python/python_technique.html">
            
                <a href="../python/python_technique.html">
            
                    
                    python编程技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../python/sort.html">
            
                <a href="../python/sort.html">
            
                    
                    python常见排序
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../python/opencv.html">
            
                <a href="../python/opencv.html">
            
                    
                    opencv-python极速入门
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="pytorch1.html">
            
                <a href="pytorch1.html">
            
                    
                    pytorch常用代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="pytorch2.html">
            
                <a href="pytorch2.html">
            
                    
                    pytorch常用代码段合集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="pytorch_train.html">
            
                <a href="pytorch_train.html">
            
                    
                    pytorch训练技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="pytorch_.html">
            
                <a href="pytorch_.html">
            
                    
                    pytorch解冻
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="pytorch_vision.html">
            
                <a href="pytorch_vision.html">
            
                    
                    pytorch网络可视化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.9" data-path="PSNR_SSIM.html">
            
                <a href="PSNR_SSIM.html">
            
                    
                    PSNR&&SSIM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.10" data-path="SPP.html">
            
                <a href="SPP.html">
            
                    
                    SPP
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.4.11" data-path="Tensor_to_img_imge_to_tensor.html">
            
                <a href="Tensor_to_img_imge_to_tensor.html">
            
                    
                    Tensor to img && imge to tensor
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../../linux/">
            
                <a href="../../linux/">
            
                    
                    Linux
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../../linux/linux_technique.html">
            
                <a href="../../linux/linux_technique.html">
            
                    
                    Linux技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../../linux/linux_GPU.html">
            
                <a href="../../linux/linux_GPU.html">
            
                    
                    Linux显卡驱动修复
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../../paper/">
            
                <a href="../../paper/">
            
                    
                    论文
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../../paper/paper_write.html">
            
                <a href="../../paper/paper_write.html">
            
                    
                    论文写作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../../paper/Image_to_Image.html">
            
                <a href="../../paper/Image_to_Image.html">
            
                    
                    Image-to-Image 的论文汇总（含 GitHub 代码）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../../paper/GNN.html">
            
                <a href="../../paper/GNN.html">
            
                    
                    GNN综述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../../paper/Perceptual_GAN_for_Small_Object_Detection.html">
            
                <a href="../../paper/Perceptual_GAN_for_Small_Object_Detection.html">
            
                    
                    Perceptual GAN for Small Object Detection阅读笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.5" data-path="../../paper/GMMN.html">
            
                <a href="../../paper/GMMN.html">
            
                    
                    GAN变体-GMMN 网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6" data-path="../../paper/Deformable_Kernels.html">
            
                <a href="../../paper/Deformable_Kernels.html">
            
                    
                    图像视频去噪中的Deformable Kernels
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.7" data-path="../../paper/Isolating_Sources_of_Disentanglement_in_VAEs.html">
            
                <a href="../../paper/Isolating_Sources_of_Disentanglement_in_VAEs.html">
            
                    
                    Isolating Sources of Disentanglement in VAEs
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.8" data-path="../../paper/Spectral_Normalization.html">
            
                <a href="../../paper/Spectral_Normalization.html">
            
                    
                    Spectral Normalization 谱归一化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9" data-path="../../paper/Unbalanced_sample_loss.html">
            
                <a href="../../paper/Unbalanced_sample_loss.html">
            
                    
                    不均衡样本loss
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10" data-path="../../paper/NN.html">
            
                <a href="../../paper/NN.html">
            
                    
                    论文神经网络示意图
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../../super_resolution/">
            
                <a href="../../super_resolution/">
            
                    
                    超分辨率
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../../super_resolution/SR_summarize.html">
            
                <a href="../../super_resolution/SR_summarize.html">
            
                    
                    超分辨率方向综述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../../super_resolution/SR.html">
            
                <a href="../../super_resolution/SR.html">
            
                    
                    超分辨率技术
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../../super_resolution/code_dataset.html">
            
                <a href="../../super_resolution/code_dataset.html">
            
                    
                    超分辨率代码数据集合集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="../../super_resolution/baseline.html">
            
                <a href="../../super_resolution/baseline.html">
            
                    
                    超分辨率baseline
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="../../super_resolution/loss.html">
            
                <a href="../../super_resolution/loss.html">
            
                    
                    超分辨率的损失函数总结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../../data/">
            
                <a href="../../data/">
            
                    
                    图片和数据处理
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="../../data/picture.html">
            
                <a href="../../data/picture.html">
            
                    
                    图片处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="../../data/picture_enhance.html">
            
                <a href="../../data/picture_enhance.html">
            
                    
                    图像数据增强
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="../../data/data.html">
            
                <a href="../../data/data.html">
            
                    
                    数据增强
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.4" data-path="../../data/imaaug.html">
            
                <a href="../../data/imaaug.html">
            
                    
                    imaaug 数据增强大杀器
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../../math/">
            
                <a href="../../math/">
            
                    
                    数学
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="../../math/matrix.html">
            
                <a href="../../math/matrix.html">
            
                    
                    矩阵总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="../../math/distribution_show.html">
            
                <a href="../../math/distribution_show.html">
            
                    
                    分布
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.3" data-path="../../math/affine_transformation.html">
            
                <a href="../../math/affine_transformation.html">
            
                    
                    仿射变换
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.4" data-path="../../math/graph.html">
            
                <a href="../../math/graph.html">
            
                    
                    图的基本概念
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../../other/">
            
                <a href="../../other/">
            
                    
                    其他
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="../../other/discriminator_train.html">
            
                <a href="../../other/discriminator_train.html">
            
                    
                    判别器训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="../../other/FLOPS.html">
            
                <a href="../../other/FLOPS.html">
            
                    
                    网络FLOPS计算
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >Tensor to img && imge to tensor</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="tensor-to-img--imge-to-tensor">Tensor to img &amp;&amp; imge to tensor</h1>
<p>&#x5728;pytorch&#x4E2D;&#x7ECF;&#x5E38;&#x4F1A;&#x9047;&#x5230;&#x56FE;&#x50CF;&#x683C;&#x5F0F;&#x7684;&#x8F6C;&#x5316;&#xFF0C;&#x4F8B;&#x5982;&#x5C06;PIL&#x5E93;&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x8F6C;&#x5316;&#x4E3A;Tensor&#xFF0C;&#x4EA6;&#x6216;&#x8005;&#x5C06;Tensor&#x8F6C;&#x5316;&#x4E3A;numpy&#x683C;&#x5F0F;&#x7684;&#x56FE;&#x7247;&#x3002;&#x800C;&#x4E14;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x5E93;&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x683C;&#x5F0F;&#x4E5F;&#x4E0D;&#x76F8;&#x540C;&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x5982;&#x4F55;&#x5728;pytorch&#x4E2D;&#x6B63;&#x786E;&#x8F6C;&#x5316;&#x5404;&#x79CD;&#x56FE;&#x7247;&#x683C;&#x5F0F;(PIL&#x3001;numpy&#x3001;Tensor)&#x662F;&#x4E00;&#x4E2A;&#x5728;&#x8C03;&#x8BD5;&#x4E2D;&#x6BD4;&#x8F83;&#x91CD;&#x8981;&#x7684;&#x95EE;&#x9898;&#x3002;</p>
<p>&#x672C;&#x6587;&#x4E3B;&#x8981;&#x8BF4;&#x660E;&#x5728;pytorch&#x4E2D;&#x5982;&#x4F55;&#x6B63;&#x786E;&#x5C06;&#x56FE;&#x7247;&#x683C;&#x5F0F;&#x5728;&#x5404;&#x79CD;&#x56FE;&#x50CF;&#x5E93;&#x8BFB;&#x53D6;&#x683C;&#x5F0F;&#x4EE5;&#x53CA;tensor&#x5411;&#x91CF;&#x4E4B;&#x95F4;&#x8F6C;&#x5316;&#x7684;&#x95EE;&#x9898;&#x3002;&#x4EE5;&#x4E0B;&#x4EE3;&#x7801;&#x7ECF;&#x8FC7;&#x6D4B;&#x8BD5;&#x90FD;&#x53EF;&#x4EE5;&#x5728;Pytorch-0.4.0&#x6216;0.3.0&#x7248;&#x672C;&#x76F4;&#x63A5;&#x4F7F;&#x7528;&#x3002;</p>
<p>&#x5BF9;python&#x4E0D;&#x540C;&#x7684;&#x56FE;&#x50CF;&#x5E93;&#x8BFB;&#x53D6;&#x683C;&#x5F0F;&#x6709;&#x7591;&#x95EE;&#x53EF;&#x4EE5;&#x770B;&#x8FD9;&#x91CC;&#xFF1A;<a href="https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image" target="_blank">https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image</a></p>
<h1 id="&#x683C;&#x5F0F;&#x8F6C;&#x6362;">&#x683C;&#x5F0F;&#x8F6C;&#x6362;</h1>
<p>&#x6211;&#x4EEC;&#x4E00;&#x822C;&#x5728;pytorch&#x6216;&#x8005;python&#x4E2D;&#x5904;&#x7406;&#x7684;&#x56FE;&#x50CF;&#x65E0;&#x975E;&#x8FD9;&#x51E0;&#x79CD;&#x683C;&#x5F0F;&#xFF1A;</p>
<ul>
<li>PIL&#xFF1A;&#x4F7F;&#x7528;python&#x81EA;&#x5E26;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x5E93;&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x683C;&#x5F0F;</li>
<li>numpy&#xFF1A;&#x4F7F;&#x7528;python-opencv&#x5E93;&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x683C;&#x5F0F;</li>
<li>tensor&#xFF1A;pytorch&#x4E2D;&#x8BAD;&#x7EC3;&#x65F6;&#x6240;&#x91C7;&#x53D6;&#x7684;&#x5411;&#x91CF;&#x683C;&#x5F0F;&#xFF08;&#x5F53;&#x7136;&#x4E5F;&#x53EF;&#x4EE5;&#x8BF4;&#x56FE;&#x7247;&#xFF09;</li>
</ul>
<p>&#x6CE8;&#x610F;&#xFF0C;&#x4E4B;&#x540E;&#x7684;&#x8BB2;&#x89E3;&#x56FE;&#x7247;&#x683C;&#x5F0F;&#x7686;&#x4E3A;RGB&#x4E09;&#x901A;&#x9053;&#xFF0C;24-bit&#x771F;&#x5F69;&#x8272;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x6211;&#x4EEC;&#x5E73;&#x5E38;&#x4F7F;&#x7528;&#x7684;&#x56FE;&#x7247;&#x5F62;&#x5F0F;&#x3002;</p>
<h2 id="pil&#x4E0E;tensor">PIL&#x4E0E;Tensor</h2>
<p>PIL&#x4E0E;Tensor&#x7684;&#x8F6C;&#x6362;&#x76F8;&#x5BF9;&#x5BB9;&#x6613;&#x4E9B;&#xFF0C;&#x56E0;&#x4E3A;pytorch&#x5DF2;&#x7ECF;&#x63D0;&#x4F9B;&#x4E86;&#x76F8;&#x5173;&#x7684;&#x4EE3;&#x7801;&#xFF0C;&#x6211;&#x4EEC;&#x53EA;&#x9700;&#x8981;&#x642D;&#x914D;&#x4F7F;&#x7528;&#x5373;&#x53EF;&#xFF1A;</p>
<p>&#x6240;&#x6709;&#x4EE3;&#x7801;&#x90FD;&#x5DF2;&#x7ECF;&#x5F15;&#x7528;&#x4E86;&#xFF08;&#x4E4B;&#x540E;&#x7684;&#x4EE3;&#x7801;&#x7701;&#x7565;&#x5F15;&#x7528;&#x90E8;&#x5206;&#xFF09;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-comment"># loader&#x4F7F;&#x7528;torchvision&#x4E2D;&#x81EA;&#x5E26;&#x7684;transforms&#x51FD;&#x6570;</span>
loader = transforms.Compose([
    transforms.ToTensor()])  

unloader = transforms.ToPILImage()
</code></pre>
<h3 id="1-pil&#x8BFB;&#x53D6;&#x56FE;&#x7247;&#x8F6C;&#x5316;&#x4E3A;tensor">1 PIL&#x8BFB;&#x53D6;&#x56FE;&#x7247;&#x8F6C;&#x5316;&#x4E3A;Tensor</h3>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8F93;&#x5165;&#x56FE;&#x7247;&#x5730;&#x5740;</span>
<span class="hljs-comment"># &#x8FD4;&#x56DE;tensor&#x53D8;&#x91CF;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">image_loader</span><span class="hljs-params">(image_name)</span>:</span>
    image = Image.open(image_name).convert(<span class="hljs-string">&apos;RGB&apos;</span>)
    image = loader(image).unsqueeze(<span class="hljs-number">0</span>)
    <span class="hljs-keyword">return</span> image.to(device, torch.float)
</code></pre>
<h3 id="2-&#x5C06;pil&#x56FE;&#x7247;&#x8F6C;&#x5316;&#x4E3A;tensor">2 &#x5C06;PIL&#x56FE;&#x7247;&#x8F6C;&#x5316;&#x4E3A;Tensor</h3>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8F93;&#x5165;PIL&#x683C;&#x5F0F;&#x56FE;&#x7247;</span>
<span class="hljs-comment"># &#x8FD4;&#x56DE;tensor&#x53D8;&#x91CF;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">PIL_to_tensor</span><span class="hljs-params">(image)</span>:</span>
    image = loader(image).unsqueeze(<span class="hljs-number">0</span>)
    <span class="hljs-keyword">return</span> image.to(device, torch.float)
</code></pre>
<h3 id="3-tensor&#x8F6C;&#x5316;&#x4E3A;pil&#x56FE;&#x7247;">3 Tensor&#x8F6C;&#x5316;&#x4E3A;PIL&#x56FE;&#x7247;</h3>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8F93;&#x5165;tensor&#x53D8;&#x91CF;</span>
<span class="hljs-comment"># &#x8F93;&#x51FA;PIL&#x683C;&#x5F0F;&#x56FE;&#x7247;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tensor_to_PIL</span><span class="hljs-params">(tensor)</span>:</span>
    image = tensor.cpu().clone()
    image = image.squeeze(<span class="hljs-number">0</span>)
    image = unloader(image)
    <span class="hljs-keyword">return</span> image
</code></pre>
<h3 id="4-&#x76F4;&#x63A5;&#x5C55;&#x793A;tensor&#x683C;&#x5F0F;&#x56FE;&#x7247;">4 &#x76F4;&#x63A5;&#x5C55;&#x793A;tensor&#x683C;&#x5F0F;&#x56FE;&#x7247;</h3>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">imshow</span><span class="hljs-params">(tensor, title=None)</span>:</span>
    image = tensor.cpu().clone()  <span class="hljs-comment"># we clone the tensor to not do changes on it</span>
    image = image.squeeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># remove the fake batch dimension</span>
    image = unloader(image)
    plt.imshow(image)
    <span class="hljs-keyword">if</span> title <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        plt.title(title)
    plt.pause(<span class="hljs-number">0.001</span>)  <span class="hljs-comment"># pause a bit so that plots are updated</span>
</code></pre>
<h3 id="5-&#x76F4;&#x63A5;&#x4FDD;&#x5B58;tensor&#x683C;&#x5F0F;&#x56FE;&#x7247;">5 &#x76F4;&#x63A5;&#x4FDD;&#x5B58;tensor&#x683C;&#x5F0F;&#x56FE;&#x7247;</h3>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_image</span><span class="hljs-params">(tensor, **para)</span>:</span>
    dir = <span class="hljs-string">&apos;results&apos;</span>
    image = tensor.cpu().clone()  <span class="hljs-comment"># we clone the tensor to not do changes on it</span>
    image = image.squeeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># remove the fake batch dimension</span>
    image = unloader(image)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> osp.exists(dir):
        os.makedirs(dir)
    image.save(<span class="hljs-string">&apos;results_{}/s{}-c{}-l{}-e{}-sl{:4f}-cl{:4f}.jpg&apos;</span>
               .format(num, para[<span class="hljs-string">&apos;style_weight&apos;</span>], para[<span class="hljs-string">&apos;content_weight&apos;</span>], para[<span class="hljs-string">&apos;lr&apos;</span>], para[<span class="hljs-string">&apos;epoch&apos;</span>],
                       para[<span class="hljs-string">&apos;style_loss&apos;</span>], para[<span class="hljs-string">&apos;content_loss&apos;</span>]))
</code></pre>
<h2 id="numpy&#x4E0E;tensor">numpy&#x4E0E;Tensor</h2>
<p>numpy&#x683C;&#x5F0F;&#x662F;&#x4F7F;&#x7528;cv2&#xFF0C;&#x4E5F;&#x5C31;&#x662F;python-opencv&#x5E93;&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x683C;&#x5F0F;&#xFF0C;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F;&#x7528;python-opencv&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x548C;&#x4F7F;&#x7528;PIL&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x6570;&#x636E;&#x7565;&#x5FAE;&#x4E0D;&#x540C;&#xFF0C;&#x7ECF;&#x6D4B;&#x8BD5;&#x7528;python-opencv&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x56FE;&#x7247;&#x5728;&#x8BAD;&#x7EC3;&#x65F6;&#x7684;&#x6548;&#x679C;&#x6BD4;&#x4F7F;&#x7528;PIL&#x8BFB;&#x53D6;&#x51FA;&#x6765;&#x7684;&#x7565;&#x5DEE;&#x4E00;&#x4E9B;(&#x8BE6;&#x7EC6;&#x8FC7;&#x7A0B;&#x4E4B;&#x540E;&#x53D1;&#x5E03;)&#x3002;</p>
<p>&#x4E4B;&#x540E;&#x6240;&#x6709;&#x4EE3;&#x7801;&#x5F15;&#x7528;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
</code></pre>
<h3 id="numpy&#x8F6C;&#x5316;&#x4E3A;tensor">numpy&#x8F6C;&#x5316;&#x4E3A;tensor</h3>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">toTensor</span><span class="hljs-params">(img)</span>:</span>
    <span class="hljs-keyword">assert</span> type(img) == np.ndarray,<span class="hljs-string">&apos;the img type is {}, but ndarry expected&apos;</span>.format(type(img))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = torch.from_numpy(img.transpose((<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)))
    <span class="hljs-keyword">return</span> img.float().div(<span class="hljs-number">255</span>).unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 255&#x4E5F;&#x53EF;&#x4EE5;&#x6539;&#x4E3A;256</span>
</code></pre>
<h3 id="tensor&#x8F6C;&#x5316;&#x4E3A;numpy">tensor&#x8F6C;&#x5316;&#x4E3A;numpy</h3>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tensor_to_np</span><span class="hljs-params">(tensor)</span>:</span>
    img = tensor.mul(<span class="hljs-number">255</span>).byte()
    img = img.cpu().numpy().squeeze(<span class="hljs-number">0</span>).transpose((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))
    <span class="hljs-keyword">return</span> img
</code></pre>
<h3 id="&#x5C55;&#x793A;numpy&#x683C;&#x5F0F;&#x56FE;&#x7247;">&#x5C55;&#x793A;numpy&#x683C;&#x5F0F;&#x56FE;&#x7247;</h3>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">show_from_cv</span><span class="hljs-params">(img, title=None)</span>:</span>
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure()
    plt.imshow(img)
    <span class="hljs-keyword">if</span> title <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        plt.title(title)
    plt.pause(<span class="hljs-number">0.001</span>)
</code></pre>
<h3 id="&#x5C55;&#x793A;tensor&#x683C;&#x5F0F;&#x56FE;&#x7247;">&#x5C55;&#x793A;tensor&#x683C;&#x5F0F;&#x56FE;&#x7247;</h3>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">show_from_tensor</span><span class="hljs-params">(tensor, title=None)</span>:</span>
    img = tensor.clone()
    img = tensor_to_np(img)
    plt.figure()
    plt.imshow(img)
    <span class="hljs-keyword">if</span> title <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        plt.title(title)
    plt.pause(<span class="hljs-number">0.001</span>)
</code></pre>
<h2 id="&#x6CE8;&#x610F;">&#x6CE8;&#x610F;</h2>
<p>&#x4E0A;&#x9762;&#x4ECB;&#x7ECD;&#x7684;&#x90FD;&#x662F;&#x4E00;&#x5F20;&#x56FE;&#x7247;&#x7684;&#x8F6C;&#x5316;&#xFF0C;&#x5982;&#x679C;&#x662F;n&#x5F20;&#x56FE;&#x7247;&#x4E00;&#x8D77;&#x7684;&#x8BDD;&#xFF0C;&#x53EA;&#x9700;&#x8981;&#x4FEE;&#x6539;&#x4E00;&#x4E0B;&#x76F8;&#x5E94;&#x4EE3;&#x7801;&#x5373;&#x53EF;&#x3002;</p>
<p>&#x4E3E;&#x4E2A;&#x4F8B;&#x5B50;&#xFF0C;&#x5C06;&#x4E4B;&#x524D;&#x8BF4;&#x8FC7;&#x7684;&#x4FEE;&#x6539;&#x7565;&#x5FAE;&#x4FEE;&#x6539;&#x4E00;&#x4E0B;&#x5373;&#x53EF;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5C06; N x H x W X C &#x7684;numpy&#x683C;&#x5F0F;&#x56FE;&#x7247;&#x8F6C;&#x5316;&#x4E3A;&#x76F8;&#x5E94;&#x7684;tensor&#x683C;&#x5F0F;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">toTensor</span><span class="hljs-params">(img)</span>:</span>
    img = torch.from_numpy(img.transpose((<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)))
    <span class="hljs-keyword">return</span> img.float().div(<span class="hljs-number">255</span>).unsqueeze(<span class="hljs-number">0</span>)
</code></pre>
<h1 id="orchvision-transforms-&#x603B;&#x7ED3;">orchvision transforms &#x603B;&#x7ED3;</h1>
<p>2018&#x5E74;11&#x6708;16&#x65E5; 17:00:04 <a href="https://me.csdn.net/Hansry" target="_blank">Hansry</a> &#x9605;&#x8BFB;&#x6570;&#xFF1A;2399</p>
<h2 id="&#x4E00;torchvisiontransforms">&#x4E00;.torchvision.transforms</h2>
<p>Transfoms &#x662F;&#x5F88;&#x5E38;&#x7528;&#x7684;&#x56FE;&#x7247;&#x53D8;&#x6362;&#x65B9;&#x5F0F;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;<code>compose</code>&#x5C06;&#x5404;&#x4E2A;&#x53D8;&#x6362;&#x4E32;&#x8054;&#x8D77;&#x6765;
<strong>1. class torchvision.transforms.Compose (transforms) </strong>
&#x8FD9;&#x4E2A;&#x7C7B;&#x5C06;&#x591A;&#x4E2A;&#x53D8;&#x6362;&#x65B9;&#x5F0F;&#x7ED3;&#x5408;&#x5728;&#x4E00;&#x8D77;
&#x53C2;&#x6570;&#xFF1A;&#x5404;&#x4E2A;&#x53D8;&#x6362;&#x7684;&#x5B9E;&#x4F8B;&#x5BF9;&#x8C61;
&#x4E3E;&#x4F8B;&#xFF1A;</p>
<pre><code>transforms.Compose([
            transforms.CenterCrop(10),
            transforms.ToTensor(), 
            ])
1234
</code></pre><h2 id="&#x4E8C;-&#x5728;pil&#x683C;&#x5F0F;&#x56FE;&#x7247;&#x4E0A;&#x7684;&#x8F6C;&#x6362;">&#x4E8C;. &#x5728;PIL&#x683C;&#x5F0F;&#x56FE;&#x7247;&#x4E0A;&#x7684;&#x8F6C;&#x6362;</h2>
<p><strong>1.class torchvision.transforms.CenterCrop(size)</strong>
&#x526A;&#x5207;&#x5E76;&#x8FD4;&#x56DE;PIL&#x56FE;&#x7247;&#x4E0A;&#x4E2D;&#x5FC3;&#x533A;&#x57DF;
&#x53C2;&#x6570;&#xFF1A;size (&#x5E8F;&#x5217;&#x6216;&#x8005;&#x6574;&#x578B;)&#x3000;&#x2014;&#x3000;&#x8F93;&#x51FA;&#x7684;&#x4E2D;&#x5FC3;&#x533A;&#x57DF;&#x7684;&#x5927;&#x5C0F;&#x3002;&#x5982;&#x679C;&#x8F93;&#x5165;&#x7684;size&#x662F;&#x6574;&#x578B;&#x800C;&#x4E0D;&#x662F;&#x7C7B;&#x4F3C;&#x4E8E; (h,w)&#x7684;&#x5E8F;&#x5217;&#xFF0C;&#x90A3;&#x4E48;&#x5C06;&#x4F1A;&#x8F6C;&#x6210;&#x7C7B;&#x4F3C;(size, size)&#x7684;&#x5E8F;&#x5217;&#x3002;</p>
<p><strong>2.class torchvision.transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)</strong>
&#x968F;&#x673A;&#x6539;&#x53D8;&#x56FE;&#x7247;&#x7684;&#x4EAE;&#x5EA6;&#x3001;&#x5BF9;&#x6BD4;&#x5EA6;&#x548C;&#x9971;&#x548C;&#x5EA6;
<strong>&#x53C2;&#x6570;&#xFF1A;</strong></p>
<ul>
<li>brightness(&#x4EAE;&#x5EA6;&#xFF0C;float&#x7C7B;&#x578B;)&#x2014;&#x2014;&#x8C03;&#x6574;&#x4EAE;&#x5EA6;&#x7684;&#x7A0B;&#x5EA6;&#xFF0C;&#x4EAE;&#x5EA6;&#x56E0;&#x5B50;(brightness_factor)&#x4ECE; <strong>[max(0,1-brightness), 1+brightness]</strong> &#x4E2D;&#x5747;&#x5300;&#x9009;&#x53D6;&#x3002;</li>
<li>contrast(&#x5BF9;&#x6BD4;&#x5EA6;&#xFF0C;float&#x7C7B;&#x578B;)&#x2014;&#x2014;&#x8C03;&#x6574;&#x5BF9;&#x6BD4;&#x5EA6;&#x7684;&#x7A0B;&#x5EA6;&#xFF0C;&#x5BF9;&#x6BD4;&#x5EA6;&#x56E0;&#x5B50;(contrast_factor)&#x4ECE; <strong>[max(0,1-contrast),1+contrast]</strong> &#x4E2D;&#x5747;&#x5300;&#x9009;&#x53D6;&#x3002;</li>
<li>saturation(&#x9971;&#x548C;&#x5EA6;&#xFF0C;float&#x7C7B;&#x578B;)&#x2014;&#x2014;&#x8C03;&#x6574;&#x9971;&#x548C;&#x5EA6;&#x7684;&#x7A0B;&#x5EA6;&#xFF0C;&#x9971;&#x548C;&#x5EA6;&#x56E0;&#x5B50;(saturation_factor) <strong>[max(0,1-saturation),1+saturation]</strong> &#x4E2D;&#x5747;&#x5300;&#x9009;&#x53D6;&#x3002;</li>
<li>hue(&#x8272;&#x76F8;&#xFF0C;float&#x7C7B;&#x578B;) &#x2014;&#x2014; &#x8C03;&#x6574;&#x8272;&#x76F8;&#x7684;&#x7A0B;&#x5EA6;&#xFF0C;&#x8272;&#x76F8;&#x56E0;&#x5B50;(hue_factor)&#x4ECE; <strong>[-hue,hue]</strong> &#x7B49;&#x5747;&#x5300;&#x9009;&#x62E9;, &#x5176;&#x4E2D;hue&#x7684;&#x5927;&#x5C0F;&#x4E3A; <strong>[0, 0.5]</strong>&#x3002;</li>
</ul>
<p><strong>&#x5BF9;&#x6BD4;&#x5EA6;&#xFF1A;</strong>&#x3000;&#x5BF9;&#x6BD4;&#x5EA6;&#x6307;&#x4E0D;&#x540C;&#x989C;&#x8272;&#x4E4B;&#x95F4;&#x7684;&#x5DEE;&#x522B;&#x3002;&#x5BF9;&#x6BD4;&#x5EA6;&#x8D8A;&#x5927;&#xFF0C;&#x4E0D;&#x540C;&#x989C;&#x8272;&#x4E4B;&#x95F4;&#x7684;&#x53CD;&#x5DEE;&#x8D8A;&#x5927;&#xFF0C;&#x6240;&#x8C13;&#x9ED1;&#x767D;&#x5206;&#x660E;&#xFF0C;&#x5BF9;&#x6BD4;&#x5EA6;&#x8FC7;&#x5927;&#xFF0C;&#x56FE;&#x50CF;&#x5C31;&#x4F1A;&#x663E;&#x5F97;&#x5F88;&#x523A;&#x773C;&#x3002;&#x5BF9;&#x6BD4;&#x5EA6;&#x8D8A;&#x5C0F;&#xFF0C;&#x4E0D;&#x540C;&#x989C;&#x8272;&#x4E4B;&#x95F4;&#x7684;&#x53CD;&#x5DEE;&#x5C31;&#x8D8A;&#x5C0F;&#x3002;
<strong>&#x4EAE;&#x5EA6;&#xFF1A;</strong>&#x3000;&#x4EAE;&#x5EA6;&#x662F;&#x6307;&#x7167;&#x5C04;&#x5728;&#x666F;&#x7269;&#x6216;&#x8005;&#x56FE;&#x50CF;&#x4E0A;&#x5149;&#x7EBF;&#x7684;&#x660E;&#x6697;&#x7A0B;&#x5EA6;&#xFF0C;&#x56FE;&#x50CF;&#x4EAE;&#x5EA6;&#x589E;&#x52A0;&#x65F6;&#xFF0C;&#x4F1A;&#x663E;&#x5F97;&#x523A;&#x773C;&#x6216;&#x8000;&#x773C;&#xFF0C;&#x4EAE;&#x5EA6;&#x8D8A;&#x5C0F;&#xFF0C;&#x4F1A;&#x663E;&#x5F97;&#x7070;&#x6697;&#x3002;
<strong>&#x8272;&#x76F8;&#xFF1A;</strong>&#x3000;&#x8272;&#x76F8;&#x5C31;&#x662F;&#x989C;&#x8272;&#xFF0C;&#x8C03;&#x6574;&#x8272;&#x76F8;&#x5C31;&#x662F;&#x8C03;&#x6574;&#x666F;&#x7269;&#x7684;&#x989C;&#x8272;&#x3002;
<strong>&#x9971;&#x548C;&#x5EA6;&#xFF1A;</strong>&#x3000;&#x9971;&#x548C;&#x5EA6;&#x6307;&#x56FE;&#x50CF;&#x989C;&#x8272;&#x7684;&#x6D53;&#x5EA6;&#x3002;&#x9971;&#x548C;&#x5EA6;&#x8D8A;&#x9AD8;&#xFF0C;&#x989C;&#x8272;&#x8D8A;&#x9971;&#x6EE1;&#xFF0C;&#x6240;&#x8C13;&#x7684;&#x9752;&#x7FE0;&#x6B32;&#x6EF4;&#x7684;&#x611F;&#x89C9;&#x3002;&#x9971;&#x548C;&#x5EA6;&#x8D8A;&#x4F4E;&#xFF0C;&#x989C;&#x8272;&#x5C31;&#x4F1A;&#x8D8A;&#x9648;&#x65E7;&#xFF0C;&#x60E8;&#x6DE1;&#xFF0C;&#x9971;&#x548C;&#x5EA6;&#x4E3A;0&#x65F6;&#xFF0C;&#x56FE;&#x50CF;&#x5C31;&#x4E3A;&#x7070;&#x5EA6;&#x56FE;&#x50CF;&#x3002;</p>
<p><strong>3. class torchvision.transforms.FiveCrop(size)</strong>
&#x5C06;&#x7ED9;&#x5B9A;&#x7684;PIL&#x56FE;&#x50CF;&#x526A;&#x88C1;&#x6210;&#x56DB;&#x4E2A;&#x89D2;&#x843D;&#x533A;&#x57DF;&#x548C;&#x4E2D;&#x5FC3;&#x533A;&#x57DF;
<strong>&#x6CE8;&#x610F;&#xFF1A;</strong>&#x3000;&#x8FD9;&#x4E2A;&#x53D8;&#x6362;&#x8FD4;&#x56DE;&#x7684;&#x662F;&#x4E00;&#x4E2A;&#x56FE;&#x50CF;&#x5143;&#x7EC4;(tuple of images), &#x56E0;&#x6B64;&#x5176;&#x8F93;&#x51FA;&#x8DDF;&#x8F93;&#x51FA;&#x7684;&#x6570;&#x91CF;&#x4F1A;&#x4E0D;&#x5339;&#x914D;&#x3002;
<strong>&#x53C2;&#x6570;&#xFF1A;</strong>&#x3000;size(&#x5E8F;&#x5217;&#x6216;&#x8005;&#x6574;&#x578B;) &#x2014;&#x2014; &#x9700;&#x8981;&#x8FD4;&#x56DE;&#x7684;&#x526A;&#x88C1;&#x533A;&#x57DF;&#x7684;&#x5C3A;&#x5BF8;&#x3002;&#x5982;&#x679C;&#x8F93;&#x5165;&#x7684;&#x662F;&#x6574;&#x578B;&#xFF0C;&#x90A3;&#x4E48;&#x4F1A;&#x88AB;&#x8F6C;&#x6210;(size,size)&#x5E8F;&#x5217;&#x3002;</p>
<p>&#x4F8B;&#x5B50;&#xFF1A;</p>
<pre><code>transform = Compose([
    FiveCrop(size),
    Lambda(lambda crops:torch.stack([ToTensor()(crop) for crop in crops]))  #return a 4D tensor
])
#in your test loop you can do the following:
input ,target = batch #input is a 5d tensor, target is 2d&#x3000;
bs, ncrops,c ,h ,w = input.size()   
result = model(input.view(-1,c,h,w))  &#x3000;#fuse batch size and ncrops  &#x8F6C;&#x6210;(bs*ncrops, c, h , w)
result_avg = result.view(bs, ncrops, -1).mean(1)      #avg over crops &#x8F6C;&#x6210;(bs&#xFF0C;ncrops, c*h*w)
123456789
</code></pre><p><strong>&#xFF14;. class torchvision.transforms.&#xFF27;rayscale(num_output_channels=1)</strong>
&#x5C06;&#x56FE;&#x7247;&#x8F6C;&#x6210;&#x7070;&#x5EA6;&#x56FE;
<strong>&#x53C2;&#x6570;&#xFF1A;</strong>&#x3000;num_output_channels(int) &#x2014;&#x2014;&#x3000;(1&#x6216;&#x8005;3)&#xFF0C;&#x8F93;&#x51FA;&#x56FE;&#x7247;&#x7684;&#x901A;&#x9053;&#x6570;&#x91CF;
<strong>&#x8FD4;&#x56DE;&#xFF1A;</strong>&#x3000;&#x8F93;&#x5165;&#x56FE;&#x7247;&#x7684;&#x7070;&#x5EA6;&#x56FE;&#xFF0C;&#x5982;&#x679C;num_output_channels=1, &#x8FD4;&#x56DE;&#x7684;&#x56FE;&#x7247;&#x4E3A;&#x5355;&#x901A;&#x9053;. &#x5982;&#x679C; num_output_channels=3, &#x8FD4;&#x56DE;&#x7684;&#x56FE;&#x7247;&#x4E3A;3&#x901A;&#x9053;&#x56FE;&#x7247;&#xFF0C;&#x4E14;r=g=b
&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;PIL&#x56FE;&#x7247;&#x7C7B;&#x578B;</p>
<p><strong>5.&#x3000;class torchvision.transforms.Pad(padding, fill=0, padding_mode=&#x2018;constant&#x2019;)</strong>
&#x5BF9;&#x7ED9;&#x5B9A;&#x7684;PIL&#x56FE;&#x50CF;&#x7684;&#x8FB9;&#x7F18;&#x8FDB;&#x884C;&#x586B;&#x5145;&#xFF0C;&#x586B;&#x5145;&#x7684;&#x6570;&#x503C;&#x4E3A;&#x7ED9;&#x5B9A;&#x586B;&#x5145;&#x6570;&#x503C;
<strong>&#x53C2;&#x6570;&#xFF1A;</strong></p>
<ul>
<li>padding(int&#x6216;&#x8005;tuple)&#x2014;&#x2014;&#x586B;&#x5145;&#x6BCF;&#x4E00;&#x4E2A;&#x8FB9;&#x754C;&#x3002;&#x5982;&#x679C;&#x53EA;&#x8F93;&#x5165;&#x4E86;&#x4E00;&#x4E2A;int&#x7C7B;&#x578B;&#x7684;&#x6570;&#x503C;&#xFF0C;&#x90A3;&#x4E48;&#x8FD9;&#x4E2A;&#x6570;&#x503C;&#x4F1A;&#x88AB;&#x7528;&#x6765;&#x586B;&#x5145;&#x6240;&#x6709;&#x7684;&#x8FB9;&#x754C;&#x3002;&#x5982;&#x679C;&#x8F93;&#x5165;&#x7684;&#x662F;tuple&#x4E14;&#x957F;&#x5EA6;&#x4E3A;2&#xFF0C;&#x90A3;&#x4E48;&#x4FE9;&#x4E2A;&#x6570;&#x503C;&#x5206;&#x522B;&#x88AB;&#x7528;&#x4E8E;&#x586B;&#x5145;left/right &#x548C; top/bottom&#x3002;&#x5982;&#x679C;&#x8F93;&#x5165;&#x7684;&#x6570;&#x7EC4;&#x4E3A;4&#xFF0C;&#x90A3;&#x4E48;&#x5206;&#x522B;&#x88AB;&#x7528;&#x6765;&#x586B;&#x5145;left, top ,right &#x548C; bottom&#x8FB9;&#x754C;&#x3002;</li>
<li>fill (int &#x6216;&#x8005; tuple) &#x2014;&#x2014;&#x3000;&#x586B;&#x5145;&#x7684;&#x50CF;&#x7D20;&#x7684;&#x6570;&#x503C;&#x4E3A;fill&#x3002;&#x9ED8;&#x8BA4;&#x4E3A;0&#xFF0C;&#x5982;&#x679C;&#x8F93;&#x5165;&#x7684;&#x5143;&#x7EC4;&#x7684;&#x957F;&#x5EA6;&#x4E3A;3&#xFF0C;&#x90A3;&#x4E48;&#x5206;&#x522B;&#x88AB;&#x7528;&#x6765;&#x586B;&#x5145;R,G,B&#x901A;&#x9053;&#x3002;&#x8FD9;&#x4E2A;&#x6570;&#x503C;&#x5F53;padding_mode &#x7B49;&#x4E8E;&#x2018;constant&#x2019;&#x3000;&#x7684;&#x65F6;&#x5019;&#x624D;&#x4F1A;&#x88AB;&#x4F7F;&#x7528;&#x3002;</li>
<li>padding_mode (string) &#x2014;&#x2014;&#x3000;&#x586B;&#x5145;&#x7684;&#x7C7B;&#x578B;&#xFF0C;&#x5FC5;&#x987B;&#x4E3A;&#xFF1A;constant, edge, reflect or symmetric&#xFF0C;&#x9ED8;&#x8BA4;&#x4E3A; constant.
  <strong>constant:</strong> &#x4EE5;&#x5E38;&#x91CF;&#x503C;&#x8FDB;&#x884C;&#x586B;&#x5145;&#xFF0C;&#x5E38;&#x91CF;&#x503C;&#x7531; fill &#x786E;&#x5B9A;&#x3002;
  <strong>edge:</strong> &#x7528;&#x56FE;&#x7247;&#x8FB9;&#x754C;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x503C;&#x8FDB;&#x884C;&#x586B;&#x5145;
  <strong>reflect:</strong> pads with reflection of image without repeating the last value on the edge (&#x8FD9;&#x53E5;&#x4E0D;&#x77E5;&#x600E;&#x4E48;&#x7FFB;&#x8BD1;&#xFF0C;&#x770B;&#x4E0B;&#x9762;&#x4F8B;&#x5B50;)
  &#x4F8B;&#x5B50;: &#x7528;&#x4FE9;&#x4E2A;&#x5143;&#x7D20;&#x586B;&#x5145;[1,2,3,4], &#x5C06;&#x4F1A;&#x8FD4;&#x56DE;[3,2,1,2,3,4,3,2]
  symmetric: pads with reflection of image repeating the last value on the edge
  &#x4F8B;&#x5B50;&#xFF1A;&#x7528;&#x4FE9;&#x4E2A;&#x51FD;&#x6570;&#x5143;&#x7D20;&#x586B;&#x5145; [1,2,3,4]&#xFF0C;&#x5C06;&#x4F1A;&#x8FD4;&#x56DE;[2,1,1,2,3,4,4,3]</li>
</ul>
<p><strong>6. class torchvision.transforms.RandomAffine(degrees, translate=None, scale=None)</strong>
&#x4FDD;&#x6301;&#x4E2D;&#x5FC3;&#x4E0D;&#x53D8;&#x7684;&#x5BF9;&#x56FE;&#x7247;&#x8FDB;&#x884C;&#x968F;&#x673A;&#x4EFF;&#x5C04;&#x53D8;&#x5316;
<strong>&#x53C2;&#x6570;&#xFF1A;</strong><a href="https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transforms" target="_blank">&#x6DFB;&#x52A0;&#x94FE;&#x63A5;&#x63CF;&#x8FF0;</a></p>
<ul>
<li>degree (&#x65CB;&#x8F6C;&#xFF0C;squence&#x6216;&#x8005;float&#x6216;&#x8005;int) &#x2014;&#x2014;&#x3000;&#x65CB;&#x8F6C;&#x7684;&#x89D2;&#x5EA6;&#x8303;&#x56F4;&#x3002;&#x5982;&#x679C;&#x89D2;&#x5EA6;&#x662F;&#x6570;&#x503C;&#x800C;&#x4E0D;&#x662F;&#x7C7B;&#x4F3C;&#x4E8E;(min,max)&#x7684;&#x5E8F;&#x5217;&#xFF0C;&#x90A3;&#x4E48;&#x5C06;&#x4F1A;&#x8F6C;&#x6362;&#x6210;(-degree, +degree)&#x5E8F;&#x5217;&#x3002;&#x8BBE;&#x4E3A;0&#x5219;&#x53D6;&#x6D88;&#x65CB;&#x8F6C;&#x3002;</li>
<li>transalate (&#x5E73;&#x79FB;&#xFF0C;tuple&#xFF0C;&#x53EF;&#x9009;)&#x3000;&#x2014;&#x2014;&#x3000;&#x6570;&#x7EC4;&#xFF0C;&#x5176;&#x4E2D;&#x5143;&#x7D20;&#x4E3A;&#x4EE3;&#x8868;&#x6C34;&#x5E73;&#x548C;&#x5782;&#x76F4;&#x53D8;&#x6362;&#x7684;&#x6700;&#x5927;&#x7EDD;&#x5BF9;&#x5206;&#x6570;&#x3002;&#x4F8B;&#x5982;translate=(a,b),&#x90A3;&#x4E48;&#x6C34;&#x5E73;&#x4F4D;&#x79FB;&#x6570;&#x503C;&#x4E3A;&#x4ECE;&#x3000;<strong>-image_widtha&lt;dx&lt;image_widtha</strong>&#x3000;&#x968F;&#x673A;&#x91C7;&#x6837;&#x7684;&#xFF0C;&#x540C;&#x65F6;&#x5782;&#x76F4;&#x4F4D;&#x79FB;&#x662F;&#x4ECE;&#x3000;<strong>-img_heightb&lt;dy&lt;image_heightb</strong> &#x968F;&#x673A;&#x91C7;&#x6837;&#x7684;&#x3002;&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#x6CA1;&#x6709;&#x5E73;&#x79FB;&#x3002;</li>
<li>scale (&#x7F29;&#x653E;&#xFF0C;tuple, &#x53EF;&#x9009;)&#x3000;&#x2014;&#x2014;&#x3000;&#x7F29;&#x653E;&#x56E0;&#x5B50;&#x533A;&#x95F4;&#x3002;&#x82E5;scale=(a,b), &#x5219;&#x7F29;&#x653E;&#x7684;&#x503C;&#x5728;<strong>a&lt;=scale&lt;=b</strong> &#x968F;&#x673A;&#x91C7;&#x6837;&#x3002;&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#x6CA1;&#x6709;&#x7F29;&#x653E;&#x3002;</li>
<li>shear (&#x9519;&#x5207;&#xFF0C;sequence &#x6216;&#x8005; float &#x6216;&#x8005; int, &#x53EF;&#x9009;)&#x3000;&#x2014;&#x2014;&#x3000;&#x9519;&#x5207;&#x7684;&#x7A0B;&#x5EA6;&#x3002;&#x5982;&#x679C;&#x9519;&#x5207;&#x7684;&#x7A0B;&#x5EA6;&#x662F;&#x4E00;&#x4E2A;&#x503C;&#xFF0C;&#x90A3;&#x4E48;&#x5C06;&#x4F1A;&#x8F6C;&#x6362;&#x4E3A;&#x5E8F;&#x5217;&#x5373;(&#x2014;degree, +degree)&#x3002;&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#x4E0D;&#x4F7F;&#x7528;&#x9519;&#x5207;&#x3002;</li>
<li>resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, &#x53EF;&#x9009;)&#x3002;</li>
<li>fillcolor(&#x6574;&#x578B;) &#x2014;&#x2014; &#x53EF;&#x9009;&#x62E9;&#x7684;&#x5728;&#x8F93;&#x51FA;&#x56FE;&#x7247;&#x4E2D;&#x586B;&#x5145;&#x53D8;&#x6362;&#x4EE5;&#x5916;&#x7684;&#x533A;&#x57DF;&#x3002;(Pillow&gt;=5.0.0)</li>
</ul>
<p><strong>7.torchvision.transforms.RandomApply(transforms, p=0.5)</strong>
&#x968F;&#x673A;&#x9009;&#x53D6;&#x53D8;&#x6362;&#x4E2D;(&#x5404;&#x79CD;&#x53D8;&#x6362;&#x5B58;&#x50A8;&#x5728;&#x5217;&#x8868;&#x4E2D;)&#x7684;&#x5176;&#x4E2D;&#x4E00;&#x4E2A;&#xFF0C;&#x540C;&#x65F6;&#x7ED9;&#x5B9A;&#x4E00;&#x5B9A;&#x7684;&#x6982;&#x7387;
<strong>&#x53C2;&#x6570;&#xFF1A;</strong>&#x3000;
&#x53D8;&#x6362;&#xFF08;list&#x6216;&#x8005;tuple&#xFF09; &#x2014;&#x2014;&#x3000;&#x8F6C;&#x6362;&#x7684;&#x5217;&#x8868;
p (float &#x7C7B;&#x578B;) &#x2014;&#x2014; &#x6982;&#x7387;,&#x9009;&#x53D6;&#x67D0;&#x4E2A;&#x53D8;&#x5316;&#x9700;&#x8981;&#x7684;&#x6982;&#x7387;</p>
<p><strong>8.transforms.RandomSizedCrop() RandomApply() RandomChoice() RadomCrop RamdomGrayscale() RamdomHorizontalFlip(p=0.5) RamdomRotation()</strong> &#x2026; &#x8FD8;&#x6709;&#x5404;&#x79CD;Random&#xFF0C;&#x8BE6;&#x7EC6;&#x8BF7;&#x67E5;&#x770B;<a href="https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transforms" target="_blank">torch.transforms</a></p>
<p><strong>9.torchvision.transforms.Resize(size,interpolation=2)</strong>
&#x5C06;&#x8F93;&#x5165;&#x7684;PIL&#x56FE;&#x7247;&#x8F6C;&#x6362;&#x6210;&#x7ED9;&#x5B9A;&#x7684;&#x5C3A;&#x5BF8;&#x7684;&#x5927;&#x5C0F;
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>size(sequence &#x6216;&#x8005; int)&#x3000;&#x2014;&#x2014;&#x3000;&#x9700;&#x8981;&#x8F93;&#x51FA;&#x7684;&#x56FE;&#x7247;&#x7684;&#x5927;&#x5C0F;&#x3002;&#x5982;&#x679C;size&#x662F;&#x7C7B;&#x4F3C;&#x4E8E;(h,w)&#x7684;&#x5E8F;&#x5217;&#xFF0C;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8;&#x5C06;&#x4F1A;&#x8DDF;(h,w)&#x4E00;&#x81F4;&#x3002;&#x5982;&#x679C;size&#x662F;&#x6574;&#x578B;&#xFF0C;&#x56FE;&#x7247;&#x8F83;&#x5C0F;&#x7684;&#x8FB9;&#x754C;&#x5C06;&#x4F1A;&#x88AB;&#x7F6E;&#x4E3A;&#x8FD9;&#x4E2A;&#x5C3A;&#x5BF8;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5982;&#x679C;height-&gt;width, &#x56FE;&#x7247;&#x5C06;&#x4F1A;&#x88AB;&#x7F6E;&#x4E3A; (size*height/width, size)</li>
<li>Interpolation (int, &#x53EF;&#x9009;) &#x2014;&#x2014; &#x9ED8;&#x8BA4;&#x4E3A; PIL.Image.BILINEAR</li>
</ul>
<h1 id="&#x4E09;-&#x5728;torchtensor&#x4E0A;&#x7684;&#x8F6C;&#x6362;">&#x4E09;. &#x5728;torch.*Tensor&#x4E0A;&#x7684;&#x8F6C;&#x6362;</h1>
<p><strong>1. class torchvision.transforms.Normalize(mean,std)</strong>
&#x7528;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;&#x5BF9;&#x5F20;&#x91CF;&#x56FE;&#x50CF;&#x8FDB;&#x884C;&#x6807;&#x51C6;&#x5316;&#x5904;&#x7406;&#x3002;&#x7ED9;&#x5B9A;n&#x901A;&#x9053;&#x7684;&#x5747;&#x503C;(M1, &#x2026; , Mn) &#x548C;&#x6807;&#x51C6;&#x5DEE;(S1, &#x2026; ,Sn), &#x8FD9;&#x4E2A;&#x53D8;&#x5316;&#x5C06;&#x4F1A;&#x5F52;&#x4E00;&#x5316;&#x6839;&#x636E;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;&#x5F52;&#x4E00;&#x5316;&#x6BCF;&#x4E2A;&#x901A;&#x9053;&#x503C;&#x3002;&#x4F8B;&#x5982;&#xFF0C;input[channel] = (input[channel]-mean[channel])/std(channel)
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>mean (squence) &#x2014;&#x2014;&#x3000;&#x6BCF;&#x4E2A;&#x901A;&#x9053;&#x7684;&#x5747;&#x503C;</li>
<li>std (sequence) &#x2014;&#x2014; &#x6BCF;&#x4E2A;&#x901A;&#x9053;&#x7684;&#x6807;&#x51C6;&#x5DEE;</li>
</ul>
<pre><code>__call__(tensor) &#x53C2;&#x6570;&#xFF1A;tensor(Tensor) , &#x5C3A;&#x5BF8;&#x4E3A;(C,H,W)&#x7684;&#x56FE;&#x7247;&#x5C06;&#x4F1A;&#x88AB;&#x5F52;&#x4E00;&#x5316; ; &#x8FD4;&#x56DE;&#xFF1A;&#x5F52;&#x4E00;&#x5316;&#x540E;&#x7684;Tensor&#x7C7B;&#x578B;&#x56FE;&#x7247; ; &#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;&#xFF34;ensor
</code></pre><h1 id="&#x56DB;-&#x7C7B;&#x578B;&#x8F6C;&#x6362;&#x53D8;&#x6362;-conversion-transforms">&#x56DB;. &#x7C7B;&#x578B;&#x8F6C;&#x6362;&#x53D8;&#x6362; (Conversion Transforms)</h1>
<p><strong>1. class torchvision.transforms.ToPILImage(mode=None)</strong>
&#x5C06;tensor&#x7C7B;&#x578B;&#x6216;&#x8005;ndarray&#x8F6C;&#x6362;&#x6210;PIL&#x56FE;&#x7247;
&#x5C06; CxHxW&#x5927;&#x5C0F;&#x7684;torch.*Tensor&#x6216;&#x8005;&#xFF28;xWxC &#x5927;&#x5C0F;&#x7684;numpy &#x77E9;&#x9635;&#x8F6C;&#x6210;PIL&#x56FE;&#x7247;
&#x53C2;&#x6570;&#xFF1A;&#x5982;&#x679C;model&#x4E3A;&#xFF2E;one,&#x90A3;&#x4E48;&#x5982;&#x679C;&#x8F93;&#x5165;&#x6709;&#x4E09;&#x4E2A;&#x901A;&#x9053;&#xFF0C;&#x90A3;&#x4E48;mode&#x4E3A;RGB; &#x5982;&#x679C;input&#x6709;4&#x4E2A;&#x901A;&#x9053;&#xFF0C;mode&#x4E3A;RGBA. &#x5982;&#x679C;&#x8F93;&#x5165;&#x662F;1&#x901A;&#x9053;&#xFF0C;mode&#x4E3A;&#x6570;&#x636E;&#x7C7B;&#x578B;&#xFF0C;&#x5982;int, float, short</p>
<pre><code>__call__(pic) &#x53C2;&#x6570;&#xFF1A;pic (Tensor&#x6216;&#x8005;numpy.ndarray&#x7C7B;&#x578B;&#x7684;)&#x3000;&#x2014;&#x2014;&#x3000;&#x8F6C;&#x6362;&#x6210;PIL&#x56FE;&#x7247;;  &#x8FD4;&#x56DE;PIL&#x56FE;&#x7247;; &#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#x4E3A;PIL&#x7C7B;&#x578B;
1
</code></pre><p><strong>2. torchvision.transforms.ToTensor</strong>
&#x5C06;PIL&#x56FE;&#x7247;&#x6216;&#x8005;numpy.ndarray&#x8F6C;&#x6210;Tensor&#x7C7B;&#x578B;&#x7684;
&#x5C06;PIL&#x56FE;&#x7247;&#x6216;&#x8005;numpy.ndarray(HxWxC) (&#x8303;&#x56F4;&#x5728;0-255) &#x8F6C;&#x6210;torch.FloatTensor (CxHxW) (&#x8303;&#x56F4;&#x4E3A;0.0-1.0)</p>
<pre><code>__call__(pic) &#x53C2;&#x6570;&#xFF1A;pic(PIL&#x56FE;&#x7247;&#x6216;&#x8005;numpy.ndarray) &#x2014;&#x2014; &#x5C06;&#x56FE;&#x7247;&#x8F6C;&#x6210;&#x5411;&#x91CF;; &#x8FD4;&#x56DE;Tensor&#x7C7B;&#x578B;&#x7684;&#x56FE;&#x7247;
1
</code></pre><h2 id="&#x4E94;-&#x4E00;&#x822C;&#x53D8;&#x6362;-generic-transforms">&#x4E94;. &#x4E00;&#x822C;&#x53D8;&#x6362; (Generic Transforms)</h2>
<p><strong>1. torchvision.transforms.Lambda(lambd)</strong>
&#x4F7F;&#x7528;&#x7528;&#x6237;&#x5B9A;&#x4E49;&#x7684;lambda&#x4F5C;&#x4E3A;&#x8F6C;&#x6362;
&#x53C2;&#x6570;&#xFF1A;lambd(function) &#x2014;&#x2014;&#x3000;&#x7528;Lambda/funtion &#x4F5C;&#x4E3A;&#x53D8;&#x6362;</p>
<p><strong>2. torchvision.transforms.functional.adjust_brightness(img, brightness_factor)</strong>
&#x8C03;&#x6574;&#x56FE;&#x7247;&#x7684;&#x4EAE;&#x5EA6;
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>img(PIL &#x56FE;&#x7247;)&#x2014;&#x2014;PIL&#x56FE;&#x7247;</li>
<li>brightness_factor(float)&#x2014;&#x2014;&#x4EAE;&#x5EA6;&#x8C03;&#x6574;&#x7A0B;&#x5EA6;&#x3002;&#x4E0D;&#x80FD;&#x4E3A;&#x8D1F;&#x6570;, &#xFF10;&#x4EE3;&#x8868;&#x9ED1;&#x8272;&#x56FE;&#x7247;&#xFF0C;1&#x4EE3;&#x8868;&#x539F;&#x59CB;&#x56FE;&#x7247;&#xFF0C;2&#x4EE3;&#x8868;&#x589E;&#x52A0;&#x4E86;2&#x4E2A;&#x56E0;&#x5B50;&#x7684;&#x4EAE;&#x5EA6;&#x3002;</li>
<li>returns: &#x8FD4;&#x56DE;&#x8C03;&#x6574;&#x5B8C;&#x7684;&#x56FE;&#x7247;</li>
</ul>
<p><strong>3.torchvision.transforms.functional.adjust_contrast(img,contrast_factor)</strong>
&#x8C03;&#x6574;&#x56FE;&#x7247;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>img &#x2014;&#x2014; &#x9700;&#x8981;&#x8C03;&#x6574;&#x7684;PIL &#x56FE;&#x7247;</li>
<li>constrast_factor(float) &#x2014;&#x2014; &#x8C03;&#x6574;&#x5BF9;&#x6BD4;&#x5EA6;&#x7684;&#x7A0B;&#x5EA6;&#x3002;&#x53EF;&#x4EE5;&#x662F;&#x975E;&#x8D1F;&#x7684;&#x6570;&#x3002;0&#x4E3A;&#x7070;&#x5EA6;&#x56FE;&#xFF0C;1&#x4E3A;&#x539F;&#x56FE;&#xFF0C;2&#x4E3A;&#x589E;&#x52A0;&#x56FE;&#x7247;2&#x4E2A;&#x5BF9;&#x6BD4;&#x56E0;&#x5B50;&#x7684;&#x56FE;&#x7247;&#x3002;</li>
<li>returns&#x3000;&#x2014;&#x2014;&#x3000;&#x8FD4;&#x56DE;&#x8C03;&#x6574;&#x540E;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;&#x56FE;&#x7247;</li>
</ul>
<p><strong>4. torchvison.transforms.function.adjust_gamma(img, gamma, gain=1)</strong>
&#x5BF9;&#x56FE;&#x7247;&#x8FDB;&#x884C;gamma&#x6821;&#x6B63;&#xFF0C;<a href="https://en.wikipedia.org/wiki/Gamma_correction" target="_blank">gamma&#x6821;&#x6B63;&#x8BE6;&#x60C5;</a>
Iout=255&#x2217;gain&#x2217;(Iin/255)&#x3B3;I<em>{out}=255<em>gain</em>(I</em>{in}/255)^{\gamma}<em>I<strong>o</strong>u**t</em>&#x200B;=255&#x2217;<em>g<strong>a</strong>i**n</em>&#x2217;(<em>I<strong>i</strong>n</em>&#x200B;/255)<em>&#x3B3;</em></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>img(PIL&#x56FE;&#x7247;)&#x2014;&#x2014;&#x9700;&#x8981;&#x8C03;&#x6574;&#x7684;PIL&#x56FE;&#x7247;</li>
<li>gamma (float&#x7C7B;&#x578B;)&#x2014;&#x2014;&#x975E;&#x96F6;&#x5B9E;&#x6570;&#xFF0C;&#x516C;&#x5F0F;&#x4E2D;&#x7684;&#x3B3;\gamma<em>&#x3B3;</em>&#x4E5F;&#x662F;&#x975E;&#x96F6;&#x5B9E;&#x6570;&#x3002;gamma&#x5927;&#x4E8E;1&#x4F7F;&#x5F97;&#x9634;&#x5F71;&#x90E8;&#x5206;&#x66F4;&#x6697;&#xFF0C;gamma&#x5C0F;&#x4E8E;1&#x4F7F;&#x5F97;&#x6697;&#x7684;&#x533A;&#x57DF;&#x4EAE;&#x4E9B;&#x3002;</li>
<li>gain(float) &#x2014;&#x2014;&#x3000;&#x5E38;&#x91CF;&#x4E58;&#x6570;</li>
</ul>
<p><strong>5.torchvision.transforms.functional.ajust_hue (img,hue_factor)</strong>
&#x8C03;&#x6574;&#x56FE;&#x7247;&#x7684;&#x8272;&#x76F8;
&#x901A;&#x8FC7;&#x5C06;&#x56FE;&#x50CF;&#x8F6C;&#x6362;&#x4E3A;HSV&#x6765;&#x8C03;&#x6574;&#x56FE;&#x50CF;&#x7684;&#x8272;&#x8C03;&#xFF0C;&#x5E76;&#x5728;&#x8272;&#x8C03;&#x901A;&#x9053;(H)&#x4E2D;&#x5FAA;&#x73AF;&#x79FB;&#x52A8;&#x5F3A;&#x5EA6;&#xFF0C;&#x7136;&#x540E;&#x5C06;&#x56FE;&#x50CF;&#x8F6C;&#x6362;&#x56DE;&#x539F;&#x59CB;&#x56FE;&#x50CF;&#x6A21;&#x5F0F;&#x3002;
&#x8272;&#x76F8;&#x56E0;&#x5B50;&#x662F;&#xFF28;&#x901A;&#x9053;&#x5E73;&#x79FB;&#x91CF;&#xFF0C;&#x5176;&#x5FC5;&#x987B;&#x5728;&#x533A;&#x95F4;[-0.5,0.5]&#x4E2D;&#x3002;
&#x53C2;&#x6570;</p>
<ul>
<li>img (PIL &#x56FE;&#x7247;)&#x3000;&#x2014;&#x2014;&#x3000;&#x9700;&#x8981;&#x8C03;&#x6574;&#x7684;PIL&#x56FE;&#x7247;</li>
<li>hue_factor (float&#x7C7B;&#x578B;) &#x2014;&#x2014; &#x8272;&#x76F8;&#x901A;&#x9053;&#x5E73;&#x79FB;&#x7684;&#x91CF;&#xFF0C;&#x5FC5;&#x987B;&#x5728;[-0.5,0.5]&#x4E4B;&#x95F4;&#x3002;0.5&#x548C;-0.5&#x5206;&#x522B;&#x4EE3;&#x8868;&#x5728;HSV&#x7A7A;&#x95F4;&#x4E2D;&#x6B63;&#x8D1F;&#x65B9;&#x5411;&#x5B8C;&#x5168;&#x76F8;&#x53CD;&#x7684;&#x8272;&#x76F8;&#x901A;&#x9053;&#x3002;0&#x4EE3;&#x8868;&#x6CA1;&#x6709;&#x5E73;&#x79FB;&#x3002;</li>
</ul>
<p><strong>5. tochvision.transforms.functional.adjust_saturation(img, hue_factor)</strong>
&#x8C03;&#x6574;&#x56FE;&#x7247;&#x7684;&#x989C;&#x8272;&#x9971;&#x548C;&#x5EA6;
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>img (PIL&#x56FE;&#x7247;)&#x2014;&#x2014;&#x9700;&#x8981;&#x8C03;&#x6574;&#x7684;PIL&#x56FE;&#x7247;</li>
<li>&#x9971;&#x548C;&#x5EA6;&#x56E0;&#x5B50;(float&#x7C7B;&#x578B;)&#x2014;&#x2014;&#x8C03;&#x6574;&#x9971;&#x548C;&#x5EA6;&#x7684;&#x7A0B;&#x5EA6;&#x3002;0&#x5C06;&#x4F1A;&#x8F93;&#x51FA;&#x9ED1;&#x767D;&#x56FE;&#x7247;&#xFF0C;1&#x5C06;&#x4F1A;&#x8F93;&#x51FA;&#x539F;&#x59CB;&#x56FE;&#x7247;&#xFF0C;2&#x5C06;&#x4F1A;&#x589E;&#x5F3A;2&#x4E2A;&#x56E0;&#x5B50;&#x7684;&#x9971;&#x548C;&#x5EA6;&#x3002;</li>
<li>&#x8FD4;&#x56DE;&#x8C03;&#x6574;&#x540E;&#x7684;&#x56FE;&#x7247;&#x3002;</li>
</ul>
<p><strong>6. torchvision.transforms.functional.affine(img, angle, translate, scale, shear, resample=0, fillcolor=None)</strong>
&#x5BF9;&#x56FE;&#x7247;&#x8FDB;&#x884C;&#x653E;&#x5C04;&#x53D8;&#x6362;&#xFF0C;&#x4FDD;&#x6301;&#x4E2D;&#x5FC3;&#x4E0D;&#x53D8;&#x3002;
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>img (PIL&#x56FE;&#x7247;)&#x2014;&#x2014;&#x9700;&#x8981;&#x53D8;&#x6362;&#x7684;PIL&#x56FE;&#x7247;</li>
<li>angle(float &#x6216;&#x8005; int)&#x2014;&#x2014;&#x65CB;&#x8F6C;&#x7684;&#x7684;&#x89D2;&#x5EA6;&#xFF0C;&#x89D2;&#x5EA6;&#x8303;&#x56F4;&#x4E3A; (-180,180), &#x6B63;&#x65B9;&#x5411;&#x4E3A;&#x987A;&#x65F6;&#x9488;&#x65B9;&#x5411;&#x3002;</li>
<li>translate(list &#x6216;&#x8005; tuple)&#x2014;&#x2014;&#x6C34;&#x5E73;&#x6216;&#x8005;&#x5782;&#x76F4;&#x5E73;&#x79FB;</li>
<li>scale(float)&#x2014;&#x2014;&#x603B;&#x4F53;&#x7F29;&#x653E;</li>
<li>shear(&#x9519;&#x5207;&#xFF0C;float)&#x2014;&#x2014;&#x9519;&#x5207;&#x7684;&#x89D2;&#x5EA6;&#x4F4D;&#x4E8E;(-180,180)&#xFF0C;&#x987A;&#x65F6;&#x9488;&#x65B9;&#x5411;&#x3002;</li>
<li>resample&#xFF08;&#x8FD9;&#x4E2A;&#x6709;&#x70B9;&#x770B;&#x4E0D;&#x61C2;&#xFF0C;&#x5E94;&#x8BE5;&#x6BD4;&#x8F83;&#x5C11;&#x7528;&#x5230;&#x2014;&#x2014;PIL.Image.NEAREST or PIL.Image.BILINEAR or PIL.Image.BICUBIC, optional</li>
<li>fillcolor (int) &#x2014;&#x2014; &#x586B;&#x5145;&#x8F93;&#x51FA;&#x56FE;&#x7247;&#x4E2D;&#x8D85;&#x8FC7;&#x53D8;&#x6362;&#x7684;&#x533A;&#x57DF;(Pillow&gt;=5.0)</li>
</ul>
<p><strong>7.torchvision.transforms.functional.crop(img,i,j,h,w)</strong>
&#x526A;&#x88C1;&#x7ED9;&#x5B9A;&#x7684;PIL&#x56FE;&#x7247;
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>img(PIL&#x56FE;&#x7247;)&#x2014;&#x2014;&#x88AB;&#x526A;&#x88C1;&#x7684;&#x56FE;&#x7247;</li>
<li>&#xFF08;i, j) &#x2014;&#x2014;&#x5DE6;&#x4E0A;&#x89D2;&#x56FE;&#x7247;&#x5750;&#x6807;</li>
<li>(h,w)&#x2014;&#x2014;&#x526A;&#x88C1;&#x7684;&#x56FE;&#x7247;&#x7684;&#x9AD8;&#x548C;&#x5BBD;
  returns: &#x8FD4;&#x56DE;&#x526A;&#x5F69;&#x7684;&#x56FE;&#x7247;</li>
</ul>
<p><strong>8. torchvision.transforms.functional.normalize(tensor, mean, std)</strong>
&#x6839;&#x636E;&#x7ED9;&#x5B9A;&#x7684;&#x6807;&#x51C6;&#x5DEE;&#x548C;&#x65B9;&#x5DEE;&#x5F52;&#x4E00;&#x5316;tensor&#x56FE;&#x7247;
&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li>tensor(Tensor)&#x2014;&#x2014; &#x5F62;&#x72B6;&#x4E3A;(C,H,W)&#x7684;Tensor&#x56FE;&#x7247;</li>
<li>mean(squence) &#x2014;&#x2014; &#x6BCF;&#x4E2A;&#x901A;&#x9053;&#x7684;&#x5747;&#x503C;&#xFF0C;&#x5E8F;&#x5217;</li>
<li>std (sequence) &#x2014;&#x2014; &#x6BCF;&#x4E2A;&#x901A;&#x9053;&#x7684;&#x6807;&#x51C6;&#x5DEE;&#xFF0C;&#x5E8F;&#x5217;
  &#x8FD4;&#x56DE;&#xFF1A;&#x8FD4;&#x56DE;&#x5F52;&#x4E00;&#x5316;&#x540E;&#x7684;Tensor&#x56FE;&#x7247;&#x3002;</li>
</ul>
<p><strong>9.torchvision.transforms.functional.pad(img, padding, fill=0, padding_mode=&#x2018;constant&#x2019;)&#x3001;torchvision.transforms.functional.resize(img, size, interpolation=2)&#x3001;torchvision.transforms.functional.rotate(img, angle, resample=False, expand=False, center=None)&#x3001;torchvision.transforms.functional.to_grayscale(img, num_output_channels&#xFF1D;&#xFF11;)</strong>
&#x7B49;&#x5747;&#x4E0E;&#x4E0A;&#x8FF0;&#x51FD;&#x6570;&#x7C7B;&#x4F3C;&#xFF0C;&#x8FD9;&#x91CC;&#x4E0D;&#x518D;&#x91CD;&#x590D;&#x3002;</p>
<p><strong>10.torchvision.transforms.functional.to_pil_image(pic, mode=None) &#x5C06;tensor&#x6216;&#x8005;numpy.ndarray&#x8F6C;&#x6210;PIL&#x56FE;&#x7247;torchvision.transforms.functional.to_tensor(pic) &#x5C06;PIL&#x56FE;&#x7247;&#x6216;&#x8005;numpy.ndarray&#x8F6C;&#x6210;tensor</strong></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="SPP.html" class="navigation navigation-prev " aria-label="Previous page: SPP">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../../linux/" class="navigation navigation-next " aria-label="Next page: Linux">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Tensor to img && imge to tensor","level":"1.4.11","depth":2,"next":{"title":"Linux","level":"1.5","depth":1,"path":"linux/README.md","ref":"linux/README.md","articles":[{"title":"Linux技巧","level":"1.5.1","depth":2,"path":"linux/linux_technique.md","ref":"linux/linux_technique.md","articles":[]},{"title":"Linux显卡驱动修复","level":"1.5.2","depth":2,"path":"linux/linux_GPU.md","ref":"linux/linux_GPU.md","articles":[]}]},"previous":{"title":"SPP","level":"1.4.10","depth":2,"path":"code_technique/pytorch/SPP.md","ref":"code_technique/pytorch/SPP.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-search","search-pro","back-to-top-button","expandable-chapters-small","back-to-top-button","chapter-fold","expandable-chapters-small","github","katex","include-codeblock","livereload"],"root":"./content","styles":{"website":"assets/styles/website.less","ebook":"assets/styles/ebook.less","pdf":"assets/styles/pdf.less","mobi":"assets/styles/mobi.less","epub":"assets/styles/epub.less"},"pluginsConfig":{"chapter-fold":{},"prism":{"css":["prismjs/themes/prism-solarizedlight.css"],"lang":{"flow":"typescript"}},"github":{"url":"https://github.com/OUCMachineLearning/OUCML"},"livereload":{},"search-pro":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"katex":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"expandable-chapters-small":{},"include-codeblock":{"check":false,"edit":false,"fixlang":false,"lang":"","template":"default","theme":"chrome","unindent":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"language":"zh-hans","gitbook":"*"},"file":{"path":"code_technique/pytorch/Tensor_to_img_imge_to_tensor.md","mtime":"2019-10-24T04:35:18.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-10-25T10:54:29.358Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

